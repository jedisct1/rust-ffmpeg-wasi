/* automatically generated by rust-bindgen 0.69.4 */

pub const __LITTLE_ENDIAN: u32 = 1234;
pub const __BIG_ENDIAN: u32 = 4321;
pub const __USE_TIME_BITS64: u32 = 1;
pub const INT8_MIN: i32 = -128;
pub const INT16_MIN: i32 = -32768;
pub const INT32_MIN: i32 = -2147483648;
pub const INT64_MIN: i64 = -9223372036854775808;
pub const INT8_MAX: u32 = 127;
pub const INT16_MAX: u32 = 32767;
pub const INT32_MAX: u32 = 2147483647;
pub const INT64_MAX: u64 = 9223372036854775807;
pub const UINT8_MAX: u32 = 255;
pub const UINT16_MAX: u32 = 65535;
pub const UINT32_MAX: u32 = 4294967295;
pub const UINT64_MAX: i32 = -1;
pub const INT_FAST8_MIN: i32 = -128;
pub const INT_FAST64_MIN: i64 = -9223372036854775808;
pub const INT_LEAST8_MIN: i32 = -128;
pub const INT_LEAST16_MIN: i32 = -32768;
pub const INT_LEAST32_MIN: i32 = -2147483648;
pub const INT_LEAST64_MIN: i64 = -9223372036854775808;
pub const INT_FAST8_MAX: u32 = 127;
pub const INT_FAST64_MAX: u64 = 9223372036854775807;
pub const INT_LEAST8_MAX: u32 = 127;
pub const INT_LEAST16_MAX: u32 = 32767;
pub const INT_LEAST32_MAX: u32 = 2147483647;
pub const INT_LEAST64_MAX: u64 = 9223372036854775807;
pub const UINT_FAST8_MAX: u32 = 255;
pub const UINT_FAST64_MAX: i32 = -1;
pub const UINT_LEAST8_MAX: u32 = 255;
pub const UINT_LEAST16_MAX: u32 = 65535;
pub const UINT_LEAST32_MAX: u32 = 4294967295;
pub const UINT_LEAST64_MAX: i32 = -1;
pub const INTMAX_MIN: i64 = -9223372036854775808;
pub const INTMAX_MAX: u64 = 9223372036854775807;
pub const UINTMAX_MAX: i32 = -1;
pub const WINT_MIN: u32 = 0;
pub const WINT_MAX: u32 = 4294967295;
pub const SIG_ATOMIC_MIN: i32 = -2147483648;
pub const SIG_ATOMIC_MAX: u32 = 2147483647;
pub const INT_FAST16_MIN: i32 = -32768;
pub const INT_FAST32_MIN: i32 = -2147483648;
pub const INT_FAST16_MAX: u32 = 32767;
pub const INT_FAST32_MAX: u32 = 2147483647;
pub const UINT_FAST16_MAX: u32 = 65535;
pub const UINT_FAST32_MAX: u32 = 4294967295;
pub const INTPTR_MIN: i32 = -2147483648;
pub const INTPTR_MAX: u32 = 2147483647;
pub const UINTPTR_MAX: u32 = 4294967295;
pub const PTRDIFF_MIN: i32 = -2147483648;
pub const PTRDIFF_MAX: u32 = 2147483647;
pub const SIZE_MAX: u32 = 4294967295;
pub const FF_LAMBDA_SHIFT: u32 = 7;
pub const FF_LAMBDA_SCALE: u32 = 128;
pub const FF_QP2LAMBDA: u32 = 118;
pub const FF_LAMBDA_MAX: u32 = 32767;
pub const FF_QUALITY_SCALE: u32 = 128;
pub const AV_TIME_BASE: u32 = 1000000;
pub const _BSD_SOURCE: u32 = 1;
pub const _XOPEN_SOURCE: u32 = 700;
pub const CHAR_MIN: i32 = -128;
pub const CHAR_MAX: u32 = 127;
pub const CHAR_BIT: u32 = 8;
pub const SCHAR_MIN: i32 = -128;
pub const SCHAR_MAX: u32 = 127;
pub const UCHAR_MAX: u32 = 255;
pub const SHRT_MIN: i32 = -32768;
pub const SHRT_MAX: u32 = 32767;
pub const USHRT_MAX: u32 = 65535;
pub const INT_MIN: i32 = -2147483648;
pub const INT_MAX: u32 = 2147483647;
pub const UINT_MAX: u32 = 4294967295;
pub const LLONG_MAX: u64 = 9223372036854775807;
pub const ULLONG_MAX: i32 = -1;
pub const MB_LEN_MAX: u32 = 4;
pub const PAGESIZE: u32 = 65536;
pub const FILESIZEBITS: u32 = 64;
pub const NAME_MAX: u32 = 255;
pub const PATH_MAX: u32 = 4096;
pub const NGROUPS_MAX: u32 = 32;
pub const ARG_MAX: u32 = 131072;
pub const IOV_MAX: u32 = 1024;
pub const SYMLOOP_MAX: u32 = 40;
pub const WORD_BIT: u32 = 32;
pub const TZNAME_MAX: u32 = 6;
pub const TTY_NAME_MAX: u32 = 32;
pub const HOST_NAME_MAX: u32 = 255;
pub const LONG_BIT: u32 = 32;
pub const DELAYTIMER_MAX: u32 = 2147483647;
pub const CHARCLASS_NAME_MAX: u32 = 14;
pub const COLL_WEIGHTS_MAX: u32 = 2;
pub const RE_DUP_MAX: u32 = 255;
pub const NL_ARGMAX: u32 = 9;
pub const NL_MSGMAX: u32 = 32767;
pub const NL_SETMAX: u32 = 255;
pub const NL_TEXTMAX: u32 = 2048;
pub const PAGE_SIZE: u32 = 65536;
pub const NZERO: u32 = 20;
pub const NL_LANGMAX: u32 = 32;
pub const NL_NMAX: u32 = 16;
pub const _POSIX_AIO_LISTIO_MAX: u32 = 2;
pub const _POSIX_AIO_MAX: u32 = 1;
pub const _POSIX_ARG_MAX: u32 = 4096;
pub const _POSIX_CHILD_MAX: u32 = 25;
pub const _POSIX_CLOCKRES_MIN: u32 = 20000000;
pub const _POSIX_DELAYTIMER_MAX: u32 = 32;
pub const _POSIX_HOST_NAME_MAX: u32 = 255;
pub const _POSIX_LINK_MAX: u32 = 8;
pub const _POSIX_LOGIN_NAME_MAX: u32 = 9;
pub const _POSIX_MAX_CANON: u32 = 255;
pub const _POSIX_MAX_INPUT: u32 = 255;
pub const _POSIX_MQ_OPEN_MAX: u32 = 8;
pub const _POSIX_MQ_PRIO_MAX: u32 = 32;
pub const _POSIX_NAME_MAX: u32 = 14;
pub const _POSIX_NGROUPS_MAX: u32 = 8;
pub const _POSIX_OPEN_MAX: u32 = 20;
pub const _POSIX_PATH_MAX: u32 = 256;
pub const _POSIX_PIPE_BUF: u32 = 512;
pub const _POSIX_RE_DUP_MAX: u32 = 255;
pub const _POSIX_RTSIG_MAX: u32 = 8;
pub const _POSIX_SEM_NSEMS_MAX: u32 = 256;
pub const _POSIX_SEM_VALUE_MAX: u32 = 32767;
pub const _POSIX_SIGQUEUE_MAX: u32 = 32;
pub const _POSIX_SSIZE_MAX: u32 = 32767;
pub const _POSIX_STREAM_MAX: u32 = 8;
pub const _POSIX_SS_REPL_MAX: u32 = 4;
pub const _POSIX_SYMLINK_MAX: u32 = 255;
pub const _POSIX_SYMLOOP_MAX: u32 = 8;
pub const _POSIX_THREAD_DESTRUCTOR_ITERATIONS: u32 = 4;
pub const _POSIX_THREAD_KEYS_MAX: u32 = 128;
pub const _POSIX_THREAD_THREADS_MAX: u32 = 64;
pub const _POSIX_TIMER_MAX: u32 = 32;
pub const _POSIX_TRACE_EVENT_NAME_MAX: u32 = 30;
pub const _POSIX_TRACE_NAME_MAX: u32 = 8;
pub const _POSIX_TRACE_SYS_MAX: u32 = 8;
pub const _POSIX_TRACE_USER_EVENT_MAX: u32 = 32;
pub const _POSIX_TTY_NAME_MAX: u32 = 9;
pub const _POSIX_TZNAME_MAX: u32 = 6;
pub const _POSIX2_BC_BASE_MAX: u32 = 99;
pub const _POSIX2_BC_DIM_MAX: u32 = 2048;
pub const _POSIX2_BC_SCALE_MAX: u32 = 99;
pub const _POSIX2_BC_STRING_MAX: u32 = 1000;
pub const _POSIX2_CHARCLASS_NAME_MAX: u32 = 14;
pub const _POSIX2_COLL_WEIGHTS_MAX: u32 = 2;
pub const _POSIX2_EXPR_NEST_MAX: u32 = 32;
pub const _POSIX2_LINE_MAX: u32 = 2048;
pub const _POSIX2_RE_DUP_MAX: u32 = 255;
pub const _XOPEN_IOV_MAX: u32 = 16;
pub const _XOPEN_NAME_MAX: u32 = 255;
pub const _XOPEN_PATH_MAX: u32 = 1024;
pub const MATH_ERRNO: u32 = 1;
pub const MATH_ERREXCEPT: u32 = 2;
pub const math_errhandling: u32 = 2;
pub const FP_ILOGBNAN: i32 = -2147483648;
pub const FP_ILOGB0: i32 = -2147483648;
pub const FP_NAN: u32 = 0;
pub const FP_INFINITE: u32 = 1;
pub const FP_ZERO: u32 = 2;
pub const FP_SUBNORMAL: u32 = 3;
pub const FP_NORMAL: u32 = 4;
pub const M_E: f64 = 2.718281828459045;
pub const M_LOG2E: f64 = 1.4426950408889634;
pub const M_LOG10E: f64 = 0.4342944819032518;
pub const M_LN2: f64 = 0.6931471805599453;
pub const M_LN10: f64 = 2.302585092994046;
pub const M_PI: f64 = 3.141592653589793;
pub const M_PI_2: f64 = 1.5707963267948966;
pub const M_PI_4: f64 = 0.7853981633974483;
pub const M_1_PI: f64 = 0.3183098861837907;
pub const M_2_PI: f64 = 0.6366197723675814;
pub const M_2_SQRTPI: f64 = 1.1283791670955126;
pub const M_SQRT2: f64 = 1.4142135623730951;
pub const M_SQRT1_2: f64 = 0.7071067811865476;
pub const EOF: i32 = -1;
pub const _IOFBF: u32 = 0;
pub const _IOLBF: u32 = 1;
pub const _IONBF: u32 = 2;
pub const BUFSIZ: u32 = 1024;
pub const FILENAME_MAX: u32 = 4096;
pub const FOPEN_MAX: u32 = 1000;
pub const L_ctermid: u32 = 20;
pub const L_cuserid: u32 = 20;
pub const EXIT_FAILURE: u32 = 1;
pub const EXIT_SUCCESS: u32 = 0;
pub const RAND_MAX: u32 = 2147483647;
pub const AV_HAVE_BIGENDIAN: u32 = 0;
pub const AV_HAVE_FAST_UNALIGNED: u32 = 0;
pub const AVERROR_EXPERIMENTAL: i32 = -733130664;
pub const AVERROR_INPUT_CHANGED: i32 = -1668179713;
pub const AVERROR_OUTPUT_CHANGED: i32 = -1668179714;
pub const AV_ERROR_MAX_STRING_SIZE: u32 = 64;
pub const LIBAVUTIL_VERSION_MAJOR: u32 = 59;
pub const LIBAVUTIL_VERSION_MINOR: u32 = 16;
pub const LIBAVUTIL_VERSION_MICRO: u32 = 101;
pub const M_Ef: f64 = 2.718281828459045;
pub const M_LN2f: f64 = 0.6931471805599453;
pub const M_LN10f: f64 = 2.302585092994046;
pub const M_LOG2_10: f64 = 3.321928094887362;
pub const M_LOG2_10f: f64 = 3.321928094887362;
pub const M_PHI: f64 = 1.618033988749895;
pub const M_PHIf: f64 = 1.618033988749895;
pub const M_PIf: f64 = 3.141592653589793;
pub const M_PI_2f: f64 = 1.5707963267948966;
pub const M_PI_4f: f64 = 0.7853981633974483;
pub const M_1_PIf: f64 = 0.3183098861837907;
pub const M_2_PIf: f64 = 0.6366197723675814;
pub const M_2_SQRTPIf: f64 = 1.1283791670955126;
pub const M_SQRT1_2f: f64 = 0.7071067811865476;
pub const M_SQRT2f: f64 = 1.4142135623730951;
pub const __GNUC_VA_LIST: u32 = 1;
pub const AV_LOG_QUIET: i32 = -8;
pub const AV_LOG_PANIC: u32 = 0;
pub const AV_LOG_FATAL: u32 = 8;
pub const AV_LOG_ERROR: u32 = 16;
pub const AV_LOG_WARNING: u32 = 24;
pub const AV_LOG_INFO: u32 = 32;
pub const AV_LOG_VERBOSE: u32 = 40;
pub const AV_LOG_DEBUG: u32 = 48;
pub const AV_LOG_TRACE: u32 = 56;
pub const AV_LOG_MAX_OFFSET: u32 = 64;
pub const AV_LOG_SKIP_REPEATED: u32 = 1;
pub const AV_LOG_PRINT_LEVEL: u32 = 2;
pub const AVPALETTE_SIZE: u32 = 1024;
pub const AVPALETTE_COUNT: u32 = 256;
pub const AV_VIDEO_MAX_PLANES: u32 = 4;
pub const AV_FOURCC_MAX_STRING_SIZE: u32 = 32;
pub const AV_BUFFER_FLAG_READONLY: u32 = 1;
pub const AV_CHANNEL_LAYOUT_RETYPE_FLAG_LOSSLESS: u32 = 1;
pub const AV_CHANNEL_LAYOUT_RETYPE_FLAG_CANONICAL: u32 = 2;
pub const AV_DICT_MATCH_CASE: u32 = 1;
pub const AV_DICT_IGNORE_SUFFIX: u32 = 2;
pub const AV_DICT_DONT_STRDUP_KEY: u32 = 4;
pub const AV_DICT_DONT_STRDUP_VAL: u32 = 8;
pub const AV_DICT_DONT_OVERWRITE: u32 = 16;
pub const AV_DICT_APPEND: u32 = 32;
pub const AV_DICT_MULTIKEY: u32 = 64;
pub const AV_NUM_DATA_POINTERS: u32 = 8;
pub const AV_FRAME_FLAG_CORRUPT: u32 = 1;
pub const AV_FRAME_FLAG_KEY: u32 = 2;
pub const AV_FRAME_FLAG_DISCARD: u32 = 4;
pub const AV_FRAME_FLAG_INTERLACED: u32 = 8;
pub const AV_FRAME_FLAG_TOP_FIELD_FIRST: u32 = 16;
pub const FF_DECODE_ERROR_INVALID_BITSTREAM: u32 = 1;
pub const FF_DECODE_ERROR_MISSING_REFERENCE: u32 = 2;
pub const FF_DECODE_ERROR_CONCEALMENT_ACTIVE: u32 = 4;
pub const FF_DECODE_ERROR_DECODE_SLICES: u32 = 8;
pub const AV_FRAME_SIDE_DATA_FLAG_UNIQUE: u32 = 1;
pub const AV_FRAME_SIDE_DATA_FLAG_REPLACE: u32 = 2;
pub const LIBAVCODEC_VERSION_MAJOR: u32 = 61;
pub const AV_CODEC_CAP_DRAW_HORIZ_BAND: u32 = 1;
pub const AV_CODEC_CAP_DR1: u32 = 2;
pub const AV_CODEC_CAP_DELAY: u32 = 32;
pub const AV_CODEC_CAP_SMALL_LAST_FRAME: u32 = 64;
pub const AV_CODEC_CAP_SUBFRAMES: u32 = 256;
pub const AV_CODEC_CAP_EXPERIMENTAL: u32 = 512;
pub const AV_CODEC_CAP_CHANNEL_CONF: u32 = 1024;
pub const AV_CODEC_CAP_FRAME_THREADS: u32 = 4096;
pub const AV_CODEC_CAP_SLICE_THREADS: u32 = 8192;
pub const AV_CODEC_CAP_PARAM_CHANGE: u32 = 16384;
pub const AV_CODEC_CAP_OTHER_THREADS: u32 = 32768;
pub const AV_CODEC_CAP_VARIABLE_FRAME_SIZE: u32 = 65536;
pub const AV_CODEC_CAP_AVOID_PROBING: u32 = 131072;
pub const AV_CODEC_CAP_HARDWARE: u32 = 262144;
pub const AV_CODEC_CAP_HYBRID: u32 = 524288;
pub const AV_CODEC_CAP_ENCODER_REORDERED_OPAQUE: u32 = 1048576;
pub const AV_CODEC_CAP_ENCODER_FLUSH: u32 = 2097152;
pub const AV_CODEC_CAP_ENCODER_RECON_FRAME: u32 = 4194304;
pub const AV_INPUT_BUFFER_PADDING_SIZE: u32 = 64;
pub const AV_EF_CRCCHECK: u32 = 1;
pub const AV_EF_BITSTREAM: u32 = 2;
pub const AV_EF_BUFFER: u32 = 4;
pub const AV_EF_EXPLODE: u32 = 8;
pub const AV_EF_IGNORE_ERR: u32 = 32768;
pub const AV_EF_CAREFUL: u32 = 65536;
pub const AV_EF_COMPLIANT: u32 = 131072;
pub const AV_EF_AGGRESSIVE: u32 = 262144;
pub const FF_COMPLIANCE_VERY_STRICT: u32 = 2;
pub const FF_COMPLIANCE_STRICT: u32 = 1;
pub const FF_COMPLIANCE_NORMAL: u32 = 0;
pub const FF_COMPLIANCE_UNOFFICIAL: i32 = -1;
pub const FF_COMPLIANCE_EXPERIMENTAL: i32 = -2;
pub const AV_PROFILE_UNKNOWN: i32 = -99;
pub const AV_PROFILE_RESERVED: i32 = -100;
pub const AV_PROFILE_AAC_MAIN: u32 = 0;
pub const AV_PROFILE_AAC_LOW: u32 = 1;
pub const AV_PROFILE_AAC_SSR: u32 = 2;
pub const AV_PROFILE_AAC_LTP: u32 = 3;
pub const AV_PROFILE_AAC_HE: u32 = 4;
pub const AV_PROFILE_AAC_HE_V2: u32 = 28;
pub const AV_PROFILE_AAC_LD: u32 = 22;
pub const AV_PROFILE_AAC_ELD: u32 = 38;
pub const AV_PROFILE_MPEG2_AAC_LOW: u32 = 128;
pub const AV_PROFILE_MPEG2_AAC_HE: u32 = 131;
pub const AV_PROFILE_DNXHD: u32 = 0;
pub const AV_PROFILE_DNXHR_LB: u32 = 1;
pub const AV_PROFILE_DNXHR_SQ: u32 = 2;
pub const AV_PROFILE_DNXHR_HQ: u32 = 3;
pub const AV_PROFILE_DNXHR_HQX: u32 = 4;
pub const AV_PROFILE_DNXHR_444: u32 = 5;
pub const AV_PROFILE_DTS: u32 = 20;
pub const AV_PROFILE_DTS_ES: u32 = 30;
pub const AV_PROFILE_DTS_96_24: u32 = 40;
pub const AV_PROFILE_DTS_HD_HRA: u32 = 50;
pub const AV_PROFILE_DTS_HD_MA: u32 = 60;
pub const AV_PROFILE_DTS_EXPRESS: u32 = 70;
pub const AV_PROFILE_DTS_HD_MA_X: u32 = 61;
pub const AV_PROFILE_DTS_HD_MA_X_IMAX: u32 = 62;
pub const AV_PROFILE_EAC3_DDP_ATMOS: u32 = 30;
pub const AV_PROFILE_TRUEHD_ATMOS: u32 = 30;
pub const AV_PROFILE_MPEG2_422: u32 = 0;
pub const AV_PROFILE_MPEG2_HIGH: u32 = 1;
pub const AV_PROFILE_MPEG2_SS: u32 = 2;
pub const AV_PROFILE_MPEG2_SNR_SCALABLE: u32 = 3;
pub const AV_PROFILE_MPEG2_MAIN: u32 = 4;
pub const AV_PROFILE_MPEG2_SIMPLE: u32 = 5;
pub const AV_PROFILE_H264_CONSTRAINED: u32 = 512;
pub const AV_PROFILE_H264_INTRA: u32 = 2048;
pub const AV_PROFILE_H264_BASELINE: u32 = 66;
pub const AV_PROFILE_H264_CONSTRAINED_BASELINE: u32 = 578;
pub const AV_PROFILE_H264_MAIN: u32 = 77;
pub const AV_PROFILE_H264_EXTENDED: u32 = 88;
pub const AV_PROFILE_H264_HIGH: u32 = 100;
pub const AV_PROFILE_H264_HIGH_10: u32 = 110;
pub const AV_PROFILE_H264_HIGH_10_INTRA: u32 = 2158;
pub const AV_PROFILE_H264_MULTIVIEW_HIGH: u32 = 118;
pub const AV_PROFILE_H264_HIGH_422: u32 = 122;
pub const AV_PROFILE_H264_HIGH_422_INTRA: u32 = 2170;
pub const AV_PROFILE_H264_STEREO_HIGH: u32 = 128;
pub const AV_PROFILE_H264_HIGH_444: u32 = 144;
pub const AV_PROFILE_H264_HIGH_444_PREDICTIVE: u32 = 244;
pub const AV_PROFILE_H264_HIGH_444_INTRA: u32 = 2292;
pub const AV_PROFILE_H264_CAVLC_444: u32 = 44;
pub const AV_PROFILE_VC1_SIMPLE: u32 = 0;
pub const AV_PROFILE_VC1_MAIN: u32 = 1;
pub const AV_PROFILE_VC1_COMPLEX: u32 = 2;
pub const AV_PROFILE_VC1_ADVANCED: u32 = 3;
pub const AV_PROFILE_MPEG4_SIMPLE: u32 = 0;
pub const AV_PROFILE_MPEG4_SIMPLE_SCALABLE: u32 = 1;
pub const AV_PROFILE_MPEG4_CORE: u32 = 2;
pub const AV_PROFILE_MPEG4_MAIN: u32 = 3;
pub const AV_PROFILE_MPEG4_N_BIT: u32 = 4;
pub const AV_PROFILE_MPEG4_SCALABLE_TEXTURE: u32 = 5;
pub const AV_PROFILE_MPEG4_SIMPLE_FACE_ANIMATION: u32 = 6;
pub const AV_PROFILE_MPEG4_BASIC_ANIMATED_TEXTURE: u32 = 7;
pub const AV_PROFILE_MPEG4_HYBRID: u32 = 8;
pub const AV_PROFILE_MPEG4_ADVANCED_REAL_TIME: u32 = 9;
pub const AV_PROFILE_MPEG4_CORE_SCALABLE: u32 = 10;
pub const AV_PROFILE_MPEG4_ADVANCED_CODING: u32 = 11;
pub const AV_PROFILE_MPEG4_ADVANCED_CORE: u32 = 12;
pub const AV_PROFILE_MPEG4_ADVANCED_SCALABLE_TEXTURE: u32 = 13;
pub const AV_PROFILE_MPEG4_SIMPLE_STUDIO: u32 = 14;
pub const AV_PROFILE_MPEG4_ADVANCED_SIMPLE: u32 = 15;
pub const AV_PROFILE_JPEG2000_CSTREAM_RESTRICTION_0: u32 = 1;
pub const AV_PROFILE_JPEG2000_CSTREAM_RESTRICTION_1: u32 = 2;
pub const AV_PROFILE_JPEG2000_CSTREAM_NO_RESTRICTION: u32 = 32768;
pub const AV_PROFILE_JPEG2000_DCINEMA_2K: u32 = 3;
pub const AV_PROFILE_JPEG2000_DCINEMA_4K: u32 = 4;
pub const AV_PROFILE_VP9_0: u32 = 0;
pub const AV_PROFILE_VP9_1: u32 = 1;
pub const AV_PROFILE_VP9_2: u32 = 2;
pub const AV_PROFILE_VP9_3: u32 = 3;
pub const AV_PROFILE_HEVC_MAIN: u32 = 1;
pub const AV_PROFILE_HEVC_MAIN_10: u32 = 2;
pub const AV_PROFILE_HEVC_MAIN_STILL_PICTURE: u32 = 3;
pub const AV_PROFILE_HEVC_REXT: u32 = 4;
pub const AV_PROFILE_HEVC_SCC: u32 = 9;
pub const AV_PROFILE_VVC_MAIN_10: u32 = 1;
pub const AV_PROFILE_VVC_MAIN_10_444: u32 = 33;
pub const AV_PROFILE_AV1_MAIN: u32 = 0;
pub const AV_PROFILE_AV1_HIGH: u32 = 1;
pub const AV_PROFILE_AV1_PROFESSIONAL: u32 = 2;
pub const AV_PROFILE_MJPEG_HUFFMAN_BASELINE_DCT: u32 = 192;
pub const AV_PROFILE_MJPEG_HUFFMAN_EXTENDED_SEQUENTIAL_DCT: u32 = 193;
pub const AV_PROFILE_MJPEG_HUFFMAN_PROGRESSIVE_DCT: u32 = 194;
pub const AV_PROFILE_MJPEG_HUFFMAN_LOSSLESS: u32 = 195;
pub const AV_PROFILE_MJPEG_JPEG_LS: u32 = 247;
pub const AV_PROFILE_SBC_MSBC: u32 = 1;
pub const AV_PROFILE_PRORES_PROXY: u32 = 0;
pub const AV_PROFILE_PRORES_LT: u32 = 1;
pub const AV_PROFILE_PRORES_STANDARD: u32 = 2;
pub const AV_PROFILE_PRORES_HQ: u32 = 3;
pub const AV_PROFILE_PRORES_4444: u32 = 4;
pub const AV_PROFILE_PRORES_XQ: u32 = 5;
pub const AV_PROFILE_ARIB_PROFILE_A: u32 = 0;
pub const AV_PROFILE_ARIB_PROFILE_C: u32 = 1;
pub const AV_PROFILE_KLVA_SYNC: u32 = 0;
pub const AV_PROFILE_KLVA_ASYNC: u32 = 1;
pub const AV_PROFILE_EVC_BASELINE: u32 = 0;
pub const AV_PROFILE_EVC_MAIN: u32 = 1;
pub const AV_LEVEL_UNKNOWN: i32 = -99;
pub const AV_PKT_FLAG_KEY: u32 = 1;
pub const AV_PKT_FLAG_CORRUPT: u32 = 2;
pub const AV_PKT_FLAG_DISCARD: u32 = 4;
pub const AV_PKT_FLAG_TRUSTED: u32 = 8;
pub const AV_PKT_FLAG_DISPOSABLE: u32 = 16;
pub const LIBAVCODEC_VERSION_MINOR: u32 = 5;
pub const LIBAVCODEC_VERSION_MICRO: u32 = 103;
pub const AV_CODEC_PROP_INTRA_ONLY: u32 = 1;
pub const AV_CODEC_PROP_LOSSY: u32 = 2;
pub const AV_CODEC_PROP_LOSSLESS: u32 = 4;
pub const AV_CODEC_PROP_REORDER: u32 = 8;
pub const AV_CODEC_PROP_FIELDS: u32 = 16;
pub const AV_CODEC_PROP_BITMAP_SUB: u32 = 65536;
pub const AV_CODEC_PROP_TEXT_SUB: u32 = 131072;
pub const AV_INPUT_BUFFER_MIN_SIZE: u32 = 16384;
pub const AV_CODEC_FLAG_UNALIGNED: u32 = 1;
pub const AV_CODEC_FLAG_QSCALE: u32 = 2;
pub const AV_CODEC_FLAG_4MV: u32 = 4;
pub const AV_CODEC_FLAG_OUTPUT_CORRUPT: u32 = 8;
pub const AV_CODEC_FLAG_QPEL: u32 = 16;
pub const AV_CODEC_FLAG_DROPCHANGED: u32 = 32;
pub const AV_CODEC_FLAG_RECON_FRAME: u32 = 64;
pub const AV_CODEC_FLAG_COPY_OPAQUE: u32 = 128;
pub const AV_CODEC_FLAG_FRAME_DURATION: u32 = 256;
pub const AV_CODEC_FLAG_PASS1: u32 = 512;
pub const AV_CODEC_FLAG_PASS2: u32 = 1024;
pub const AV_CODEC_FLAG_LOOP_FILTER: u32 = 2048;
pub const AV_CODEC_FLAG_GRAY: u32 = 8192;
pub const AV_CODEC_FLAG_PSNR: u32 = 32768;
pub const AV_CODEC_FLAG_INTERLACED_DCT: u32 = 262144;
pub const AV_CODEC_FLAG_LOW_DELAY: u32 = 524288;
pub const AV_CODEC_FLAG_GLOBAL_HEADER: u32 = 4194304;
pub const AV_CODEC_FLAG_BITEXACT: u32 = 8388608;
pub const AV_CODEC_FLAG_AC_PRED: u32 = 16777216;
pub const AV_CODEC_FLAG_INTERLACED_ME: u32 = 536870912;
pub const AV_CODEC_FLAG_CLOSED_GOP: u32 = 2147483648;
pub const AV_CODEC_FLAG2_FAST: u32 = 1;
pub const AV_CODEC_FLAG2_NO_OUTPUT: u32 = 4;
pub const AV_CODEC_FLAG2_LOCAL_HEADER: u32 = 8;
pub const AV_CODEC_FLAG2_CHUNKS: u32 = 32768;
pub const AV_CODEC_FLAG2_IGNORE_CROP: u32 = 65536;
pub const AV_CODEC_FLAG2_SHOW_ALL: u32 = 4194304;
pub const AV_CODEC_FLAG2_EXPORT_MVS: u32 = 268435456;
pub const AV_CODEC_FLAG2_SKIP_MANUAL: u32 = 536870912;
pub const AV_CODEC_FLAG2_RO_FLUSH_NOOP: u32 = 1073741824;
pub const AV_CODEC_FLAG2_ICC_PROFILES: u32 = 2147483648;
pub const AV_CODEC_EXPORT_DATA_MVS: u32 = 1;
pub const AV_CODEC_EXPORT_DATA_PRFT: u32 = 2;
pub const AV_CODEC_EXPORT_DATA_VIDEO_ENC_PARAMS: u32 = 4;
pub const AV_CODEC_EXPORT_DATA_FILM_GRAIN: u32 = 8;
pub const AV_GET_BUFFER_FLAG_REF: u32 = 1;
pub const AV_GET_ENCODE_BUFFER_FLAG_REF: u32 = 1;
pub const SLICE_FLAG_CODED_ORDER: u32 = 1;
pub const SLICE_FLAG_ALLOW_FIELD: u32 = 2;
pub const SLICE_FLAG_ALLOW_PLANE: u32 = 4;
pub const FF_CMP_SAD: u32 = 0;
pub const FF_CMP_SSE: u32 = 1;
pub const FF_CMP_SATD: u32 = 2;
pub const FF_CMP_DCT: u32 = 3;
pub const FF_CMP_PSNR: u32 = 4;
pub const FF_CMP_BIT: u32 = 5;
pub const FF_CMP_RD: u32 = 6;
pub const FF_CMP_ZERO: u32 = 7;
pub const FF_CMP_VSAD: u32 = 8;
pub const FF_CMP_VSSE: u32 = 9;
pub const FF_CMP_NSSE: u32 = 10;
pub const FF_CMP_W53: u32 = 11;
pub const FF_CMP_W97: u32 = 12;
pub const FF_CMP_DCTMAX: u32 = 13;
pub const FF_CMP_DCT264: u32 = 14;
pub const FF_CMP_MEDIAN_SAD: u32 = 15;
pub const FF_CMP_CHROMA: u32 = 256;
pub const FF_MB_DECISION_SIMPLE: u32 = 0;
pub const FF_MB_DECISION_BITS: u32 = 1;
pub const FF_MB_DECISION_RD: u32 = 2;
pub const FF_COMPRESSION_DEFAULT: i32 = -1;
pub const FF_BUG_AUTODETECT: u32 = 1;
pub const FF_BUG_XVID_ILACE: u32 = 4;
pub const FF_BUG_UMP4: u32 = 8;
pub const FF_BUG_NO_PADDING: u32 = 16;
pub const FF_BUG_AMV: u32 = 32;
pub const FF_BUG_QPEL_CHROMA: u32 = 64;
pub const FF_BUG_STD_QPEL: u32 = 128;
pub const FF_BUG_QPEL_CHROMA2: u32 = 256;
pub const FF_BUG_DIRECT_BLOCKSIZE: u32 = 512;
pub const FF_BUG_EDGE: u32 = 1024;
pub const FF_BUG_HPEL_CHROMA: u32 = 2048;
pub const FF_BUG_DC_CLIP: u32 = 4096;
pub const FF_BUG_MS: u32 = 8192;
pub const FF_BUG_TRUNCATED: u32 = 16384;
pub const FF_BUG_IEDGE: u32 = 32768;
pub const FF_EC_GUESS_MVS: u32 = 1;
pub const FF_EC_DEBLOCK: u32 = 2;
pub const FF_EC_FAVOR_INTER: u32 = 256;
pub const FF_DEBUG_PICT_INFO: u32 = 1;
pub const FF_DEBUG_RC: u32 = 2;
pub const FF_DEBUG_BITSTREAM: u32 = 4;
pub const FF_DEBUG_MB_TYPE: u32 = 8;
pub const FF_DEBUG_QP: u32 = 16;
pub const FF_DEBUG_DCT_COEFF: u32 = 64;
pub const FF_DEBUG_SKIP: u32 = 128;
pub const FF_DEBUG_STARTCODE: u32 = 256;
pub const FF_DEBUG_ER: u32 = 1024;
pub const FF_DEBUG_MMCO: u32 = 2048;
pub const FF_DEBUG_BUGS: u32 = 4096;
pub const FF_DEBUG_BUFFERS: u32 = 32768;
pub const FF_DEBUG_THREADS: u32 = 65536;
pub const FF_DEBUG_GREEN_MD: u32 = 8388608;
pub const FF_DEBUG_NOMC: u32 = 16777216;
pub const FF_DCT_AUTO: u32 = 0;
pub const FF_DCT_FASTINT: u32 = 1;
pub const FF_DCT_INT: u32 = 2;
pub const FF_DCT_MMX: u32 = 3;
pub const FF_DCT_ALTIVEC: u32 = 5;
pub const FF_DCT_FAAN: u32 = 6;
pub const FF_IDCT_AUTO: u32 = 0;
pub const FF_IDCT_INT: u32 = 1;
pub const FF_IDCT_SIMPLE: u32 = 2;
pub const FF_IDCT_SIMPLEMMX: u32 = 3;
pub const FF_IDCT_ARM: u32 = 7;
pub const FF_IDCT_ALTIVEC: u32 = 8;
pub const FF_IDCT_SIMPLEARM: u32 = 10;
pub const FF_IDCT_XVID: u32 = 14;
pub const FF_IDCT_SIMPLEARMV5TE: u32 = 16;
pub const FF_IDCT_SIMPLEARMV6: u32 = 17;
pub const FF_IDCT_FAAN: u32 = 20;
pub const FF_IDCT_SIMPLENEON: u32 = 22;
pub const FF_IDCT_SIMPLEAUTO: u32 = 128;
pub const FF_THREAD_FRAME: u32 = 1;
pub const FF_THREAD_SLICE: u32 = 2;
pub const FF_PROFILE_UNKNOWN: i32 = -99;
pub const FF_PROFILE_RESERVED: i32 = -100;
pub const FF_PROFILE_AAC_MAIN: u32 = 0;
pub const FF_PROFILE_AAC_LOW: u32 = 1;
pub const FF_PROFILE_AAC_SSR: u32 = 2;
pub const FF_PROFILE_AAC_LTP: u32 = 3;
pub const FF_PROFILE_AAC_HE: u32 = 4;
pub const FF_PROFILE_AAC_HE_V2: u32 = 28;
pub const FF_PROFILE_AAC_LD: u32 = 22;
pub const FF_PROFILE_AAC_ELD: u32 = 38;
pub const FF_PROFILE_MPEG2_AAC_LOW: u32 = 128;
pub const FF_PROFILE_MPEG2_AAC_HE: u32 = 131;
pub const FF_PROFILE_DNXHD: u32 = 0;
pub const FF_PROFILE_DNXHR_LB: u32 = 1;
pub const FF_PROFILE_DNXHR_SQ: u32 = 2;
pub const FF_PROFILE_DNXHR_HQ: u32 = 3;
pub const FF_PROFILE_DNXHR_HQX: u32 = 4;
pub const FF_PROFILE_DNXHR_444: u32 = 5;
pub const FF_PROFILE_DTS: u32 = 20;
pub const FF_PROFILE_DTS_ES: u32 = 30;
pub const FF_PROFILE_DTS_96_24: u32 = 40;
pub const FF_PROFILE_DTS_HD_HRA: u32 = 50;
pub const FF_PROFILE_DTS_HD_MA: u32 = 60;
pub const FF_PROFILE_DTS_EXPRESS: u32 = 70;
pub const FF_PROFILE_DTS_HD_MA_X: u32 = 61;
pub const FF_PROFILE_DTS_HD_MA_X_IMAX: u32 = 62;
pub const FF_PROFILE_EAC3_DDP_ATMOS: u32 = 30;
pub const FF_PROFILE_TRUEHD_ATMOS: u32 = 30;
pub const FF_PROFILE_MPEG2_422: u32 = 0;
pub const FF_PROFILE_MPEG2_HIGH: u32 = 1;
pub const FF_PROFILE_MPEG2_SS: u32 = 2;
pub const FF_PROFILE_MPEG2_SNR_SCALABLE: u32 = 3;
pub const FF_PROFILE_MPEG2_MAIN: u32 = 4;
pub const FF_PROFILE_MPEG2_SIMPLE: u32 = 5;
pub const FF_PROFILE_H264_CONSTRAINED: u32 = 512;
pub const FF_PROFILE_H264_INTRA: u32 = 2048;
pub const FF_PROFILE_H264_BASELINE: u32 = 66;
pub const FF_PROFILE_H264_CONSTRAINED_BASELINE: u32 = 578;
pub const FF_PROFILE_H264_MAIN: u32 = 77;
pub const FF_PROFILE_H264_EXTENDED: u32 = 88;
pub const FF_PROFILE_H264_HIGH: u32 = 100;
pub const FF_PROFILE_H264_HIGH_10: u32 = 110;
pub const FF_PROFILE_H264_HIGH_10_INTRA: u32 = 2158;
pub const FF_PROFILE_H264_MULTIVIEW_HIGH: u32 = 118;
pub const FF_PROFILE_H264_HIGH_422: u32 = 122;
pub const FF_PROFILE_H264_HIGH_422_INTRA: u32 = 2170;
pub const FF_PROFILE_H264_STEREO_HIGH: u32 = 128;
pub const FF_PROFILE_H264_HIGH_444: u32 = 144;
pub const FF_PROFILE_H264_HIGH_444_PREDICTIVE: u32 = 244;
pub const FF_PROFILE_H264_HIGH_444_INTRA: u32 = 2292;
pub const FF_PROFILE_H264_CAVLC_444: u32 = 44;
pub const FF_PROFILE_VC1_SIMPLE: u32 = 0;
pub const FF_PROFILE_VC1_MAIN: u32 = 1;
pub const FF_PROFILE_VC1_COMPLEX: u32 = 2;
pub const FF_PROFILE_VC1_ADVANCED: u32 = 3;
pub const FF_PROFILE_MPEG4_SIMPLE: u32 = 0;
pub const FF_PROFILE_MPEG4_SIMPLE_SCALABLE: u32 = 1;
pub const FF_PROFILE_MPEG4_CORE: u32 = 2;
pub const FF_PROFILE_MPEG4_MAIN: u32 = 3;
pub const FF_PROFILE_MPEG4_N_BIT: u32 = 4;
pub const FF_PROFILE_MPEG4_SCALABLE_TEXTURE: u32 = 5;
pub const FF_PROFILE_MPEG4_SIMPLE_FACE_ANIMATION: u32 = 6;
pub const FF_PROFILE_MPEG4_BASIC_ANIMATED_TEXTURE: u32 = 7;
pub const FF_PROFILE_MPEG4_HYBRID: u32 = 8;
pub const FF_PROFILE_MPEG4_ADVANCED_REAL_TIME: u32 = 9;
pub const FF_PROFILE_MPEG4_CORE_SCALABLE: u32 = 10;
pub const FF_PROFILE_MPEG4_ADVANCED_CODING: u32 = 11;
pub const FF_PROFILE_MPEG4_ADVANCED_CORE: u32 = 12;
pub const FF_PROFILE_MPEG4_ADVANCED_SCALABLE_TEXTURE: u32 = 13;
pub const FF_PROFILE_MPEG4_SIMPLE_STUDIO: u32 = 14;
pub const FF_PROFILE_MPEG4_ADVANCED_SIMPLE: u32 = 15;
pub const FF_PROFILE_JPEG2000_CSTREAM_RESTRICTION_0: u32 = 1;
pub const FF_PROFILE_JPEG2000_CSTREAM_RESTRICTION_1: u32 = 2;
pub const FF_PROFILE_JPEG2000_CSTREAM_NO_RESTRICTION: u32 = 32768;
pub const FF_PROFILE_JPEG2000_DCINEMA_2K: u32 = 3;
pub const FF_PROFILE_JPEG2000_DCINEMA_4K: u32 = 4;
pub const FF_PROFILE_VP9_0: u32 = 0;
pub const FF_PROFILE_VP9_1: u32 = 1;
pub const FF_PROFILE_VP9_2: u32 = 2;
pub const FF_PROFILE_VP9_3: u32 = 3;
pub const FF_PROFILE_HEVC_MAIN: u32 = 1;
pub const FF_PROFILE_HEVC_MAIN_10: u32 = 2;
pub const FF_PROFILE_HEVC_MAIN_STILL_PICTURE: u32 = 3;
pub const FF_PROFILE_HEVC_REXT: u32 = 4;
pub const FF_PROFILE_HEVC_SCC: u32 = 9;
pub const FF_PROFILE_VVC_MAIN_10: u32 = 1;
pub const FF_PROFILE_VVC_MAIN_10_444: u32 = 33;
pub const FF_PROFILE_AV1_MAIN: u32 = 0;
pub const FF_PROFILE_AV1_HIGH: u32 = 1;
pub const FF_PROFILE_AV1_PROFESSIONAL: u32 = 2;
pub const FF_PROFILE_MJPEG_HUFFMAN_BASELINE_DCT: u32 = 192;
pub const FF_PROFILE_MJPEG_HUFFMAN_EXTENDED_SEQUENTIAL_DCT: u32 = 193;
pub const FF_PROFILE_MJPEG_HUFFMAN_PROGRESSIVE_DCT: u32 = 194;
pub const FF_PROFILE_MJPEG_HUFFMAN_LOSSLESS: u32 = 195;
pub const FF_PROFILE_MJPEG_JPEG_LS: u32 = 247;
pub const FF_PROFILE_SBC_MSBC: u32 = 1;
pub const FF_PROFILE_PRORES_PROXY: u32 = 0;
pub const FF_PROFILE_PRORES_LT: u32 = 1;
pub const FF_PROFILE_PRORES_STANDARD: u32 = 2;
pub const FF_PROFILE_PRORES_HQ: u32 = 3;
pub const FF_PROFILE_PRORES_4444: u32 = 4;
pub const FF_PROFILE_PRORES_XQ: u32 = 5;
pub const FF_PROFILE_ARIB_PROFILE_A: u32 = 0;
pub const FF_PROFILE_ARIB_PROFILE_C: u32 = 1;
pub const FF_PROFILE_KLVA_SYNC: u32 = 0;
pub const FF_PROFILE_KLVA_ASYNC: u32 = 1;
pub const FF_PROFILE_EVC_BASELINE: u32 = 0;
pub const FF_PROFILE_EVC_MAIN: u32 = 1;
pub const FF_LEVEL_UNKNOWN: i32 = -99;
pub const FF_CODEC_PROPERTY_LOSSLESS: u32 = 1;
pub const FF_CODEC_PROPERTY_CLOSED_CAPTIONS: u32 = 2;
pub const FF_CODEC_PROPERTY_FILM_GRAIN: u32 = 4;
pub const FF_SUB_CHARENC_MODE_DO_NOTHING: i32 = -1;
pub const FF_SUB_CHARENC_MODE_AUTOMATIC: u32 = 0;
pub const FF_SUB_CHARENC_MODE_PRE_DECODER: u32 = 1;
pub const FF_SUB_CHARENC_MODE_IGNORE: u32 = 2;
pub const AV_HWACCEL_CODEC_CAP_EXPERIMENTAL: u32 = 512;
pub const AV_HWACCEL_FLAG_IGNORE_LEVEL: u32 = 1;
pub const AV_HWACCEL_FLAG_ALLOW_HIGH_DEPTH: u32 = 2;
pub const AV_HWACCEL_FLAG_ALLOW_PROFILE_MISMATCH: u32 = 4;
pub const AV_HWACCEL_FLAG_UNSAFE_OUTPUT: u32 = 8;
pub const AV_SUBTITLE_FLAG_FORCED: u32 = 1;
pub const AV_PARSER_PTS_NB: u32 = 4;
pub const PARSER_FLAG_COMPLETE_FRAMES: u32 = 1;
pub const PARSER_FLAG_ONCE: u32 = 2;
pub const PARSER_FLAG_FETCHED_OFFSET: u32 = 4;
pub const PARSER_FLAG_USE_CODEC_TS: u32 = 4096;
pub type intmax_t = ::std::os::raw::c_longlong;
pub type uintmax_t = ::std::os::raw::c_ulonglong;
pub type time_t = ::std::os::raw::c_longlong;
pub type suseconds_t = ::std::os::raw::c_longlong;
#[repr(C)]
#[derive(Debug, Default, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct timeval {
    pub tv_sec: time_t,
    pub tv_usec: suseconds_t,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct timespec {
    pub tv_sec: time_t,
    pub tv_nsec: ::std::os::raw::c_long,
}
#[repr(C)]
#[derive(Debug, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct iovec {
    pub iov_base: *mut ::std::os::raw::c_void,
    pub iov_len: usize,
}
impl Default for iovec {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub type int_fast8_t = i8;
pub type int_fast64_t = i64;
pub type int_least8_t = i8;
pub type int_least16_t = i16;
pub type int_least32_t = i32;
pub type int_least64_t = i64;
pub type uint_fast8_t = u8;
pub type uint_fast64_t = u64;
pub type uint_least8_t = u8;
pub type uint_least16_t = u16;
pub type uint_least32_t = u32;
pub type uint_least64_t = u64;
pub type int_fast16_t = i16;
pub type int_fast32_t = i32;
pub type uint_fast16_t = u16;
pub type uint_fast32_t = u32;
pub const AVSampleFormat_AV_SAMPLE_FMT_NONE: AVSampleFormat = -1;
#[doc = "< unsigned 8 bits"]
pub const AVSampleFormat_AV_SAMPLE_FMT_U8: AVSampleFormat = 0;
#[doc = "< signed 16 bits"]
pub const AVSampleFormat_AV_SAMPLE_FMT_S16: AVSampleFormat = 1;
#[doc = "< signed 32 bits"]
pub const AVSampleFormat_AV_SAMPLE_FMT_S32: AVSampleFormat = 2;
#[doc = "< float"]
pub const AVSampleFormat_AV_SAMPLE_FMT_FLT: AVSampleFormat = 3;
#[doc = "< double"]
pub const AVSampleFormat_AV_SAMPLE_FMT_DBL: AVSampleFormat = 4;
#[doc = "< unsigned 8 bits, planar"]
pub const AVSampleFormat_AV_SAMPLE_FMT_U8P: AVSampleFormat = 5;
#[doc = "< signed 16 bits, planar"]
pub const AVSampleFormat_AV_SAMPLE_FMT_S16P: AVSampleFormat = 6;
#[doc = "< signed 32 bits, planar"]
pub const AVSampleFormat_AV_SAMPLE_FMT_S32P: AVSampleFormat = 7;
#[doc = "< float, planar"]
pub const AVSampleFormat_AV_SAMPLE_FMT_FLTP: AVSampleFormat = 8;
#[doc = "< double, planar"]
pub const AVSampleFormat_AV_SAMPLE_FMT_DBLP: AVSampleFormat = 9;
#[doc = "< signed 64 bits"]
pub const AVSampleFormat_AV_SAMPLE_FMT_S64: AVSampleFormat = 10;
#[doc = "< signed 64 bits, planar"]
pub const AVSampleFormat_AV_SAMPLE_FMT_S64P: AVSampleFormat = 11;
#[doc = "< Number of sample formats. DO NOT USE if linking dynamically"]
pub const AVSampleFormat_AV_SAMPLE_FMT_NB: AVSampleFormat = 12;
#[doc = " Audio sample formats\n\n - The data described by the sample format is always in native-endian order.\n   Sample values can be expressed by native C types, hence the lack of a signed\n   24-bit sample format even though it is a common raw audio data format.\n\n - The floating-point formats are based on full volume being in the range\n   [-1.0, 1.0]. Any values outside this range are beyond full volume level.\n\n - The data layout as used in av_samples_fill_arrays() and elsewhere in FFmpeg\n   (such as AVFrame in libavcodec) is as follows:\n\n @par\n For planar sample formats, each audio channel is in a separate data plane,\n and linesize is the buffer size, in bytes, for a single plane. All data\n planes must be the same size. For packed sample formats, only the first data\n plane is used, and samples for each channel are interleaved. In this case,\n linesize is the buffer size, in bytes, for the 1 plane.\n"]
pub type AVSampleFormat = ::std::os::raw::c_int;
extern "C" {
    #[doc = " Return the name of sample_fmt, or NULL if sample_fmt is not\n recognized."]
    pub fn av_get_sample_fmt_name(sample_fmt: AVSampleFormat) -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Return a sample format corresponding to name, or AV_SAMPLE_FMT_NONE\n on error."]
    pub fn av_get_sample_fmt(name: *const ::std::os::raw::c_char) -> AVSampleFormat;
}
extern "C" {
    #[doc = " Return the planar<->packed alternative form of the given sample format, or\n AV_SAMPLE_FMT_NONE on error. If the passed sample_fmt is already in the\n requested planar/packed format, the format returned is the same as the\n input."]
    pub fn av_get_alt_sample_fmt(
        sample_fmt: AVSampleFormat,
        planar: ::std::os::raw::c_int,
    ) -> AVSampleFormat;
}
extern "C" {
    #[doc = " Get the packed alternative form of the given sample format.\n\n If the passed sample_fmt is already in packed format, the format returned is\n the same as the input.\n\n @return  the packed alternative form of the given sample format or\nAV_SAMPLE_FMT_NONE on error."]
    pub fn av_get_packed_sample_fmt(sample_fmt: AVSampleFormat) -> AVSampleFormat;
}
extern "C" {
    #[doc = " Get the planar alternative form of the given sample format.\n\n If the passed sample_fmt is already in planar format, the format returned is\n the same as the input.\n\n @return  the planar alternative form of the given sample format or\nAV_SAMPLE_FMT_NONE on error."]
    pub fn av_get_planar_sample_fmt(sample_fmt: AVSampleFormat) -> AVSampleFormat;
}
extern "C" {
    #[doc = " Generate a string corresponding to the sample format with\n sample_fmt, or a header if sample_fmt is negative.\n\n @param buf the buffer where to write the string\n @param buf_size the size of buf\n @param sample_fmt the number of the sample format to print the\n corresponding info string, or a negative value to print the\n corresponding header.\n @return the pointer to the filled buffer or NULL if sample_fmt is\n unknown or in case of other errors"]
    pub fn av_get_sample_fmt_string(
        buf: *mut ::std::os::raw::c_char,
        buf_size: ::std::os::raw::c_int,
        sample_fmt: AVSampleFormat,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Return number of bytes per sample.\n\n @param sample_fmt the sample format\n @return number of bytes per sample or zero if unknown for the given\n sample format"]
    pub fn av_get_bytes_per_sample(sample_fmt: AVSampleFormat) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Check if the sample format is planar.\n\n @param sample_fmt the sample format to inspect\n @return 1 if the sample format is planar, 0 if it is interleaved"]
    pub fn av_sample_fmt_is_planar(sample_fmt: AVSampleFormat) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get the required buffer size for the given audio parameters.\n\n @param[out] linesize calculated linesize, may be NULL\n @param nb_channels   the number of channels\n @param nb_samples    the number of samples in a single channel\n @param sample_fmt    the sample format\n @param align         buffer size alignment (0 = default, 1 = no alignment)\n @return              required buffer size, or negative error code on failure"]
    pub fn av_samples_get_buffer_size(
        linesize: *mut ::std::os::raw::c_int,
        nb_channels: ::std::os::raw::c_int,
        nb_samples: ::std::os::raw::c_int,
        sample_fmt: AVSampleFormat,
        align: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Fill plane data pointers and linesize for samples with sample\n format sample_fmt.\n\n The audio_data array is filled with the pointers to the samples data planes:\n for planar, set the start point of each channel's data within the buffer,\n for packed, set the start point of the entire buffer only.\n\n The value pointed to by linesize is set to the aligned size of each\n channel's data buffer for planar layout, or to the aligned size of the\n buffer for all channels for packed layout.\n\n The buffer in buf must be big enough to contain all the samples\n (use av_samples_get_buffer_size() to compute its minimum size),\n otherwise the audio_data pointers will point to invalid data.\n\n @see enum AVSampleFormat\n The documentation for AVSampleFormat describes the data layout.\n\n @param[out] audio_data  array to be filled with the pointer for each channel\n @param[out] linesize    calculated linesize, may be NULL\n @param buf              the pointer to a buffer containing the samples\n @param nb_channels      the number of channels\n @param nb_samples       the number of samples in a single channel\n @param sample_fmt       the sample format\n @param align            buffer size alignment (0 = default, 1 = no alignment)\n @return                 minimum size in bytes required for the buffer on success,\n                         or a negative error code on failure"]
    pub fn av_samples_fill_arrays(
        audio_data: *mut *mut u8,
        linesize: *mut ::std::os::raw::c_int,
        buf: *const u8,
        nb_channels: ::std::os::raw::c_int,
        nb_samples: ::std::os::raw::c_int,
        sample_fmt: AVSampleFormat,
        align: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Allocate a samples buffer for nb_samples samples, and fill data pointers and\n linesize accordingly.\n The allocated samples buffer can be freed by using av_freep(&audio_data[0])\n Allocated data will be initialized to silence.\n\n @see enum AVSampleFormat\n The documentation for AVSampleFormat describes the data layout.\n\n @param[out] audio_data  array to be filled with the pointer for each channel\n @param[out] linesize    aligned size for audio buffer(s), may be NULL\n @param nb_channels      number of audio channels\n @param nb_samples       number of samples per channel\n @param sample_fmt       the sample format\n @param align            buffer size alignment (0 = default, 1 = no alignment)\n @return                 >=0 on success or a negative error code on failure\n @todo return the size of the allocated buffer in case of success at the next bump\n @see av_samples_fill_arrays()\n @see av_samples_alloc_array_and_samples()"]
    pub fn av_samples_alloc(
        audio_data: *mut *mut u8,
        linesize: *mut ::std::os::raw::c_int,
        nb_channels: ::std::os::raw::c_int,
        nb_samples: ::std::os::raw::c_int,
        sample_fmt: AVSampleFormat,
        align: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Allocate a data pointers array, samples buffer for nb_samples\n samples, and fill data pointers and linesize accordingly.\n\n This is the same as av_samples_alloc(), but also allocates the data\n pointers array.\n\n @see av_samples_alloc()"]
    pub fn av_samples_alloc_array_and_samples(
        audio_data: *mut *mut *mut u8,
        linesize: *mut ::std::os::raw::c_int,
        nb_channels: ::std::os::raw::c_int,
        nb_samples: ::std::os::raw::c_int,
        sample_fmt: AVSampleFormat,
        align: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Copy samples from src to dst.\n\n @param dst destination array of pointers to data planes\n @param src source array of pointers to data planes\n @param dst_offset offset in samples at which the data will be written to dst\n @param src_offset offset in samples at which the data will be read from src\n @param nb_samples number of samples to be copied\n @param nb_channels number of audio channels\n @param sample_fmt audio sample format"]
    pub fn av_samples_copy(
        dst: *const *mut u8,
        src: *const *mut u8,
        dst_offset: ::std::os::raw::c_int,
        src_offset: ::std::os::raw::c_int,
        nb_samples: ::std::os::raw::c_int,
        nb_channels: ::std::os::raw::c_int,
        sample_fmt: AVSampleFormat,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Fill an audio buffer with silence.\n\n @param audio_data  array of pointers to data planes\n @param offset      offset in samples at which to start filling\n @param nb_samples  number of samples to fill\n @param nb_channels number of audio channels\n @param sample_fmt  audio sample format"]
    pub fn av_samples_set_silence(
        audio_data: *const *mut u8,
        offset: ::std::os::raw::c_int,
        nb_samples: ::std::os::raw::c_int,
        nb_channels: ::std::os::raw::c_int,
        sample_fmt: AVSampleFormat,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Return the LIBAVUTIL_VERSION_INT constant."]
    pub fn avutil_version() -> ::std::os::raw::c_uint;
}
extern "C" {
    #[doc = " Return an informative version string. This usually is the actual release\n version number or a git commit description. This string has no fixed format\n and can change any time. It should never be parsed by code."]
    pub fn av_version_info() -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Return the libavutil build-time configuration."]
    pub fn avutil_configuration() -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Return the libavutil license."]
    pub fn avutil_license() -> *const ::std::os::raw::c_char;
}
#[doc = "< Usually treated as AVMEDIA_TYPE_DATA"]
pub const AVMediaType_AVMEDIA_TYPE_UNKNOWN: AVMediaType = -1;
pub const AVMediaType_AVMEDIA_TYPE_VIDEO: AVMediaType = 0;
pub const AVMediaType_AVMEDIA_TYPE_AUDIO: AVMediaType = 1;
#[doc = "< Opaque data information usually continuous"]
pub const AVMediaType_AVMEDIA_TYPE_DATA: AVMediaType = 2;
pub const AVMediaType_AVMEDIA_TYPE_SUBTITLE: AVMediaType = 3;
#[doc = "< Opaque data information usually sparse"]
pub const AVMediaType_AVMEDIA_TYPE_ATTACHMENT: AVMediaType = 4;
pub const AVMediaType_AVMEDIA_TYPE_NB: AVMediaType = 5;
#[doc = " @addtogroup lavu_media Media Type\n @brief Media Type"]
pub type AVMediaType = ::std::os::raw::c_int;
extern "C" {
    #[doc = " Return a string describing the media_type enum, NULL if media_type\n is unknown."]
    pub fn av_get_media_type_string(media_type: AVMediaType) -> *const ::std::os::raw::c_char;
}
#[doc = "< Undefined"]
pub const AVPictureType_AV_PICTURE_TYPE_NONE: AVPictureType = 0;
#[doc = "< Intra"]
pub const AVPictureType_AV_PICTURE_TYPE_I: AVPictureType = 1;
#[doc = "< Predicted"]
pub const AVPictureType_AV_PICTURE_TYPE_P: AVPictureType = 2;
#[doc = "< Bi-dir predicted"]
pub const AVPictureType_AV_PICTURE_TYPE_B: AVPictureType = 3;
#[doc = "< S(GMC)-VOP MPEG-4"]
pub const AVPictureType_AV_PICTURE_TYPE_S: AVPictureType = 4;
#[doc = "< Switching Intra"]
pub const AVPictureType_AV_PICTURE_TYPE_SI: AVPictureType = 5;
#[doc = "< Switching Predicted"]
pub const AVPictureType_AV_PICTURE_TYPE_SP: AVPictureType = 6;
#[doc = "< BI type"]
pub const AVPictureType_AV_PICTURE_TYPE_BI: AVPictureType = 7;
#[doc = " @}\n @}\n @defgroup lavu_picture Image related\n\n AVPicture types, pixel formats and basic image planes manipulation.\n\n @{"]
pub type AVPictureType = ::std::os::raw::c_uint;
extern "C" {
    #[doc = " Return a single letter to describe the given picture type\n pict_type.\n\n @param[in] pict_type the picture type @return a single character\n representing the picture type, '?' if pict_type is unknown"]
    pub fn av_get_picture_type_char(pict_type: AVPictureType) -> ::std::os::raw::c_char;
}
extern "C" {
    pub static mut errno: ::std::os::raw::c_int;
}
pub type wchar_t = ::std::os::raw::c_int;
#[repr(C)]
#[repr(align(16))]
#[derive(Debug, Default, Copy, Clone, PartialOrd, PartialEq)]
pub struct max_align_t {
    pub __clang_max_align_nonce1: ::std::os::raw::c_longlong,
    pub __bindgen_padding_0: u64,
    pub __clang_max_align_nonce2: u128,
}
pub type __wasi_size_t = ::std::os::raw::c_ulong;
#[doc = " Non-negative file size or length of a region within a file."]
pub type __wasi_filesize_t = u64;
#[doc = " Timestamp in nanoseconds."]
pub type __wasi_timestamp_t = u64;
#[doc = " Identifiers for clocks."]
pub type __wasi_clockid_t = u32;
#[doc = " Error codes returned by functions.\n Not all of these error codes are returned by the functions provided by this\n API; some are used in higher-level library layers, and others are provided\n merely for alignment with POSIX."]
pub type __wasi_errno_t = u16;
#[doc = " File descriptor rights, determining which actions may be performed."]
pub type __wasi_rights_t = u64;
#[doc = " A file descriptor handle."]
pub type __wasi_fd_t = ::std::os::raw::c_int;
#[doc = " A region of memory for scatter/gather reads."]
#[repr(C)]
#[derive(Debug, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct __wasi_iovec_t {
    #[doc = " The address of the buffer to be filled."]
    pub buf: *mut u8,
    #[doc = " The length of the buffer to be filled."]
    pub buf_len: __wasi_size_t,
}
impl Default for __wasi_iovec_t {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = " A region of memory for scatter/gather writes."]
#[repr(C)]
#[derive(Debug, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct __wasi_ciovec_t {
    #[doc = " The address of the buffer to be written."]
    pub buf: *const u8,
    #[doc = " The length of the buffer to be written."]
    pub buf_len: __wasi_size_t,
}
impl Default for __wasi_ciovec_t {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = " Relative offset within a file."]
pub type __wasi_filedelta_t = i64;
#[doc = " The position relative to which to set the offset of the file descriptor."]
pub type __wasi_whence_t = u8;
#[doc = " A reference to the offset of a directory entry.\n\n The value 0 signifies the start of the directory."]
pub type __wasi_dircookie_t = u64;
#[doc = " The type for the `dirent::d_namlen` field of `dirent` struct."]
pub type __wasi_dirnamlen_t = u32;
#[doc = " File serial number that is unique within its file system."]
pub type __wasi_inode_t = u64;
#[doc = " The type of a file descriptor or file."]
pub type __wasi_filetype_t = u8;
#[doc = " A directory entry."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct __wasi_dirent_t {
    #[doc = " The offset of the next directory entry stored in this directory."]
    pub d_next: __wasi_dircookie_t,
    #[doc = " The serial number of the file referred to by this directory entry."]
    pub d_ino: __wasi_inode_t,
    #[doc = " The length of the name of the directory entry."]
    pub d_namlen: __wasi_dirnamlen_t,
    #[doc = " The type of the file referred to by this directory entry."]
    pub d_type: __wasi_filetype_t,
}
#[doc = " File or memory access pattern advisory information."]
pub type __wasi_advice_t = u8;
#[doc = " File descriptor flags."]
pub type __wasi_fdflags_t = u16;
#[doc = " File descriptor attributes."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct __wasi_fdstat_t {
    #[doc = " File type."]
    pub fs_filetype: __wasi_filetype_t,
    #[doc = " File descriptor flags."]
    pub fs_flags: __wasi_fdflags_t,
    #[doc = " Rights that apply to this file descriptor."]
    pub fs_rights_base: __wasi_rights_t,
    #[doc = " Maximum set of rights that may be installed on new file descriptors that\n are created through this file descriptor, e.g., through `path_open`."]
    pub fs_rights_inheriting: __wasi_rights_t,
}
#[doc = " Identifier for a device containing a file system. Can be used in combination\n with `inode` to uniquely identify a file or directory in the filesystem."]
pub type __wasi_device_t = u64;
#[doc = " Which file time attributes to adjust."]
pub type __wasi_fstflags_t = u16;
#[doc = " Flags determining the method of how paths are resolved."]
pub type __wasi_lookupflags_t = u32;
#[doc = " Open flags used by `path_open`."]
pub type __wasi_oflags_t = u16;
#[doc = " Number of hard links to an inode."]
pub type __wasi_linkcount_t = u64;
#[doc = " File attributes."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct __wasi_filestat_t {
    #[doc = " Device ID of device containing the file."]
    pub dev: __wasi_device_t,
    #[doc = " File serial number."]
    pub ino: __wasi_inode_t,
    #[doc = " File type."]
    pub filetype: __wasi_filetype_t,
    #[doc = " Number of hard links to the file."]
    pub nlink: __wasi_linkcount_t,
    #[doc = " For regular files, the file size in bytes. For symbolic links, the length in bytes of the pathname contained in the symbolic link."]
    pub size: __wasi_filesize_t,
    #[doc = " Last data access timestamp."]
    pub atim: __wasi_timestamp_t,
    #[doc = " Last data modification timestamp."]
    pub mtim: __wasi_timestamp_t,
    #[doc = " Last file status change timestamp."]
    pub ctim: __wasi_timestamp_t,
}
#[doc = " User-provided value that may be attached to objects that is retained when\n extracted from the implementation."]
pub type __wasi_userdata_t = u64;
#[doc = " Type of a subscription to an event or its occurrence."]
pub type __wasi_eventtype_t = u8;
#[doc = " The state of the file descriptor subscribed to with\n `eventtype::fd_read` or `eventtype::fd_write`."]
pub type __wasi_eventrwflags_t = u16;
#[doc = " The contents of an `event` when type is `eventtype::fd_read` or\n `eventtype::fd_write`."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct __wasi_event_fd_readwrite_t {
    #[doc = " The number of bytes available for reading or writing."]
    pub nbytes: __wasi_filesize_t,
    #[doc = " The state of the file descriptor."]
    pub flags: __wasi_eventrwflags_t,
}
#[doc = " An event that occurred."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct __wasi_event_t {
    #[doc = " User-provided value that got attached to `subscription::userdata`."]
    pub userdata: __wasi_userdata_t,
    #[doc = " If non-zero, an error that occurred while processing the subscription request."]
    pub error: __wasi_errno_t,
    #[doc = " The type of event that occured"]
    pub type_: __wasi_eventtype_t,
    #[doc = " The contents of the event, if it is an `eventtype::fd_read` or\n `eventtype::fd_write`. `eventtype::clock` events ignore this field."]
    pub fd_readwrite: __wasi_event_fd_readwrite_t,
}
#[doc = " Flags determining how to interpret the timestamp provided in\n `subscription_clock::timeout`."]
pub type __wasi_subclockflags_t = u16;
#[doc = " The contents of a `subscription` when type is `eventtype::clock`."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct __wasi_subscription_clock_t {
    #[doc = " The clock against which to compare the timestamp."]
    pub id: __wasi_clockid_t,
    #[doc = " The absolute or relative timestamp."]
    pub timeout: __wasi_timestamp_t,
    #[doc = " The amount of time that the implementation may wait additionally\n to coalesce with other events."]
    pub precision: __wasi_timestamp_t,
    #[doc = " Flags specifying whether the timeout is absolute or relative"]
    pub flags: __wasi_subclockflags_t,
}
#[doc = " The contents of a `subscription` when type is type is\n `eventtype::fd_read` or `eventtype::fd_write`."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct __wasi_subscription_fd_readwrite_t {
    #[doc = " The file descriptor on which to wait for it to become ready for reading or writing."]
    pub file_descriptor: __wasi_fd_t,
}
#[doc = " The contents of a `subscription`."]
#[repr(C)]
#[derive(Copy, Clone)]
pub union __wasi_subscription_u_u_t {
    pub clock: __wasi_subscription_clock_t,
    pub fd_read: __wasi_subscription_fd_readwrite_t,
    pub fd_write: __wasi_subscription_fd_readwrite_t,
}
impl Default for __wasi_subscription_u_u_t {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Copy, Clone)]
pub struct __wasi_subscription_u_t {
    pub tag: u8,
    pub u: __wasi_subscription_u_u_t,
}
impl Default for __wasi_subscription_u_t {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = " Subscription to an event."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct __wasi_subscription_t {
    #[doc = " User-provided value that is attached to the subscription in the\n implementation and returned through `event::userdata`."]
    pub userdata: __wasi_userdata_t,
    #[doc = " The type of the event to which to subscribe, and its contents"]
    pub u: __wasi_subscription_u_t,
}
impl Default for __wasi_subscription_t {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = " Exit code generated by a process when exiting."]
pub type __wasi_exitcode_t = u32;
#[doc = " Flags provided to `sock_recv`."]
pub type __wasi_riflags_t = u16;
#[doc = " Flags returned by `sock_recv`."]
pub type __wasi_roflags_t = u16;
#[doc = " Flags provided to `sock_send`. As there are currently no flags\n defined, it must be set to zero."]
pub type __wasi_siflags_t = u16;
#[doc = " Which channels on a socket to shut down."]
pub type __wasi_sdflags_t = u8;
#[doc = " Identifiers for preopened capabilities."]
pub type __wasi_preopentype_t = u8;
#[doc = " The contents of a $prestat when type is `preopentype::dir`."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct __wasi_prestat_dir_t {
    #[doc = " The length of the directory name for use with `fd_prestat_dir_name`."]
    pub pr_name_len: __wasi_size_t,
}
#[doc = " Information about a pre-opened capability."]
#[repr(C)]
#[derive(Copy, Clone)]
pub union __wasi_prestat_u_t {
    pub dir: __wasi_prestat_dir_t,
}
impl Default for __wasi_prestat_u_t {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Copy, Clone)]
pub struct __wasi_prestat_t {
    pub tag: u8,
    pub u: __wasi_prestat_u_t,
}
impl Default for __wasi_prestat_t {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
extern "C" {
    #[must_use]
    #[doc = " Read command-line argument data.\n The size of the array should match that returned by `args_sizes_get`.\n Each argument is expected to be `\\0` terminated."]
    pub fn __wasi_args_get(argv: *mut *mut u8, argv_buf: *mut u8) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Return command-line argument data sizes.\n @return\n Returns the number of arguments and the size of the argument string\n data, or an error."]
    pub fn __wasi_args_sizes_get(
        retptr0: *mut __wasi_size_t,
        retptr1: *mut __wasi_size_t,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Read environment variable data.\n The sizes of the buffers should match that returned by `environ_sizes_get`.\n Key/value pairs are expected to be joined with `=`s, and terminated with `\\0`s."]
    pub fn __wasi_environ_get(environ: *mut *mut u8, environ_buf: *mut u8) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Return environment variable data sizes.\n @return\n Returns the number of environment variable arguments and the size of the\n environment variable data."]
    pub fn __wasi_environ_sizes_get(
        retptr0: *mut __wasi_size_t,
        retptr1: *mut __wasi_size_t,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Return the resolution of a clock.\n Implementations are required to provide a non-zero value for supported clocks. For unsupported clocks,\n return `errno::inval`.\n Note: This is similar to `clock_getres` in POSIX.\n @return\n The resolution of the clock, or an error if one happened."]
    pub fn __wasi_clock_res_get(
        id: __wasi_clockid_t,
        retptr0: *mut __wasi_timestamp_t,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Return the time value of a clock.\n Note: This is similar to `clock_gettime` in POSIX.\n @return\n The time value of the clock."]
    pub fn __wasi_clock_time_get(
        id: __wasi_clockid_t,
        precision: __wasi_timestamp_t,
        retptr0: *mut __wasi_timestamp_t,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Provide file advisory information on a file descriptor.\n Note: This is similar to `posix_fadvise` in POSIX."]
    pub fn __wasi_fd_advise(
        fd: __wasi_fd_t,
        offset: __wasi_filesize_t,
        len: __wasi_filesize_t,
        advice: __wasi_advice_t,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Force the allocation of space in a file.\n Note: This is similar to `posix_fallocate` in POSIX."]
    pub fn __wasi_fd_allocate(
        fd: __wasi_fd_t,
        offset: __wasi_filesize_t,
        len: __wasi_filesize_t,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Close a file descriptor.\n Note: This is similar to `close` in POSIX."]
    pub fn __wasi_fd_close(fd: __wasi_fd_t) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Synchronize the data of a file to disk.\n Note: This is similar to `fdatasync` in POSIX."]
    pub fn __wasi_fd_datasync(fd: __wasi_fd_t) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Get the attributes of a file descriptor.\n Note: This returns similar flags to `fsync(fd, F_GETFL)` in POSIX, as well as additional fields.\n @return\n The buffer where the file descriptor's attributes are stored."]
    pub fn __wasi_fd_fdstat_get(fd: __wasi_fd_t, retptr0: *mut __wasi_fdstat_t) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Adjust the flags associated with a file descriptor.\n Note: This is similar to `fcntl(fd, F_SETFL, flags)` in POSIX."]
    pub fn __wasi_fd_fdstat_set_flags(fd: __wasi_fd_t, flags: __wasi_fdflags_t) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Adjust the rights associated with a file descriptor.\n This can only be used to remove rights, and returns `errno::notcapable` if called in a way that would attempt to add rights"]
    pub fn __wasi_fd_fdstat_set_rights(
        fd: __wasi_fd_t,
        fs_rights_base: __wasi_rights_t,
        fs_rights_inheriting: __wasi_rights_t,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Return the attributes of an open file.\n @return\n The buffer where the file's attributes are stored."]
    pub fn __wasi_fd_filestat_get(
        fd: __wasi_fd_t,
        retptr0: *mut __wasi_filestat_t,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Adjust the size of an open file. If this increases the file's size, the extra bytes are filled with zeros.\n Note: This is similar to `ftruncate` in POSIX."]
    pub fn __wasi_fd_filestat_set_size(fd: __wasi_fd_t, size: __wasi_filesize_t) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Adjust the timestamps of an open file or directory.\n Note: This is similar to `futimens` in POSIX."]
    pub fn __wasi_fd_filestat_set_times(
        fd: __wasi_fd_t,
        atim: __wasi_timestamp_t,
        mtim: __wasi_timestamp_t,
        fst_flags: __wasi_fstflags_t,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Read from a file descriptor, without using and updating the file descriptor's offset.\n Note: This is similar to `preadv` in POSIX.\n @return\n The number of bytes read."]
    pub fn __wasi_fd_pread(
        fd: __wasi_fd_t,
        iovs: *const __wasi_iovec_t,
        iovs_len: usize,
        offset: __wasi_filesize_t,
        retptr0: *mut __wasi_size_t,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Return a description of the given preopened file descriptor.\n @return\n The buffer where the description is stored."]
    pub fn __wasi_fd_prestat_get(fd: __wasi_fd_t, retptr0: *mut __wasi_prestat_t)
        -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Return a description of the given preopened file descriptor."]
    pub fn __wasi_fd_prestat_dir_name(
        fd: __wasi_fd_t,
        path: *mut u8,
        path_len: __wasi_size_t,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Write to a file descriptor, without using and updating the file descriptor's offset.\n Note: This is similar to `pwritev` in POSIX.\n @return\n The number of bytes written."]
    pub fn __wasi_fd_pwrite(
        fd: __wasi_fd_t,
        iovs: *const __wasi_ciovec_t,
        iovs_len: usize,
        offset: __wasi_filesize_t,
        retptr0: *mut __wasi_size_t,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Read from a file descriptor.\n Note: This is similar to `readv` in POSIX.\n @return\n The number of bytes read."]
    pub fn __wasi_fd_read(
        fd: __wasi_fd_t,
        iovs: *const __wasi_iovec_t,
        iovs_len: usize,
        retptr0: *mut __wasi_size_t,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Read directory entries from a directory.\n When successful, the contents of the output buffer consist of a sequence of\n directory entries. Each directory entry consists of a `dirent` object,\n followed by `dirent::d_namlen` bytes holding the name of the directory\n entry.\n This function fills the output buffer as much as possible, potentially\n truncating the last directory entry. This allows the caller to grow its\n read buffer size in case it's too small to fit a single large directory\n entry, or skip the oversized directory entry.\n @return\n The number of bytes stored in the read buffer. If less than the size of the read buffer, the end of the directory has been reached."]
    pub fn __wasi_fd_readdir(
        fd: __wasi_fd_t,
        buf: *mut u8,
        buf_len: __wasi_size_t,
        cookie: __wasi_dircookie_t,
        retptr0: *mut __wasi_size_t,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Atomically replace a file descriptor by renumbering another file descriptor.\n Due to the strong focus on thread safety, this environment does not provide\n a mechanism to duplicate or renumber a file descriptor to an arbitrary\n number, like `dup2()`. This would be prone to race conditions, as an actual\n file descriptor with the same number could be allocated by a different\n thread at the same time.\n This function provides a way to atomically renumber file descriptors, which\n would disappear if `dup2()` were to be removed entirely."]
    pub fn __wasi_fd_renumber(fd: __wasi_fd_t, to: __wasi_fd_t) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Move the offset of a file descriptor.\n Note: This is similar to `lseek` in POSIX.\n @return\n The new offset of the file descriptor, relative to the start of the file."]
    pub fn __wasi_fd_seek(
        fd: __wasi_fd_t,
        offset: __wasi_filedelta_t,
        whence: __wasi_whence_t,
        retptr0: *mut __wasi_filesize_t,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Synchronize the data and metadata of a file to disk.\n Note: This is similar to `fsync` in POSIX."]
    pub fn __wasi_fd_sync(fd: __wasi_fd_t) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Return the current offset of a file descriptor.\n Note: This is similar to `lseek(fd, 0, SEEK_CUR)` in POSIX.\n @return\n The current offset of the file descriptor, relative to the start of the file."]
    pub fn __wasi_fd_tell(fd: __wasi_fd_t, retptr0: *mut __wasi_filesize_t) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Write to a file descriptor.\n Note: This is similar to `writev` in POSIX."]
    pub fn __wasi_fd_write(
        fd: __wasi_fd_t,
        iovs: *const __wasi_ciovec_t,
        iovs_len: usize,
        retptr0: *mut __wasi_size_t,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Create a directory.\n Note: This is similar to `mkdirat` in POSIX."]
    pub fn __wasi_path_create_directory(
        fd: __wasi_fd_t,
        path: *const ::std::os::raw::c_char,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Return the attributes of a file or directory.\n Note: This is similar to `stat` in POSIX.\n @return\n The buffer where the file's attributes are stored."]
    pub fn __wasi_path_filestat_get(
        fd: __wasi_fd_t,
        flags: __wasi_lookupflags_t,
        path: *const ::std::os::raw::c_char,
        retptr0: *mut __wasi_filestat_t,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Adjust the timestamps of a file or directory.\n Note: This is similar to `utimensat` in POSIX."]
    pub fn __wasi_path_filestat_set_times(
        fd: __wasi_fd_t,
        flags: __wasi_lookupflags_t,
        path: *const ::std::os::raw::c_char,
        atim: __wasi_timestamp_t,
        mtim: __wasi_timestamp_t,
        fst_flags: __wasi_fstflags_t,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Create a hard link.\n Note: This is similar to `linkat` in POSIX."]
    pub fn __wasi_path_link(
        old_fd: __wasi_fd_t,
        old_flags: __wasi_lookupflags_t,
        old_path: *const ::std::os::raw::c_char,
        new_fd: __wasi_fd_t,
        new_path: *const ::std::os::raw::c_char,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Open a file or directory.\n The returned file descriptor is not guaranteed to be the lowest-numbered\n file descriptor not currently open; it is randomized to prevent\n applications from depending on making assumptions about indexes, since this\n is error-prone in multi-threaded contexts. The returned file descriptor is\n guaranteed to be less than 2**31.\n Note: This is similar to `openat` in POSIX.\n @return\n The file descriptor of the file that has been opened."]
    pub fn __wasi_path_open(
        fd: __wasi_fd_t,
        dirflags: __wasi_lookupflags_t,
        path: *const ::std::os::raw::c_char,
        oflags: __wasi_oflags_t,
        fs_rights_base: __wasi_rights_t,
        fs_rights_inheriting: __wasi_rights_t,
        fdflags: __wasi_fdflags_t,
        retptr0: *mut __wasi_fd_t,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Read the contents of a symbolic link.\n Note: This is similar to `readlinkat` in POSIX.\n @return\n The number of bytes placed in the buffer."]
    pub fn __wasi_path_readlink(
        fd: __wasi_fd_t,
        path: *const ::std::os::raw::c_char,
        buf: *mut u8,
        buf_len: __wasi_size_t,
        retptr0: *mut __wasi_size_t,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Remove a directory.\n Return `errno::notempty` if the directory is not empty.\n Note: This is similar to `unlinkat(fd, path, AT_REMOVEDIR)` in POSIX."]
    pub fn __wasi_path_remove_directory(
        fd: __wasi_fd_t,
        path: *const ::std::os::raw::c_char,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Rename a file or directory.\n Note: This is similar to `renameat` in POSIX."]
    pub fn __wasi_path_rename(
        fd: __wasi_fd_t,
        old_path: *const ::std::os::raw::c_char,
        new_fd: __wasi_fd_t,
        new_path: *const ::std::os::raw::c_char,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Create a symbolic link.\n Note: This is similar to `symlinkat` in POSIX."]
    pub fn __wasi_path_symlink(
        old_path: *const ::std::os::raw::c_char,
        fd: __wasi_fd_t,
        new_path: *const ::std::os::raw::c_char,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Unlink a file.\n Return `errno::isdir` if the path refers to a directory.\n Note: This is similar to `unlinkat(fd, path, 0)` in POSIX."]
    pub fn __wasi_path_unlink_file(
        fd: __wasi_fd_t,
        path: *const ::std::os::raw::c_char,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Concurrently poll for the occurrence of a set of events.\n @return\n The number of events stored."]
    pub fn __wasi_poll_oneoff(
        in_: *const __wasi_subscription_t,
        out: *mut __wasi_event_t,
        nsubscriptions: __wasi_size_t,
        retptr0: *mut __wasi_size_t,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[doc = " Terminate the process normally. An exit code of 0 indicates successful\n termination of the program. The meanings of other values is dependent on\n the environment."]
    pub fn __wasi_proc_exit(rval: __wasi_exitcode_t) -> !;
}
extern "C" {
    #[must_use]
    #[doc = " Temporarily yield execution of the calling thread.\n Note: This is similar to `sched_yield` in POSIX."]
    pub fn __wasi_sched_yield() -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Write high-quality random data into a buffer.\n This function blocks when the implementation is unable to immediately\n provide sufficient high-quality random data.\n This function may execute slowly, so when large mounts of random data are\n required, it's advisable to use this function to seed a pseudo-random\n number generator, rather than to provide the random data directly."]
    pub fn __wasi_random_get(buf: *mut u8, buf_len: __wasi_size_t) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Accept a new incoming connection.\n Note: This is similar to `accept` in POSIX.\n @return\n New socket connection"]
    pub fn __wasi_sock_accept(
        fd: __wasi_fd_t,
        flags: __wasi_fdflags_t,
        retptr0: *mut __wasi_fd_t,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Receive a message from a socket.\n Note: This is similar to `recv` in POSIX, though it also supports reading\n the data into multiple buffers in the manner of `readv`.\n @return\n Number of bytes stored in ri_data and message flags."]
    pub fn __wasi_sock_recv(
        fd: __wasi_fd_t,
        ri_data: *const __wasi_iovec_t,
        ri_data_len: usize,
        ri_flags: __wasi_riflags_t,
        retptr0: *mut __wasi_size_t,
        retptr1: *mut __wasi_roflags_t,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Send a message on a socket.\n Note: This is similar to `send` in POSIX, though it also supports writing\n the data from multiple buffers in the manner of `writev`.\n @return\n Number of bytes transmitted."]
    pub fn __wasi_sock_send(
        fd: __wasi_fd_t,
        si_data: *const __wasi_ciovec_t,
        si_data_len: usize,
        si_flags: __wasi_siflags_t,
        retptr0: *mut __wasi_size_t,
    ) -> __wasi_errno_t;
}
extern "C" {
    #[must_use]
    #[doc = " Shut down socket send and receive channels.\n Note: This is similar to `shutdown` in POSIX."]
    pub fn __wasi_sock_shutdown(fd: __wasi_fd_t, how: __wasi_sdflags_t) -> __wasi_errno_t;
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct imaxdiv_t {
    pub quot: intmax_t,
    pub rem: intmax_t,
}
extern "C" {
    pub fn imaxabs(arg1: intmax_t) -> intmax_t;
}
extern "C" {
    pub fn imaxdiv(arg1: intmax_t, arg2: intmax_t) -> imaxdiv_t;
}
extern "C" {
    pub fn strtoimax(
        arg1: *const ::std::os::raw::c_char,
        arg2: *mut *mut ::std::os::raw::c_char,
        arg3: ::std::os::raw::c_int,
    ) -> intmax_t;
}
extern "C" {
    pub fn strtoumax(
        arg1: *const ::std::os::raw::c_char,
        arg2: *mut *mut ::std::os::raw::c_char,
        arg3: ::std::os::raw::c_int,
    ) -> uintmax_t;
}
extern "C" {
    pub fn wcstoimax(
        arg1: *const wchar_t,
        arg2: *mut *mut wchar_t,
        arg3: ::std::os::raw::c_int,
    ) -> intmax_t;
}
extern "C" {
    pub fn wcstoumax(
        arg1: *const wchar_t,
        arg2: *mut *mut wchar_t,
        arg3: ::std::os::raw::c_int,
    ) -> uintmax_t;
}
pub type float_t = f32;
pub type double_t = f64;
extern "C" {
    pub fn acos(arg1: f64) -> f64;
}
extern "C" {
    pub fn acosf(arg1: f32) -> f32;
}
extern "C" {
    pub fn acosl(arg1: u128) -> u128;
}
extern "C" {
    pub fn acosh(arg1: f64) -> f64;
}
extern "C" {
    pub fn acoshf(arg1: f32) -> f32;
}
extern "C" {
    pub fn acoshl(arg1: u128) -> u128;
}
extern "C" {
    pub fn asin(arg1: f64) -> f64;
}
extern "C" {
    pub fn asinf(arg1: f32) -> f32;
}
extern "C" {
    pub fn asinl(arg1: u128) -> u128;
}
extern "C" {
    pub fn asinh(arg1: f64) -> f64;
}
extern "C" {
    pub fn asinhf(arg1: f32) -> f32;
}
extern "C" {
    pub fn asinhl(arg1: u128) -> u128;
}
extern "C" {
    pub fn atan(arg1: f64) -> f64;
}
extern "C" {
    pub fn atanf(arg1: f32) -> f32;
}
extern "C" {
    pub fn atanl(arg1: u128) -> u128;
}
extern "C" {
    pub fn atan2(arg1: f64, arg2: f64) -> f64;
}
extern "C" {
    pub fn atan2f(arg1: f32, arg2: f32) -> f32;
}
extern "C" {
    pub fn atan2l(arg1: u128, arg2: u128) -> u128;
}
extern "C" {
    pub fn atanh(arg1: f64) -> f64;
}
extern "C" {
    pub fn atanhf(arg1: f32) -> f32;
}
extern "C" {
    pub fn atanhl(arg1: u128) -> u128;
}
extern "C" {
    pub fn cbrt(arg1: f64) -> f64;
}
extern "C" {
    pub fn cbrtf(arg1: f32) -> f32;
}
extern "C" {
    pub fn cbrtl(arg1: u128) -> u128;
}
extern "C" {
    pub fn ceil(arg1: f64) -> f64;
}
extern "C" {
    pub fn ceilf(arg1: f32) -> f32;
}
extern "C" {
    pub fn ceill(arg1: u128) -> u128;
}
extern "C" {
    pub fn copysign(arg1: f64, arg2: f64) -> f64;
}
extern "C" {
    pub fn copysignf(arg1: f32, arg2: f32) -> f32;
}
extern "C" {
    pub fn copysignl(arg1: u128, arg2: u128) -> u128;
}
extern "C" {
    pub fn cos(arg1: f64) -> f64;
}
extern "C" {
    pub fn cosf(arg1: f32) -> f32;
}
extern "C" {
    pub fn cosl(arg1: u128) -> u128;
}
extern "C" {
    pub fn cosh(arg1: f64) -> f64;
}
extern "C" {
    pub fn coshf(arg1: f32) -> f32;
}
extern "C" {
    pub fn coshl(arg1: u128) -> u128;
}
extern "C" {
    pub fn erf(arg1: f64) -> f64;
}
extern "C" {
    pub fn erff(arg1: f32) -> f32;
}
extern "C" {
    pub fn erfl(arg1: u128) -> u128;
}
extern "C" {
    pub fn erfc(arg1: f64) -> f64;
}
extern "C" {
    pub fn erfcf(arg1: f32) -> f32;
}
extern "C" {
    pub fn erfcl(arg1: u128) -> u128;
}
extern "C" {
    pub fn exp(arg1: f64) -> f64;
}
extern "C" {
    pub fn expf(arg1: f32) -> f32;
}
extern "C" {
    pub fn expl(arg1: u128) -> u128;
}
extern "C" {
    pub fn exp2(arg1: f64) -> f64;
}
extern "C" {
    pub fn exp2f(arg1: f32) -> f32;
}
extern "C" {
    pub fn exp2l(arg1: u128) -> u128;
}
extern "C" {
    pub fn expm1(arg1: f64) -> f64;
}
extern "C" {
    pub fn expm1f(arg1: f32) -> f32;
}
extern "C" {
    pub fn expm1l(arg1: u128) -> u128;
}
extern "C" {
    pub fn fabs(arg1: f64) -> f64;
}
extern "C" {
    pub fn fabsf(arg1: f32) -> f32;
}
extern "C" {
    pub fn fabsl(arg1: u128) -> u128;
}
extern "C" {
    pub fn fdim(arg1: f64, arg2: f64) -> f64;
}
extern "C" {
    pub fn fdimf(arg1: f32, arg2: f32) -> f32;
}
extern "C" {
    pub fn fdiml(arg1: u128, arg2: u128) -> u128;
}
extern "C" {
    pub fn floor(arg1: f64) -> f64;
}
extern "C" {
    pub fn floorf(arg1: f32) -> f32;
}
extern "C" {
    pub fn floorl(arg1: u128) -> u128;
}
extern "C" {
    pub fn fma(arg1: f64, arg2: f64, arg3: f64) -> f64;
}
extern "C" {
    pub fn fmaf(arg1: f32, arg2: f32, arg3: f32) -> f32;
}
extern "C" {
    pub fn fmal(arg1: u128, arg2: u128, arg3: u128) -> u128;
}
extern "C" {
    pub fn fmax(arg1: f64, arg2: f64) -> f64;
}
extern "C" {
    pub fn fmaxf(arg1: f32, arg2: f32) -> f32;
}
extern "C" {
    pub fn fmaxl(arg1: u128, arg2: u128) -> u128;
}
extern "C" {
    pub fn fmin(arg1: f64, arg2: f64) -> f64;
}
extern "C" {
    pub fn fminf(arg1: f32, arg2: f32) -> f32;
}
extern "C" {
    pub fn fminl(arg1: u128, arg2: u128) -> u128;
}
extern "C" {
    pub fn fmod(arg1: f64, arg2: f64) -> f64;
}
extern "C" {
    pub fn fmodf(arg1: f32, arg2: f32) -> f32;
}
extern "C" {
    pub fn fmodl(arg1: u128, arg2: u128) -> u128;
}
extern "C" {
    pub fn frexp(arg1: f64, arg2: *mut ::std::os::raw::c_int) -> f64;
}
extern "C" {
    pub fn frexpf(arg1: f32, arg2: *mut ::std::os::raw::c_int) -> f32;
}
extern "C" {
    pub fn frexpl(arg1: u128, arg2: *mut ::std::os::raw::c_int) -> u128;
}
extern "C" {
    pub fn hypot(arg1: f64, arg2: f64) -> f64;
}
extern "C" {
    pub fn hypotf(arg1: f32, arg2: f32) -> f32;
}
extern "C" {
    pub fn hypotl(arg1: u128, arg2: u128) -> u128;
}
extern "C" {
    pub fn ilogb(arg1: f64) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn ilogbf(arg1: f32) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn ilogbl(arg1: u128) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn ldexp(arg1: f64, arg2: ::std::os::raw::c_int) -> f64;
}
extern "C" {
    pub fn ldexpf(arg1: f32, arg2: ::std::os::raw::c_int) -> f32;
}
extern "C" {
    pub fn ldexpl(arg1: u128, arg2: ::std::os::raw::c_int) -> u128;
}
extern "C" {
    pub fn lgamma(arg1: f64) -> f64;
}
extern "C" {
    pub fn lgammaf(arg1: f32) -> f32;
}
extern "C" {
    pub fn lgammal(arg1: u128) -> u128;
}
extern "C" {
    pub fn llrint(arg1: f64) -> ::std::os::raw::c_longlong;
}
extern "C" {
    pub fn llrintf(arg1: f32) -> ::std::os::raw::c_longlong;
}
extern "C" {
    pub fn llrintl(arg1: u128) -> ::std::os::raw::c_longlong;
}
extern "C" {
    pub fn llround(arg1: f64) -> ::std::os::raw::c_longlong;
}
extern "C" {
    pub fn llroundf(arg1: f32) -> ::std::os::raw::c_longlong;
}
extern "C" {
    pub fn llroundl(arg1: u128) -> ::std::os::raw::c_longlong;
}
extern "C" {
    pub fn log(arg1: f64) -> f64;
}
extern "C" {
    pub fn logf(arg1: f32) -> f32;
}
extern "C" {
    pub fn logl(arg1: u128) -> u128;
}
extern "C" {
    pub fn log10(arg1: f64) -> f64;
}
extern "C" {
    pub fn log10f(arg1: f32) -> f32;
}
extern "C" {
    pub fn log10l(arg1: u128) -> u128;
}
extern "C" {
    pub fn log1p(arg1: f64) -> f64;
}
extern "C" {
    pub fn log1pf(arg1: f32) -> f32;
}
extern "C" {
    pub fn log1pl(arg1: u128) -> u128;
}
extern "C" {
    pub fn log2(arg1: f64) -> f64;
}
extern "C" {
    pub fn log2f(arg1: f32) -> f32;
}
extern "C" {
    pub fn log2l(arg1: u128) -> u128;
}
extern "C" {
    pub fn logb(arg1: f64) -> f64;
}
extern "C" {
    pub fn logbf(arg1: f32) -> f32;
}
extern "C" {
    pub fn logbl(arg1: u128) -> u128;
}
extern "C" {
    pub fn lrint(arg1: f64) -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn lrintf(arg1: f32) -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn lrintl(arg1: u128) -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn lround(arg1: f64) -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn lroundf(arg1: f32) -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn lroundl(arg1: u128) -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn modf(arg1: f64, arg2: *mut f64) -> f64;
}
extern "C" {
    pub fn modff(arg1: f32, arg2: *mut f32) -> f32;
}
extern "C" {
    pub fn modfl(arg1: u128, arg2: *mut u128) -> u128;
}
extern "C" {
    pub fn nan(arg1: *const ::std::os::raw::c_char) -> f64;
}
extern "C" {
    pub fn nanf(arg1: *const ::std::os::raw::c_char) -> f32;
}
extern "C" {
    pub fn nanl(arg1: *const ::std::os::raw::c_char) -> u128;
}
extern "C" {
    pub fn nearbyint(arg1: f64) -> f64;
}
extern "C" {
    pub fn nearbyintf(arg1: f32) -> f32;
}
extern "C" {
    pub fn nearbyintl(arg1: u128) -> u128;
}
extern "C" {
    pub fn nextafter(arg1: f64, arg2: f64) -> f64;
}
extern "C" {
    pub fn nextafterf(arg1: f32, arg2: f32) -> f32;
}
extern "C" {
    pub fn nextafterl(arg1: u128, arg2: u128) -> u128;
}
extern "C" {
    pub fn nexttoward(arg1: f64, arg2: u128) -> f64;
}
extern "C" {
    pub fn nexttowardf(arg1: f32, arg2: u128) -> f32;
}
extern "C" {
    pub fn nexttowardl(arg1: u128, arg2: u128) -> u128;
}
extern "C" {
    pub fn pow(arg1: f64, arg2: f64) -> f64;
}
extern "C" {
    pub fn powf(arg1: f32, arg2: f32) -> f32;
}
extern "C" {
    pub fn powl(arg1: u128, arg2: u128) -> u128;
}
extern "C" {
    pub fn remainder(arg1: f64, arg2: f64) -> f64;
}
extern "C" {
    pub fn remainderf(arg1: f32, arg2: f32) -> f32;
}
extern "C" {
    pub fn remainderl(arg1: u128, arg2: u128) -> u128;
}
extern "C" {
    pub fn remquo(arg1: f64, arg2: f64, arg3: *mut ::std::os::raw::c_int) -> f64;
}
extern "C" {
    pub fn remquof(arg1: f32, arg2: f32, arg3: *mut ::std::os::raw::c_int) -> f32;
}
extern "C" {
    pub fn remquol(arg1: u128, arg2: u128, arg3: *mut ::std::os::raw::c_int) -> u128;
}
extern "C" {
    pub fn rint(arg1: f64) -> f64;
}
extern "C" {
    pub fn rintf(arg1: f32) -> f32;
}
extern "C" {
    pub fn rintl(arg1: u128) -> u128;
}
extern "C" {
    pub fn round(arg1: f64) -> f64;
}
extern "C" {
    pub fn roundf(arg1: f32) -> f32;
}
extern "C" {
    pub fn roundl(arg1: u128) -> u128;
}
extern "C" {
    pub fn scalbln(arg1: f64, arg2: ::std::os::raw::c_long) -> f64;
}
extern "C" {
    pub fn scalblnf(arg1: f32, arg2: ::std::os::raw::c_long) -> f32;
}
extern "C" {
    pub fn scalblnl(arg1: u128, arg2: ::std::os::raw::c_long) -> u128;
}
extern "C" {
    pub fn scalbn(arg1: f64, arg2: ::std::os::raw::c_int) -> f64;
}
extern "C" {
    pub fn scalbnf(arg1: f32, arg2: ::std::os::raw::c_int) -> f32;
}
extern "C" {
    pub fn scalbnl(arg1: u128, arg2: ::std::os::raw::c_int) -> u128;
}
extern "C" {
    pub fn sin(arg1: f64) -> f64;
}
extern "C" {
    pub fn sinf(arg1: f32) -> f32;
}
extern "C" {
    pub fn sinl(arg1: u128) -> u128;
}
extern "C" {
    pub fn sinh(arg1: f64) -> f64;
}
extern "C" {
    pub fn sinhf(arg1: f32) -> f32;
}
extern "C" {
    pub fn sinhl(arg1: u128) -> u128;
}
extern "C" {
    pub fn sqrt(arg1: f64) -> f64;
}
extern "C" {
    pub fn sqrtf(arg1: f32) -> f32;
}
extern "C" {
    pub fn sqrtl(arg1: u128) -> u128;
}
extern "C" {
    pub fn tan(arg1: f64) -> f64;
}
extern "C" {
    pub fn tanf(arg1: f32) -> f32;
}
extern "C" {
    pub fn tanl(arg1: u128) -> u128;
}
extern "C" {
    pub fn tanh(arg1: f64) -> f64;
}
extern "C" {
    pub fn tanhf(arg1: f32) -> f32;
}
extern "C" {
    pub fn tanhl(arg1: u128) -> u128;
}
extern "C" {
    pub fn tgamma(arg1: f64) -> f64;
}
extern "C" {
    pub fn tgammaf(arg1: f32) -> f32;
}
extern "C" {
    pub fn tgammal(arg1: u128) -> u128;
}
extern "C" {
    pub fn trunc(arg1: f64) -> f64;
}
extern "C" {
    pub fn truncf(arg1: f32) -> f32;
}
extern "C" {
    pub fn truncl(arg1: u128) -> u128;
}
extern "C" {
    pub static mut signgam: ::std::os::raw::c_int;
}
extern "C" {
    pub fn j0(arg1: f64) -> f64;
}
extern "C" {
    pub fn j1(arg1: f64) -> f64;
}
extern "C" {
    pub fn jn(arg1: ::std::os::raw::c_int, arg2: f64) -> f64;
}
extern "C" {
    pub fn y0(arg1: f64) -> f64;
}
extern "C" {
    pub fn y1(arg1: f64) -> f64;
}
extern "C" {
    pub fn yn(arg1: ::std::os::raw::c_int, arg2: f64) -> f64;
}
extern "C" {
    pub fn drem(arg1: f64, arg2: f64) -> f64;
}
extern "C" {
    pub fn dremf(arg1: f32, arg2: f32) -> f32;
}
extern "C" {
    pub fn finite(arg1: f64) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn finitef(arg1: f32) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn scalb(arg1: f64, arg2: f64) -> f64;
}
extern "C" {
    pub fn scalbf(arg1: f32, arg2: f32) -> f32;
}
extern "C" {
    pub fn significand(arg1: f64) -> f64;
}
extern "C" {
    pub fn significandf(arg1: f32) -> f32;
}
extern "C" {
    pub fn lgamma_r(arg1: f64, arg2: *mut ::std::os::raw::c_int) -> f64;
}
extern "C" {
    pub fn lgammaf_r(arg1: f32, arg2: *mut ::std::os::raw::c_int) -> f32;
}
extern "C" {
    pub fn j0f(arg1: f32) -> f32;
}
extern "C" {
    pub fn j1f(arg1: f32) -> f32;
}
extern "C" {
    pub fn jnf(arg1: ::std::os::raw::c_int, arg2: f32) -> f32;
}
extern "C" {
    pub fn y0f(arg1: f32) -> f32;
}
extern "C" {
    pub fn y1f(arg1: f32) -> f32;
}
extern "C" {
    pub fn ynf(arg1: ::std::os::raw::c_int, arg2: f32) -> f32;
}
pub type off_t = ::std::os::raw::c_longlong;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct _IO_FILE {
    _unused: [u8; 0],
}
pub type FILE = _IO_FILE;
pub type va_list = __builtin_va_list;
pub type __isoc_va_list = __builtin_va_list;
#[repr(C)]
#[derive(Copy, Clone)]
pub union _G_fpos64_t {
    pub __opaque: [::std::os::raw::c_char; 16usize],
    pub __lldata: ::std::os::raw::c_longlong,
    pub __align: f64,
}
impl Default for _G_fpos64_t {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub type fpos_t = _G_fpos64_t;
extern "C" {
    pub static stdin: *mut FILE;
}
extern "C" {
    pub static stdout: *mut FILE;
}
extern "C" {
    pub static stderr: *mut FILE;
}
extern "C" {
    pub fn fopen(
        arg1: *const ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
    ) -> *mut FILE;
}
extern "C" {
    pub fn freopen(
        arg1: *const ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
        arg3: *mut FILE,
    ) -> *mut FILE;
}
extern "C" {
    pub fn fclose(arg1: *mut FILE) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn remove(arg1: *const ::std::os::raw::c_char) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn rename(
        arg1: *const ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn feof(arg1: *mut FILE) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn ferror(arg1: *mut FILE) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn fflush(arg1: *mut FILE) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn clearerr(arg1: *mut FILE);
}
extern "C" {
    pub fn fseek(
        arg1: *mut FILE,
        arg2: ::std::os::raw::c_long,
        arg3: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn ftell(arg1: *mut FILE) -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn rewind(arg1: *mut FILE);
}
extern "C" {
    pub fn fgetpos(arg1: *mut FILE, arg2: *mut fpos_t) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn fsetpos(arg1: *mut FILE, arg2: *const fpos_t) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn fread(
        arg1: *mut ::std::os::raw::c_void,
        arg2: ::std::os::raw::c_ulong,
        arg3: ::std::os::raw::c_ulong,
        arg4: *mut FILE,
    ) -> ::std::os::raw::c_ulong;
}
extern "C" {
    pub fn fwrite(
        arg1: *const ::std::os::raw::c_void,
        arg2: ::std::os::raw::c_ulong,
        arg3: ::std::os::raw::c_ulong,
        arg4: *mut FILE,
    ) -> ::std::os::raw::c_ulong;
}
extern "C" {
    pub fn fgetc(arg1: *mut FILE) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn getc(arg1: *mut FILE) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn getchar() -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn ungetc(arg1: ::std::os::raw::c_int, arg2: *mut FILE) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn fputc(arg1: ::std::os::raw::c_int, arg2: *mut FILE) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn putc(arg1: ::std::os::raw::c_int, arg2: *mut FILE) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn putchar(arg1: ::std::os::raw::c_int) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn fgets(
        arg1: *mut ::std::os::raw::c_char,
        arg2: ::std::os::raw::c_int,
        arg3: *mut FILE,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn fputs(arg1: *const ::std::os::raw::c_char, arg2: *mut FILE) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn puts(arg1: *const ::std::os::raw::c_char) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn printf(arg1: *const ::std::os::raw::c_char, ...) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn fprintf(
        arg1: *mut FILE,
        arg2: *const ::std::os::raw::c_char,
        ...
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn sprintf(
        arg1: *mut ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
        ...
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn snprintf(
        arg1: *mut ::std::os::raw::c_char,
        arg2: ::std::os::raw::c_ulong,
        arg3: *const ::std::os::raw::c_char,
        ...
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn vprintf(
        arg1: *const ::std::os::raw::c_char,
        arg2: __builtin_va_list,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn vfprintf(
        arg1: *mut FILE,
        arg2: *const ::std::os::raw::c_char,
        arg3: __builtin_va_list,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn vsprintf(
        arg1: *mut ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
        arg3: __builtin_va_list,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn vsnprintf(
        arg1: *mut ::std::os::raw::c_char,
        arg2: ::std::os::raw::c_ulong,
        arg3: *const ::std::os::raw::c_char,
        arg4: __builtin_va_list,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn scanf(arg1: *const ::std::os::raw::c_char, ...) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn fscanf(
        arg1: *mut FILE,
        arg2: *const ::std::os::raw::c_char,
        ...
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn sscanf(
        arg1: *const ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
        ...
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn vscanf(
        arg1: *const ::std::os::raw::c_char,
        arg2: __builtin_va_list,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn vfscanf(
        arg1: *mut FILE,
        arg2: *const ::std::os::raw::c_char,
        arg3: __builtin_va_list,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn vsscanf(
        arg1: *const ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
        arg3: __builtin_va_list,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn perror(arg1: *const ::std::os::raw::c_char);
}
extern "C" {
    pub fn setvbuf(
        arg1: *mut FILE,
        arg2: *mut ::std::os::raw::c_char,
        arg3: ::std::os::raw::c_int,
        arg4: usize,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn setbuf(arg1: *mut FILE, arg2: *mut ::std::os::raw::c_char);
}
extern "C" {
    pub fn tmpnam(arg1: *mut ::std::os::raw::c_char) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn tmpfile() -> *mut FILE;
}
extern "C" {
    pub fn fmemopen(
        arg1: *mut ::std::os::raw::c_void,
        arg2: usize,
        arg3: *const ::std::os::raw::c_char,
    ) -> *mut FILE;
}
extern "C" {
    pub fn open_memstream(arg1: *mut *mut ::std::os::raw::c_char, arg2: *mut usize) -> *mut FILE;
}
extern "C" {
    pub fn fdopen(arg1: ::std::os::raw::c_int, arg2: *const ::std::os::raw::c_char) -> *mut FILE;
}
extern "C" {
    pub fn fileno(arg1: *mut FILE) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn fseeko(
        arg1: *mut FILE,
        arg2: off_t,
        arg3: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn ftello(arg1: *mut FILE) -> off_t;
}
extern "C" {
    pub fn dprintf(
        arg1: ::std::os::raw::c_int,
        arg2: *const ::std::os::raw::c_char,
        ...
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn vdprintf(
        arg1: ::std::os::raw::c_int,
        arg2: *const ::std::os::raw::c_char,
        arg3: __isoc_va_list,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn getc_unlocked(arg1: *mut FILE) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn getchar_unlocked() -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn putc_unlocked(arg1: ::std::os::raw::c_int, arg2: *mut FILE) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn putchar_unlocked(arg1: ::std::os::raw::c_int) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn getdelim(
        arg1: *mut *mut ::std::os::raw::c_char,
        arg2: *mut usize,
        arg3: ::std::os::raw::c_int,
        arg4: *mut FILE,
    ) -> isize;
}
extern "C" {
    pub fn getline(
        arg1: *mut *mut ::std::os::raw::c_char,
        arg2: *mut usize,
        arg3: *mut FILE,
    ) -> isize;
}
extern "C" {
    pub fn renameat(
        arg1: ::std::os::raw::c_int,
        arg2: *const ::std::os::raw::c_char,
        arg3: ::std::os::raw::c_int,
        arg4: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn ctermid(arg1: *mut ::std::os::raw::c_char) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn cuserid(arg1: *mut ::std::os::raw::c_char) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn setlinebuf(arg1: *mut FILE);
}
extern "C" {
    pub fn setbuffer(arg1: *mut FILE, arg2: *mut ::std::os::raw::c_char, arg3: usize);
}
extern "C" {
    pub fn fgetc_unlocked(arg1: *mut FILE) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn fputc_unlocked(arg1: ::std::os::raw::c_int, arg2: *mut FILE) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn fflush_unlocked(arg1: *mut FILE) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn fread_unlocked(
        arg1: *mut ::std::os::raw::c_void,
        arg2: usize,
        arg3: usize,
        arg4: *mut FILE,
    ) -> usize;
}
extern "C" {
    pub fn fwrite_unlocked(
        arg1: *const ::std::os::raw::c_void,
        arg2: usize,
        arg3: usize,
        arg4: *mut FILE,
    ) -> usize;
}
extern "C" {
    pub fn clearerr_unlocked(arg1: *mut FILE);
}
extern "C" {
    pub fn feof_unlocked(arg1: *mut FILE) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn ferror_unlocked(arg1: *mut FILE) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn fileno_unlocked(arg1: *mut FILE) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn getw(arg1: *mut FILE) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn putw(arg1: ::std::os::raw::c_int, arg2: *mut FILE) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn fgetln(arg1: *mut FILE, arg2: *mut usize) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn asprintf(
        arg1: *mut *mut ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
        ...
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn vasprintf(
        arg1: *mut *mut ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
        arg3: __isoc_va_list,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[must_use]
    pub fn malloc(__size: ::std::os::raw::c_ulong) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    pub fn free(__ptr: *mut ::std::os::raw::c_void);
}
extern "C" {
    #[must_use]
    pub fn calloc(
        __nmemb: ::std::os::raw::c_ulong,
        __size: ::std::os::raw::c_ulong,
    ) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    #[must_use]
    pub fn realloc(
        __ptr: *mut ::std::os::raw::c_void,
        __size: ::std::os::raw::c_ulong,
    ) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    #[must_use]
    pub fn reallocarray(
        __ptr: *mut ::std::os::raw::c_void,
        __nmemb: usize,
        __size: usize,
    ) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    pub fn abort() -> !;
}
extern "C" {
    pub fn qsort(
        arg1: *mut ::std::os::raw::c_void,
        arg2: usize,
        arg3: usize,
        arg4: ::std::option::Option<
            unsafe extern "C" fn(
                arg1: *const ::std::os::raw::c_void,
                arg2: *const ::std::os::raw::c_void,
            ) -> ::std::os::raw::c_int,
        >,
    );
}
extern "C" {
    pub fn _Exit(arg1: ::std::os::raw::c_int) -> !;
}
extern "C" {
    pub fn atoi(arg1: *const ::std::os::raw::c_char) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn atol(arg1: *const ::std::os::raw::c_char) -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn atoll(arg1: *const ::std::os::raw::c_char) -> ::std::os::raw::c_longlong;
}
extern "C" {
    pub fn atof(arg1: *const ::std::os::raw::c_char) -> f64;
}
extern "C" {
    pub fn strtof(
        arg1: *const ::std::os::raw::c_char,
        arg2: *mut *mut ::std::os::raw::c_char,
    ) -> f32;
}
extern "C" {
    pub fn strtod(
        arg1: *const ::std::os::raw::c_char,
        arg2: *mut *mut ::std::os::raw::c_char,
    ) -> f64;
}
extern "C" {
    pub fn strtold(
        arg1: *const ::std::os::raw::c_char,
        arg2: *mut *mut ::std::os::raw::c_char,
    ) -> u128;
}
extern "C" {
    pub fn strtol(
        arg1: *const ::std::os::raw::c_char,
        arg2: *mut *mut ::std::os::raw::c_char,
        arg3: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn strtoul(
        arg1: *const ::std::os::raw::c_char,
        arg2: *mut *mut ::std::os::raw::c_char,
        arg3: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_ulong;
}
extern "C" {
    pub fn strtoll(
        arg1: *const ::std::os::raw::c_char,
        arg2: *mut *mut ::std::os::raw::c_char,
        arg3: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_longlong;
}
extern "C" {
    pub fn strtoull(
        arg1: *const ::std::os::raw::c_char,
        arg2: *mut *mut ::std::os::raw::c_char,
        arg3: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_ulonglong;
}
extern "C" {
    pub fn rand() -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn srand(arg1: ::std::os::raw::c_uint);
}
extern "C" {
    pub fn aligned_alloc(
        arg1: ::std::os::raw::c_ulong,
        arg2: ::std::os::raw::c_ulong,
    ) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    pub fn atexit(arg1: ::std::option::Option<unsafe extern "C" fn()>) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn exit(arg1: ::std::os::raw::c_int) -> !;
}
extern "C" {
    pub fn at_quick_exit(
        arg1: ::std::option::Option<unsafe extern "C" fn()>,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn quick_exit(arg1: ::std::os::raw::c_int) -> !;
}
extern "C" {
    pub fn getenv(arg1: *const ::std::os::raw::c_char) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn system(arg1: *const ::std::os::raw::c_char) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn bsearch(
        arg1: *const ::std::os::raw::c_void,
        arg2: *const ::std::os::raw::c_void,
        arg3: usize,
        arg4: usize,
        arg5: ::std::option::Option<
            unsafe extern "C" fn(
                arg1: *const ::std::os::raw::c_void,
                arg2: *const ::std::os::raw::c_void,
            ) -> ::std::os::raw::c_int,
        >,
    ) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    pub fn abs(arg1: ::std::os::raw::c_int) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn labs(arg1: ::std::os::raw::c_long) -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn llabs(arg1: ::std::os::raw::c_longlong) -> ::std::os::raw::c_longlong;
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct div_t {
    pub quot: ::std::os::raw::c_int,
    pub rem: ::std::os::raw::c_int,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct ldiv_t {
    pub quot: ::std::os::raw::c_long,
    pub rem: ::std::os::raw::c_long,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct lldiv_t {
    pub quot: ::std::os::raw::c_longlong,
    pub rem: ::std::os::raw::c_longlong,
}
extern "C" {
    pub fn div(arg1: ::std::os::raw::c_int, arg2: ::std::os::raw::c_int) -> div_t;
}
extern "C" {
    pub fn ldiv(arg1: ::std::os::raw::c_long, arg2: ::std::os::raw::c_long) -> ldiv_t;
}
extern "C" {
    pub fn lldiv(arg1: ::std::os::raw::c_longlong, arg2: ::std::os::raw::c_longlong) -> lldiv_t;
}
extern "C" {
    pub fn mblen(arg1: *const ::std::os::raw::c_char, arg2: usize) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn mbtowc(
        arg1: *mut wchar_t,
        arg2: *const ::std::os::raw::c_char,
        arg3: usize,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn wctomb(arg1: *mut ::std::os::raw::c_char, arg2: wchar_t) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn mbstowcs(arg1: *mut wchar_t, arg2: *const ::std::os::raw::c_char, arg3: usize) -> usize;
}
extern "C" {
    pub fn wcstombs(arg1: *mut ::std::os::raw::c_char, arg2: *const wchar_t, arg3: usize) -> usize;
}
extern "C" {
    pub fn __ctype_get_mb_cur_max() -> usize;
}
extern "C" {
    pub fn posix_memalign(
        arg1: *mut *mut ::std::os::raw::c_void,
        arg2: usize,
        arg3: usize,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn setenv(
        arg1: *const ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
        arg3: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn unsetenv(arg1: *const ::std::os::raw::c_char) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn getsubopt(
        arg1: *mut *mut ::std::os::raw::c_char,
        arg2: *const *mut ::std::os::raw::c_char,
        arg3: *mut *mut ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn rand_r(arg1: *mut ::std::os::raw::c_uint) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn random() -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn srandom(arg1: ::std::os::raw::c_uint);
}
extern "C" {
    pub fn initstate(
        arg1: ::std::os::raw::c_uint,
        arg2: *mut ::std::os::raw::c_char,
        arg3: usize,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn setstate(arg1: *mut ::std::os::raw::c_char) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn putenv(arg1: *mut ::std::os::raw::c_char) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn l64a(arg1: ::std::os::raw::c_long) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn a64l(arg1: *const ::std::os::raw::c_char) -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn setkey(arg1: *const ::std::os::raw::c_char);
}
extern "C" {
    pub fn drand48() -> f64;
}
extern "C" {
    pub fn erand48(arg1: *mut ::std::os::raw::c_ushort) -> f64;
}
extern "C" {
    pub fn lrand48() -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn nrand48(arg1: *mut ::std::os::raw::c_ushort) -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn mrand48() -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn jrand48(arg1: *mut ::std::os::raw::c_ushort) -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn srand48(arg1: ::std::os::raw::c_long);
}
extern "C" {
    pub fn seed48(arg1: *mut ::std::os::raw::c_ushort) -> *mut ::std::os::raw::c_ushort;
}
extern "C" {
    pub fn lcong48(arg1: *mut ::std::os::raw::c_ushort);
}
extern "C" {
    pub fn alloca(arg1: ::std::os::raw::c_ulong) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    pub fn clearenv() -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn arc4random() -> u32;
}
extern "C" {
    pub fn arc4random_buf(arg1: *mut ::std::os::raw::c_void, arg2: usize);
}
extern "C" {
    pub fn arc4random_uniform(arg1: u32) -> u32;
}
extern "C" {
    pub fn memcpy(
        __dst: *mut ::std::os::raw::c_void,
        __src: *const ::std::os::raw::c_void,
        __n: ::std::os::raw::c_ulong,
    ) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    pub fn memmove(
        __dst: *mut ::std::os::raw::c_void,
        __src: *const ::std::os::raw::c_void,
        __n: ::std::os::raw::c_ulong,
    ) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    pub fn memset(
        __dst: *mut ::std::os::raw::c_void,
        __c: ::std::os::raw::c_int,
        __n: ::std::os::raw::c_ulong,
    ) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    pub fn strlen(arg1: *const ::std::os::raw::c_char) -> ::std::os::raw::c_ulong;
}
extern "C" {
    pub fn strdup(arg1: *const ::std::os::raw::c_char) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn strcmp(
        arg1: *const ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn memchr(
        arg1: *const ::std::os::raw::c_void,
        arg2: ::std::os::raw::c_int,
        arg3: ::std::os::raw::c_ulong,
    ) -> *mut ::std::os::raw::c_void;
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct __locale_struct {
    _unused: [u8; 0],
}
pub type locale_t = *mut __locale_struct;
extern "C" {
    pub fn memcmp(
        arg1: *const ::std::os::raw::c_void,
        arg2: *const ::std::os::raw::c_void,
        arg3: ::std::os::raw::c_ulong,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn strcpy(
        arg1: *mut ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn strncpy(
        arg1: *mut ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
        arg3: ::std::os::raw::c_ulong,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn strcat(
        arg1: *mut ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn strncat(
        arg1: *mut ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
        arg3: ::std::os::raw::c_ulong,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn strncmp(
        arg1: *const ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
        arg3: ::std::os::raw::c_ulong,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn strcoll(
        arg1: *const ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn strxfrm(
        arg1: *mut ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
        arg3: ::std::os::raw::c_ulong,
    ) -> ::std::os::raw::c_ulong;
}
extern "C" {
    pub fn strchr(
        arg1: *const ::std::os::raw::c_char,
        arg2: ::std::os::raw::c_int,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn strrchr(
        arg1: *const ::std::os::raw::c_char,
        arg2: ::std::os::raw::c_int,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn strcspn(
        arg1: *const ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_ulong;
}
extern "C" {
    pub fn strspn(
        arg1: *const ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_ulong;
}
extern "C" {
    pub fn strpbrk(
        arg1: *const ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn strstr(
        arg1: *const ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn strtok(
        arg1: *mut ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn strerror(arg1: ::std::os::raw::c_int) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn bcmp(
        arg1: *const ::std::os::raw::c_void,
        arg2: *const ::std::os::raw::c_void,
        arg3: ::std::os::raw::c_ulong,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn bcopy(
        arg1: *const ::std::os::raw::c_void,
        arg2: *mut ::std::os::raw::c_void,
        arg3: usize,
    );
}
extern "C" {
    pub fn bzero(arg1: *mut ::std::os::raw::c_void, arg2: ::std::os::raw::c_ulong);
}
extern "C" {
    pub fn index(
        arg1: *const ::std::os::raw::c_char,
        arg2: ::std::os::raw::c_int,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn rindex(
        arg1: *const ::std::os::raw::c_char,
        arg2: ::std::os::raw::c_int,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn ffs(arg1: ::std::os::raw::c_int) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn ffsl(arg1: ::std::os::raw::c_long) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn ffsll(arg1: ::std::os::raw::c_longlong) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn strcasecmp(
        arg1: *const ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn strncasecmp(
        arg1: *const ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
        arg3: ::std::os::raw::c_ulong,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn strcasecmp_l(
        arg1: *const ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
        arg3: locale_t,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn strncasecmp_l(
        arg1: *const ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
        arg3: usize,
        arg4: locale_t,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn strtok_r(
        arg1: *mut ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
        arg3: *mut *mut ::std::os::raw::c_char,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn strerror_r(
        arg1: ::std::os::raw::c_int,
        arg2: *mut ::std::os::raw::c_char,
        arg3: usize,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn stpcpy(
        arg1: *mut ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn stpncpy(
        arg1: *mut ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
        arg3: ::std::os::raw::c_ulong,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn strnlen(arg1: *const ::std::os::raw::c_char, arg2: usize) -> usize;
}
extern "C" {
    pub fn strndup(
        arg1: *const ::std::os::raw::c_char,
        arg2: ::std::os::raw::c_ulong,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn strsignal(arg1: ::std::os::raw::c_int) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn strerror_l(arg1: ::std::os::raw::c_int, arg2: locale_t) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn strcoll_l(
        arg1: *const ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
        arg3: locale_t,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn strxfrm_l(
        arg1: *mut ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
        arg3: usize,
        arg4: locale_t,
    ) -> usize;
}
extern "C" {
    pub fn memccpy(
        arg1: *mut ::std::os::raw::c_void,
        arg2: *const ::std::os::raw::c_void,
        arg3: ::std::os::raw::c_int,
        arg4: ::std::os::raw::c_ulong,
    ) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    pub fn strsep(
        arg1: *mut *mut ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn strlcat(
        arg1: *mut ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
        arg3: ::std::os::raw::c_ulong,
    ) -> ::std::os::raw::c_ulong;
}
extern "C" {
    pub fn strlcpy(
        arg1: *mut ::std::os::raw::c_char,
        arg2: *const ::std::os::raw::c_char,
        arg3: ::std::os::raw::c_ulong,
    ) -> ::std::os::raw::c_ulong;
}
extern "C" {
    pub fn explicit_bzero(arg1: *mut ::std::os::raw::c_void, arg2: usize);
}
extern "C" {
    #[doc = " Put a description of the AVERROR code errnum in errbuf.\n In case of failure the global variable errno is set to indicate the\n error. Even in case of failure av_strerror() will print a generic\n error message indicating the errnum provided to errbuf.\n\n @param errnum      error code to describe\n @param errbuf      buffer to which description is written\n @param errbuf_size the size in bytes of errbuf\n @return 0 on success, a negative value if a description for errnum\n cannot be found"]
    pub fn av_strerror(
        errnum: ::std::os::raw::c_int,
        errbuf: *mut ::std::os::raw::c_char,
        errbuf_size: usize,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Allocate a memory block with alignment suitable for all memory accesses\n (including vectors if available on the CPU).\n\n @param size Size in bytes for the memory block to be allocated\n @return Pointer to the allocated block, or `NULL` if the block cannot\n         be allocated\n @see av_mallocz()"]
    pub fn av_malloc(size: usize) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    #[doc = " Allocate a memory block with alignment suitable for all memory accesses\n (including vectors if available on the CPU) and zero all the bytes of the\n block.\n\n @param size Size in bytes for the memory block to be allocated\n @return Pointer to the allocated block, or `NULL` if it cannot be allocated\n @see av_malloc()"]
    pub fn av_mallocz(size: usize) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    #[doc = " Allocate a memory block for an array with av_malloc().\n\n The allocated memory will have size `size * nmemb` bytes.\n\n @param nmemb Number of element\n @param size  Size of a single element\n @return Pointer to the allocated block, or `NULL` if the block cannot\n         be allocated\n @see av_malloc()"]
    pub fn av_malloc_array(nmemb: usize, size: usize) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    #[doc = " Allocate a memory block for an array with av_mallocz().\n\n The allocated memory will have size `size * nmemb` bytes.\n\n @param nmemb Number of elements\n @param size  Size of the single element\n @return Pointer to the allocated block, or `NULL` if the block cannot\n         be allocated\n\n @see av_mallocz()\n @see av_malloc_array()"]
    pub fn av_calloc(nmemb: usize, size: usize) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    #[doc = " Allocate, reallocate, or free a block of memory.\n\n If `ptr` is `NULL` and `size` > 0, allocate a new block. Otherwise, expand or\n shrink that block of memory according to `size`.\n\n @param ptr  Pointer to a memory block already allocated with\n             av_realloc() or `NULL`\n @param size Size in bytes of the memory block to be allocated or\n             reallocated\n\n @return Pointer to a newly-reallocated block or `NULL` if the block\n         cannot be reallocated\n\n @warning Unlike av_malloc(), the returned pointer is not guaranteed to be\n          correctly aligned. The returned pointer must be freed after even\n          if size is zero.\n @see av_fast_realloc()\n @see av_reallocp()"]
    pub fn av_realloc(ptr: *mut ::std::os::raw::c_void, size: usize)
        -> *mut ::std::os::raw::c_void;
}
extern "C" {
    #[must_use]
    #[doc = " Allocate, reallocate, or free a block of memory through a pointer to a\n pointer.\n\n If `*ptr` is `NULL` and `size` > 0, allocate a new block. If `size` is\n zero, free the memory block pointed to by `*ptr`. Otherwise, expand or\n shrink that block of memory according to `size`.\n\n @param[in,out] ptr  Pointer to a pointer to a memory block already allocated\n                     with av_realloc(), or a pointer to `NULL`. The pointer\n                     is updated on success, or freed on failure.\n @param[in]     size Size in bytes for the memory block to be allocated or\n                     reallocated\n\n @return Zero on success, an AVERROR error code on failure\n\n @warning Unlike av_malloc(), the allocated memory is not guaranteed to be\n          correctly aligned."]
    pub fn av_reallocp(ptr: *mut ::std::os::raw::c_void, size: usize) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Allocate, reallocate, or free a block of memory.\n\n This function does the same thing as av_realloc(), except:\n - It takes two size arguments and allocates `nelem * elsize` bytes,\n   after checking the result of the multiplication for integer overflow.\n - It frees the input block in case of failure, thus avoiding the memory\n   leak with the classic\n   @code{.c}\n   buf = realloc(buf);\n   if (!buf)\n       return -1;\n   @endcode\n   pattern."]
    pub fn av_realloc_f(
        ptr: *mut ::std::os::raw::c_void,
        nelem: usize,
        elsize: usize,
    ) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    #[doc = " Allocate, reallocate, or free an array.\n\n If `ptr` is `NULL` and `nmemb` > 0, allocate a new block.\n\n @param ptr   Pointer to a memory block already allocated with\n              av_realloc() or `NULL`\n @param nmemb Number of elements in the array\n @param size  Size of the single element of the array\n\n @return Pointer to a newly-reallocated block or NULL if the block\n         cannot be reallocated\n\n @warning Unlike av_malloc(), the allocated memory is not guaranteed to be\n          correctly aligned. The returned pointer must be freed after even if\n          nmemb is zero.\n @see av_reallocp_array()"]
    pub fn av_realloc_array(
        ptr: *mut ::std::os::raw::c_void,
        nmemb: usize,
        size: usize,
    ) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    #[doc = " Allocate, reallocate an array through a pointer to a pointer.\n\n If `*ptr` is `NULL` and `nmemb` > 0, allocate a new block.\n\n @param[in,out] ptr   Pointer to a pointer to a memory block already\n                      allocated with av_realloc(), or a pointer to `NULL`.\n                      The pointer is updated on success, or freed on failure.\n @param[in]     nmemb Number of elements\n @param[in]     size  Size of the single element\n\n @return Zero on success, an AVERROR error code on failure\n\n @warning Unlike av_malloc(), the allocated memory is not guaranteed to be\n          correctly aligned. *ptr must be freed after even if nmemb is zero."]
    pub fn av_reallocp_array(
        ptr: *mut ::std::os::raw::c_void,
        nmemb: usize,
        size: usize,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Reallocate the given buffer if it is not large enough, otherwise do nothing.\n\n If the given buffer is `NULL`, then a new uninitialized buffer is allocated.\n\n If the given buffer is not large enough, and reallocation fails, `NULL` is\n returned and `*size` is set to 0, but the original buffer is not changed or\n freed.\n\n A typical use pattern follows:\n\n @code{.c}\n uint8_t *buf = ...;\n uint8_t *new_buf = av_fast_realloc(buf, &current_size, size_needed);\n if (!new_buf) {\n     // Allocation failed; clean up original buffer\n     av_freep(&buf);\n     return AVERROR(ENOMEM);\n }\n @endcode\n\n @param[in,out] ptr      Already allocated buffer, or `NULL`\n @param[in,out] size     Pointer to the size of buffer `ptr`. `*size` is\n                         updated to the new allocated size, in particular 0\n                         in case of failure.\n @param[in]     min_size Desired minimal size of buffer `ptr`\n @return `ptr` if the buffer is large enough, a pointer to newly reallocated\n         buffer if the buffer was not large enough, or `NULL` in case of\n         error\n @see av_realloc()\n @see av_fast_malloc()"]
    pub fn av_fast_realloc(
        ptr: *mut ::std::os::raw::c_void,
        size: *mut ::std::os::raw::c_uint,
        min_size: usize,
    ) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    #[doc = " Allocate a buffer, reusing the given one if large enough.\n\n Contrary to av_fast_realloc(), the current buffer contents might not be\n preserved and on error the old buffer is freed, thus no special handling to\n avoid memleaks is necessary.\n\n `*ptr` is allowed to be `NULL`, in which case allocation always happens if\n `size_needed` is greater than 0.\n\n @code{.c}\n uint8_t *buf = ...;\n av_fast_malloc(&buf, &current_size, size_needed);\n if (!buf) {\n     // Allocation failed; buf already freed\n     return AVERROR(ENOMEM);\n }\n @endcode\n\n @param[in,out] ptr      Pointer to pointer to an already allocated buffer.\n                         `*ptr` will be overwritten with pointer to new\n                         buffer on success or `NULL` on failure\n @param[in,out] size     Pointer to the size of buffer `*ptr`. `*size` is\n                         updated to the new allocated size, in particular 0\n                         in case of failure.\n @param[in]     min_size Desired minimal size of buffer `*ptr`\n @see av_realloc()\n @see av_fast_mallocz()"]
    pub fn av_fast_malloc(
        ptr: *mut ::std::os::raw::c_void,
        size: *mut ::std::os::raw::c_uint,
        min_size: usize,
    );
}
extern "C" {
    #[doc = " Allocate and clear a buffer, reusing the given one if large enough.\n\n Like av_fast_malloc(), but all newly allocated space is initially cleared.\n Reused buffer is not cleared.\n\n `*ptr` is allowed to be `NULL`, in which case allocation always happens if\n `size_needed` is greater than 0.\n\n @param[in,out] ptr      Pointer to pointer to an already allocated buffer.\n                         `*ptr` will be overwritten with pointer to new\n                         buffer on success or `NULL` on failure\n @param[in,out] size     Pointer to the size of buffer `*ptr`. `*size` is\n                         updated to the new allocated size, in particular 0\n                         in case of failure.\n @param[in]     min_size Desired minimal size of buffer `*ptr`\n @see av_fast_malloc()"]
    pub fn av_fast_mallocz(
        ptr: *mut ::std::os::raw::c_void,
        size: *mut ::std::os::raw::c_uint,
        min_size: usize,
    );
}
extern "C" {
    #[doc = " Free a memory block which has been allocated with a function of av_malloc()\n or av_realloc() family.\n\n @param ptr Pointer to the memory block which should be freed.\n\n @note `ptr = NULL` is explicitly allowed.\n @note It is recommended that you use av_freep() instead, to prevent leaving\n       behind dangling pointers.\n @see av_freep()"]
    pub fn av_free(ptr: *mut ::std::os::raw::c_void);
}
extern "C" {
    #[doc = " Free a memory block which has been allocated with a function of av_malloc()\n or av_realloc() family, and set the pointer pointing to it to `NULL`.\n\n @code{.c}\n uint8_t *buf = av_malloc(16);\n av_free(buf);\n // buf now contains a dangling pointer to freed memory, and accidental\n // dereference of buf will result in a use-after-free, which may be a\n // security risk.\n\n uint8_t *buf = av_malloc(16);\n av_freep(&buf);\n // buf is now NULL, and accidental dereference will only result in a\n // NULL-pointer dereference.\n @endcode\n\n @param ptr Pointer to the pointer to the memory block which should be freed\n @note `*ptr = NULL` is safe and leads to no action.\n @see av_free()"]
    pub fn av_freep(ptr: *mut ::std::os::raw::c_void);
}
extern "C" {
    #[doc = " Duplicate a string.\n\n @param s String to be duplicated\n @return Pointer to a newly-allocated string containing a\n         copy of `s` or `NULL` if the string cannot be allocated\n @see av_strndup()"]
    pub fn av_strdup(s: *const ::std::os::raw::c_char) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Duplicate a substring of a string.\n\n @param s   String to be duplicated\n @param len Maximum length of the resulting string (not counting the\n            terminating byte)\n @return Pointer to a newly-allocated string containing a\n         substring of `s` or `NULL` if the string cannot be allocated"]
    pub fn av_strndup(s: *const ::std::os::raw::c_char, len: usize) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Duplicate a buffer with av_malloc().\n\n @param p    Buffer to be duplicated\n @param size Size in bytes of the buffer copied\n @return Pointer to a newly allocated buffer containing a\n         copy of `p` or `NULL` if the buffer cannot be allocated"]
    pub fn av_memdup(p: *const ::std::os::raw::c_void, size: usize) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    #[doc = " Overlapping memcpy() implementation.\n\n @param dst  Destination buffer\n @param back Number of bytes back to start copying (i.e. the initial size of\n             the overlapping window); must be > 0\n @param cnt  Number of bytes to copy; must be >= 0\n\n @note `cnt > back` is valid, this will copy the bytes we just copied,\n       thus creating a repeating pattern with a period length of `back`."]
    pub fn av_memcpy_backptr(dst: *mut u8, back: ::std::os::raw::c_int, cnt: ::std::os::raw::c_int);
}
extern "C" {
    #[doc = " Add the pointer to an element to a dynamic array.\n\n The array to grow is supposed to be an array of pointers to\n structures, and the element to add must be a pointer to an already\n allocated structure.\n\n The array is reallocated when its size reaches powers of 2.\n Therefore, the amortized cost of adding an element is constant.\n\n In case of success, the pointer to the array is updated in order to\n point to the new grown array, and the number pointed to by `nb_ptr`\n is incremented.\n In case of failure, the array is freed, `*tab_ptr` is set to `NULL` and\n `*nb_ptr` is set to 0.\n\n @param[in,out] tab_ptr Pointer to the array to grow\n @param[in,out] nb_ptr  Pointer to the number of elements in the array\n @param[in]     elem    Element to add\n @see av_dynarray_add_nofree(), av_dynarray2_add()"]
    pub fn av_dynarray_add(
        tab_ptr: *mut ::std::os::raw::c_void,
        nb_ptr: *mut ::std::os::raw::c_int,
        elem: *mut ::std::os::raw::c_void,
    );
}
extern "C" {
    #[must_use]
    #[doc = " Add an element to a dynamic array.\n\n Function has the same functionality as av_dynarray_add(),\n but it doesn't free memory on fails. It returns error code\n instead and leave current buffer untouched.\n\n @return >=0 on success, negative otherwise\n @see av_dynarray_add(), av_dynarray2_add()"]
    pub fn av_dynarray_add_nofree(
        tab_ptr: *mut ::std::os::raw::c_void,
        nb_ptr: *mut ::std::os::raw::c_int,
        elem: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Add an element of size `elem_size` to a dynamic array.\n\n The array is reallocated when its number of elements reaches powers of 2.\n Therefore, the amortized cost of adding an element is constant.\n\n In case of success, the pointer to the array is updated in order to\n point to the new grown array, and the number pointed to by `nb_ptr`\n is incremented.\n In case of failure, the array is freed, `*tab_ptr` is set to `NULL` and\n `*nb_ptr` is set to 0.\n\n @param[in,out] tab_ptr   Pointer to the array to grow\n @param[in,out] nb_ptr    Pointer to the number of elements in the array\n @param[in]     elem_size Size in bytes of an element in the array\n @param[in]     elem_data Pointer to the data of the element to add. If\n                          `NULL`, the space of the newly added element is\n                          allocated but left uninitialized.\n\n @return Pointer to the data of the element to copy in the newly allocated\n         space\n @see av_dynarray_add(), av_dynarray_add_nofree()"]
    pub fn av_dynarray2_add(
        tab_ptr: *mut *mut ::std::os::raw::c_void,
        nb_ptr: *mut ::std::os::raw::c_int,
        elem_size: usize,
        elem_data: *const u8,
    ) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    #[doc = " Multiply two `size_t` values checking for overflow.\n\n @param[in]  a   Operand of multiplication\n @param[in]  b   Operand of multiplication\n @param[out] r   Pointer to the result of the operation\n @return 0 on success, AVERROR(EINVAL) on overflow"]
    pub fn av_size_mult(a: usize, b: usize, r: *mut usize) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Set the maximum size that may be allocated in one block.\n\n The value specified with this function is effective for all libavutil's @ref\n lavu_mem_funcs \"heap management functions.\"\n\n By default, the max value is defined as `INT_MAX`.\n\n @param max Value to be set as the new maximum size\n\n @warning Exercise extreme caution when using this function. Don't touch\n          this if you do not understand the full consequence of doing so."]
    pub fn av_max_alloc(max: usize);
}
extern "C" {
    pub fn av_log2(v: ::std::os::raw::c_uint) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn av_log2_16bit(v: ::std::os::raw::c_uint) -> ::std::os::raw::c_int;
}
#[doc = " Rational number (pair of numerator and denominator)."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVRational {
    #[doc = "< Numerator"]
    pub num: ::std::os::raw::c_int,
    #[doc = "< Denominator"]
    pub den: ::std::os::raw::c_int,
}
extern "C" {
    #[doc = " Reduce a fraction.\n\n This is useful for framerate calculations.\n\n @param[out] dst_num Destination numerator\n @param[out] dst_den Destination denominator\n @param[in]      num Source numerator\n @param[in]      den Source denominator\n @param[in]      max Maximum allowed values for `dst_num` & `dst_den`\n @return 1 if the operation is exact, 0 otherwise"]
    pub fn av_reduce(
        dst_num: *mut ::std::os::raw::c_int,
        dst_den: *mut ::std::os::raw::c_int,
        num: i64,
        den: i64,
        max: i64,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Multiply two rationals.\n @param b First rational\n @param c Second rational\n @return b*c"]
    pub fn av_mul_q(b: AVRational, c: AVRational) -> AVRational;
}
extern "C" {
    #[doc = " Divide one rational by another.\n @param b First rational\n @param c Second rational\n @return b/c"]
    pub fn av_div_q(b: AVRational, c: AVRational) -> AVRational;
}
extern "C" {
    #[doc = " Add two rationals.\n @param b First rational\n @param c Second rational\n @return b+c"]
    pub fn av_add_q(b: AVRational, c: AVRational) -> AVRational;
}
extern "C" {
    #[doc = " Subtract one rational from another.\n @param b First rational\n @param c Second rational\n @return b-c"]
    pub fn av_sub_q(b: AVRational, c: AVRational) -> AVRational;
}
extern "C" {
    #[doc = " Convert a double precision floating point number to a rational.\n\n In case of infinity, the returned value is expressed as `{1, 0}` or\n `{-1, 0}` depending on the sign.\n\n In general rational numbers with |num| <= 1<<26 && |den| <= 1<<26\n can be recovered exactly from their double representation.\n (no exceptions were found within 1B random ones)\n\n @param d   `double` to convert\n @param max Maximum allowed numerator and denominator\n @return `d` in AVRational form\n @see av_q2d()"]
    pub fn av_d2q(d: f64, max: ::std::os::raw::c_int) -> AVRational;
}
extern "C" {
    #[doc = " Find which of the two rationals is closer to another rational.\n\n @param q     Rational to be compared against\n @param q1    Rational to be tested\n @param q2    Rational to be tested\n @return One of the following values:\n         - 1 if `q1` is nearer to `q` than `q2`\n         - -1 if `q2` is nearer to `q` than `q1`\n         - 0 if they have the same distance"]
    pub fn av_nearer_q(q: AVRational, q1: AVRational, q2: AVRational) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Find the value in a list of rationals nearest a given reference rational.\n\n @param q      Reference rational\n @param q_list Array of rationals terminated by `{0, 0}`\n @return Index of the nearest value found in the array"]
    pub fn av_find_nearest_q_idx(q: AVRational, q_list: *const AVRational)
        -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Convert an AVRational to a IEEE 32-bit `float` expressed in fixed-point\n format.\n\n @param q Rational to be converted\n @return Equivalent floating-point value, expressed as an unsigned 32-bit\n         integer.\n @note The returned value is platform-indepedant."]
    pub fn av_q2intfloat(q: AVRational) -> u32;
}
extern "C" {
    #[doc = " Return the best rational so that a and b are multiple of it.\n If the resulting denominator is larger than max_den, return def."]
    pub fn av_gcd_q(
        a: AVRational,
        b: AVRational,
        max_den: ::std::os::raw::c_int,
        def: AVRational,
    ) -> AVRational;
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union av_intfloat32 {
    pub i: u32,
    pub f: f32,
}
impl Default for av_intfloat32 {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union av_intfloat64 {
    pub i: u64,
    pub f: f64,
}
impl Default for av_intfloat64 {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "< Round toward zero."]
pub const AVRounding_AV_ROUND_ZERO: AVRounding = 0;
#[doc = "< Round away from zero."]
pub const AVRounding_AV_ROUND_INF: AVRounding = 1;
#[doc = "< Round toward -infinity."]
pub const AVRounding_AV_ROUND_DOWN: AVRounding = 2;
#[doc = "< Round toward +infinity."]
pub const AVRounding_AV_ROUND_UP: AVRounding = 3;
#[doc = "< Round to nearest and halfway cases away from zero."]
pub const AVRounding_AV_ROUND_NEAR_INF: AVRounding = 5;
#[doc = " Flag telling rescaling functions to pass `INT64_MIN`/`MAX` through\n unchanged, avoiding special cases for #AV_NOPTS_VALUE.\n\n Unlike other values of the enumeration AVRounding, this value is a\n bitmask that must be used in conjunction with another value of the\n enumeration through a bitwise OR, in order to set behavior for normal\n cases.\n\n @code{.c}\n av_rescale_rnd(3, 1, 2, AV_ROUND_UP | AV_ROUND_PASS_MINMAX);\n // Rescaling 3:\n //     Calculating 3 * 1 / 2\n //     3 / 2 is rounded up to 2\n //     => 2\n\n av_rescale_rnd(AV_NOPTS_VALUE, 1, 2, AV_ROUND_UP | AV_ROUND_PASS_MINMAX);\n // Rescaling AV_NOPTS_VALUE:\n //     AV_NOPTS_VALUE == INT64_MIN\n //     AV_NOPTS_VALUE is passed through\n //     => AV_NOPTS_VALUE\n @endcode"]
pub const AVRounding_AV_ROUND_PASS_MINMAX: AVRounding = 8192;
#[doc = " Rounding methods."]
pub type AVRounding = ::std::os::raw::c_uint;
extern "C" {
    #[doc = " Compute the greatest common divisor of two integer operands.\n\n @param a Operand\n @param b Operand\n @return GCD of a and b up to sign; if a >= 0 and b >= 0, return value is >= 0;\n if a == 0 and b == 0, returns 0."]
    pub fn av_gcd(a: i64, b: i64) -> i64;
}
extern "C" {
    #[doc = " Rescale a 64-bit integer with rounding to nearest.\n\n The operation is mathematically equivalent to `a * b / c`, but writing that\n directly can overflow.\n\n This function is equivalent to av_rescale_rnd() with #AV_ROUND_NEAR_INF.\n\n @see av_rescale_rnd(), av_rescale_q(), av_rescale_q_rnd()"]
    pub fn av_rescale(a: i64, b: i64, c: i64) -> i64;
}
extern "C" {
    #[doc = " Rescale a 64-bit integer with specified rounding.\n\n The operation is mathematically equivalent to `a * b / c`, but writing that\n directly can overflow, and does not support different rounding methods.\n If the result is not representable then INT64_MIN is returned.\n\n @see av_rescale(), av_rescale_q(), av_rescale_q_rnd()"]
    pub fn av_rescale_rnd(a: i64, b: i64, c: i64, rnd: AVRounding) -> i64;
}
extern "C" {
    #[doc = " Rescale a 64-bit integer by 2 rational numbers.\n\n The operation is mathematically equivalent to `a * bq / cq`.\n\n This function is equivalent to av_rescale_q_rnd() with #AV_ROUND_NEAR_INF.\n\n @see av_rescale(), av_rescale_rnd(), av_rescale_q_rnd()"]
    pub fn av_rescale_q(a: i64, bq: AVRational, cq: AVRational) -> i64;
}
extern "C" {
    #[doc = " Rescale a 64-bit integer by 2 rational numbers with specified rounding.\n\n The operation is mathematically equivalent to `a * bq / cq`.\n\n @see av_rescale(), av_rescale_rnd(), av_rescale_q()"]
    pub fn av_rescale_q_rnd(a: i64, bq: AVRational, cq: AVRational, rnd: AVRounding) -> i64;
}
extern "C" {
    #[doc = " Compare two timestamps each in its own time base.\n\n @return One of the following values:\n         - -1 if `ts_a` is before `ts_b`\n         - 1 if `ts_a` is after `ts_b`\n         - 0 if they represent the same position\n\n @warning\n The result of the function is undefined if one of the timestamps is outside\n the `int64_t` range when represented in the other's timebase."]
    pub fn av_compare_ts(
        ts_a: i64,
        tb_a: AVRational,
        ts_b: i64,
        tb_b: AVRational,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Compare the remainders of two integer operands divided by a common divisor.\n\n In other words, compare the least significant `log2(mod)` bits of integers\n `a` and `b`.\n\n @code{.c}\n av_compare_mod(0x11, 0x02, 0x10) < 0 // since 0x11 % 0x10  (0x1) < 0x02 % 0x10  (0x2)\n av_compare_mod(0x11, 0x02, 0x20) > 0 // since 0x11 % 0x20 (0x11) > 0x02 % 0x20 (0x02)\n @endcode\n\n @param a Operand\n @param b Operand\n @param mod Divisor; must be a power of 2\n @return\n         - a negative value if `a % mod < b % mod`\n         - a positive value if `a % mod > b % mod`\n         - zero             if `a % mod == b % mod`"]
    pub fn av_compare_mod(a: u64, b: u64, mod_: u64) -> i64;
}
extern "C" {
    #[doc = " Rescale a timestamp while preserving known durations.\n\n This function is designed to be called per audio packet to scale the input\n timestamp to a different time base. Compared to a simple av_rescale_q()\n call, this function is robust against possible inconsistent frame durations.\n\n The `last` parameter is a state variable that must be preserved for all\n subsequent calls for the same stream. For the first call, `*last` should be\n initialized to #AV_NOPTS_VALUE.\n\n @param[in]     in_tb    Input time base\n @param[in]     in_ts    Input timestamp\n @param[in]     fs_tb    Duration time base; typically this is finer-grained\n                         (greater) than `in_tb` and `out_tb`\n @param[in]     duration Duration till the next call to this function (i.e.\n                         duration of the current packet/frame)\n @param[in,out] last     Pointer to a timestamp expressed in terms of\n                         `fs_tb`, acting as a state variable\n @param[in]     out_tb   Output timebase\n @return        Timestamp expressed in terms of `out_tb`\n\n @note In the context of this function, \"duration\" is in term of samples, not\n       seconds."]
    pub fn av_rescale_delta(
        in_tb: AVRational,
        in_ts: i64,
        fs_tb: AVRational,
        duration: ::std::os::raw::c_int,
        last: *mut i64,
        out_tb: AVRational,
    ) -> i64;
}
extern "C" {
    #[doc = " Add a value to a timestamp.\n\n This function guarantees that when the same value is repeatly added that\n no accumulation of rounding errors occurs.\n\n @param[in] ts     Input timestamp\n @param[in] ts_tb  Input timestamp time base\n @param[in] inc    Value to be added\n @param[in] inc_tb Time base of `inc`"]
    pub fn av_add_stable(ts_tb: AVRational, ts: i64, inc_tb: AVRational, inc: i64) -> i64;
}
extern "C" {
    #[doc = " 0th order modified bessel function of the first kind."]
    pub fn av_bessel_i0(x: f64) -> f64;
}
pub type __gnuc_va_list = __builtin_va_list;
pub const AVClassCategory_AV_CLASS_CATEGORY_NA: AVClassCategory = 0;
pub const AVClassCategory_AV_CLASS_CATEGORY_INPUT: AVClassCategory = 1;
pub const AVClassCategory_AV_CLASS_CATEGORY_OUTPUT: AVClassCategory = 2;
pub const AVClassCategory_AV_CLASS_CATEGORY_MUXER: AVClassCategory = 3;
pub const AVClassCategory_AV_CLASS_CATEGORY_DEMUXER: AVClassCategory = 4;
pub const AVClassCategory_AV_CLASS_CATEGORY_ENCODER: AVClassCategory = 5;
pub const AVClassCategory_AV_CLASS_CATEGORY_DECODER: AVClassCategory = 6;
pub const AVClassCategory_AV_CLASS_CATEGORY_FILTER: AVClassCategory = 7;
pub const AVClassCategory_AV_CLASS_CATEGORY_BITSTREAM_FILTER: AVClassCategory = 8;
pub const AVClassCategory_AV_CLASS_CATEGORY_SWSCALER: AVClassCategory = 9;
pub const AVClassCategory_AV_CLASS_CATEGORY_SWRESAMPLER: AVClassCategory = 10;
pub const AVClassCategory_AV_CLASS_CATEGORY_DEVICE_VIDEO_OUTPUT: AVClassCategory = 40;
pub const AVClassCategory_AV_CLASS_CATEGORY_DEVICE_VIDEO_INPUT: AVClassCategory = 41;
pub const AVClassCategory_AV_CLASS_CATEGORY_DEVICE_AUDIO_OUTPUT: AVClassCategory = 42;
pub const AVClassCategory_AV_CLASS_CATEGORY_DEVICE_AUDIO_INPUT: AVClassCategory = 43;
pub const AVClassCategory_AV_CLASS_CATEGORY_DEVICE_OUTPUT: AVClassCategory = 44;
pub const AVClassCategory_AV_CLASS_CATEGORY_DEVICE_INPUT: AVClassCategory = 45;
#[doc = "< not part of ABI/API"]
pub const AVClassCategory_AV_CLASS_CATEGORY_NB: AVClassCategory = 46;
pub type AVClassCategory = ::std::os::raw::c_uint;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct AVOptionRanges {
    _unused: [u8; 0],
}
#[doc = " Describe the class of an AVClass context structure. That is an\n arbitrary struct of which the first field is a pointer to an\n AVClass struct (e.g. AVCodecContext, AVFormatContext etc.)."]
#[repr(C)]
#[derive(Debug, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVClass {
    #[doc = " The name of the class; usually it is the same name as the\n context structure type to which the AVClass is associated."]
    pub class_name: *const ::std::os::raw::c_char,
    #[doc = " A pointer to a function which returns the name of a context\n instance ctx associated with the class."]
    pub item_name: ::std::option::Option<
        unsafe extern "C" fn(ctx: *mut ::std::os::raw::c_void) -> *const ::std::os::raw::c_char,
    >,
    #[doc = " a pointer to the first option specified in the class if any or NULL\n\n @see av_set_default_options()"]
    pub option: *mut AVOption,
    #[doc = " LIBAVUTIL_VERSION with which this structure was created.\n This is used to allow fields to be added without requiring major\n version bumps everywhere."]
    pub version: ::std::os::raw::c_int,
    #[doc = " Offset in the structure where log_level_offset is stored.\n 0 means there is no such variable"]
    pub log_level_offset_offset: ::std::os::raw::c_int,
    #[doc = " Offset in the structure where a pointer to the parent context for\n logging is stored. For example a decoder could pass its AVCodecContext\n to eval as such a parent context, which an av_log() implementation\n could then leverage to display the parent context.\n The offset can be NULL."]
    pub parent_log_context_offset: ::std::os::raw::c_int,
    #[doc = " Category used for visualization (like color)\n This is only set if the category is equal for all objects using this class.\n available since version (51 << 16 | 56 << 8 | 100)"]
    pub category: AVClassCategory,
    #[doc = " Callback to return the category.\n available since version (51 << 16 | 59 << 8 | 100)"]
    pub get_category: ::std::option::Option<
        unsafe extern "C" fn(ctx: *mut ::std::os::raw::c_void) -> AVClassCategory,
    >,
    #[doc = " Callback to return the supported/allowed ranges.\n available since version (52.12)"]
    pub query_ranges: ::std::option::Option<
        unsafe extern "C" fn(
            arg1: *mut *mut AVOptionRanges,
            obj: *mut ::std::os::raw::c_void,
            key: *const ::std::os::raw::c_char,
            flags: ::std::os::raw::c_int,
        ) -> ::std::os::raw::c_int,
    >,
    #[doc = " Return next AVOptions-enabled child or NULL"]
    pub child_next: ::std::option::Option<
        unsafe extern "C" fn(
            obj: *mut ::std::os::raw::c_void,
            prev: *mut ::std::os::raw::c_void,
        ) -> *mut ::std::os::raw::c_void,
    >,
    #[doc = " Iterate over the AVClasses corresponding to potential AVOptions-enabled\n children.\n\n @param iter pointer to opaque iteration state. The caller must initialize\n             *iter to NULL before the first call.\n @return AVClass for the next AVOptions-enabled child or NULL if there are\n         no more such children.\n\n @note The difference between child_next and this is that child_next\n       iterates over _already existing_ objects, while child_class_iterate\n       iterates over _all possible_ children."]
    pub child_class_iterate: ::std::option::Option<
        unsafe extern "C" fn(iter: *mut *mut ::std::os::raw::c_void) -> *const AVClass,
    >,
}
impl Default for AVClass {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
extern "C" {
    #[doc = " Send the specified message to the log if the level is less than or equal\n to the current av_log_level. By default, all logging messages are sent to\n stderr. This behavior can be altered by setting a different logging callback\n function.\n @see av_log_set_callback\n\n @param avcl A pointer to an arbitrary struct of which the first field is a\n        pointer to an AVClass struct or NULL if general log.\n @param level The importance level of the message expressed using a @ref\n        lavu_log_constants \"Logging Constant\".\n @param fmt The format string (printf-compatible) that specifies how\n        subsequent arguments are converted to output."]
    pub fn av_log(
        avcl: *mut ::std::os::raw::c_void,
        level: ::std::os::raw::c_int,
        fmt: *const ::std::os::raw::c_char,
        ...
    );
}
extern "C" {
    #[doc = " Send the specified message to the log once with the initial_level and then with\n the subsequent_level. By default, all logging messages are sent to\n stderr. This behavior can be altered by setting a different logging callback\n function.\n @see av_log\n\n @param avcl A pointer to an arbitrary struct of which the first field is a\n        pointer to an AVClass struct or NULL if general log.\n @param initial_level importance level of the message expressed using a @ref\n        lavu_log_constants \"Logging Constant\" for the first occurance.\n @param subsequent_level importance level of the message expressed using a @ref\n        lavu_log_constants \"Logging Constant\" after the first occurance.\n @param fmt The format string (printf-compatible) that specifies how\n        subsequent arguments are converted to output.\n @param state a variable to keep trak of if a message has already been printed\n        this must be initialized to 0 before the first use. The same state\n        must not be accessed by 2 Threads simultaneously."]
    pub fn av_log_once(
        avcl: *mut ::std::os::raw::c_void,
        initial_level: ::std::os::raw::c_int,
        subsequent_level: ::std::os::raw::c_int,
        state: *mut ::std::os::raw::c_int,
        fmt: *const ::std::os::raw::c_char,
        ...
    );
}
extern "C" {
    #[doc = " Send the specified message to the log if the level is less than or equal\n to the current av_log_level. By default, all logging messages are sent to\n stderr. This behavior can be altered by setting a different logging callback\n function.\n @see av_log_set_callback\n\n @param avcl A pointer to an arbitrary struct of which the first field is a\n        pointer to an AVClass struct.\n @param level The importance level of the message expressed using a @ref\n        lavu_log_constants \"Logging Constant\".\n @param fmt The format string (printf-compatible) that specifies how\n        subsequent arguments are converted to output.\n @param vl The arguments referenced by the format string."]
    pub fn av_vlog(
        avcl: *mut ::std::os::raw::c_void,
        level: ::std::os::raw::c_int,
        fmt: *const ::std::os::raw::c_char,
        vl: va_list,
    );
}
extern "C" {
    #[doc = " Get the current log level\n\n @see lavu_log_constants\n\n @return Current log level"]
    pub fn av_log_get_level() -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Set the log level\n\n @see lavu_log_constants\n\n @param level Logging level"]
    pub fn av_log_set_level(level: ::std::os::raw::c_int);
}
extern "C" {
    #[doc = " Set the logging callback\n\n @note The callback must be thread safe, even if the application does not use\n       threads itself as some codecs are multithreaded.\n\n @see av_log_default_callback\n\n @param callback A logging function with a compatible signature."]
    pub fn av_log_set_callback(
        callback: ::std::option::Option<
            unsafe extern "C" fn(
                arg1: *mut ::std::os::raw::c_void,
                arg2: ::std::os::raw::c_int,
                arg3: *const ::std::os::raw::c_char,
                arg4: va_list,
            ),
        >,
    );
}
extern "C" {
    #[doc = " Default logging callback\n\n It prints the message to stderr, optionally colorizing it.\n\n @param avcl A pointer to an arbitrary struct of which the first field is a\n        pointer to an AVClass struct.\n @param level The importance level of the message expressed using a @ref\n        lavu_log_constants \"Logging Constant\".\n @param fmt The format string (printf-compatible) that specifies how\n        subsequent arguments are converted to output.\n @param vl The arguments referenced by the format string."]
    pub fn av_log_default_callback(
        avcl: *mut ::std::os::raw::c_void,
        level: ::std::os::raw::c_int,
        fmt: *const ::std::os::raw::c_char,
        vl: va_list,
    );
}
extern "C" {
    #[doc = " Return the context name\n\n @param  ctx The AVClass context\n\n @return The AVClass class_name"]
    pub fn av_default_item_name(ctx: *mut ::std::os::raw::c_void) -> *const ::std::os::raw::c_char;
}
extern "C" {
    pub fn av_default_get_category(ptr: *mut ::std::os::raw::c_void) -> AVClassCategory;
}
extern "C" {
    #[doc = " Format a line of log the same way as the default callback.\n @param line          buffer to receive the formatted line\n @param line_size     size of the buffer\n @param print_prefix  used to store whether the prefix must be printed;\n                      must point to a persistent integer initially set to 1"]
    pub fn av_log_format_line(
        ptr: *mut ::std::os::raw::c_void,
        level: ::std::os::raw::c_int,
        fmt: *const ::std::os::raw::c_char,
        vl: va_list,
        line: *mut ::std::os::raw::c_char,
        line_size: ::std::os::raw::c_int,
        print_prefix: *mut ::std::os::raw::c_int,
    );
}
extern "C" {
    #[doc = " Format a line of log the same way as the default callback.\n @param line          buffer to receive the formatted line;\n                      may be NULL if line_size is 0\n @param line_size     size of the buffer; at most line_size-1 characters will\n                      be written to the buffer, plus one null terminator\n @param print_prefix  used to store whether the prefix must be printed;\n                      must point to a persistent integer initially set to 1\n @return Returns a negative value if an error occurred, otherwise returns\n         the number of characters that would have been written for a\n         sufficiently large buffer, not including the terminating null\n         character. If the return value is not less than line_size, it means\n         that the log message was truncated to fit the buffer."]
    pub fn av_log_format_line2(
        ptr: *mut ::std::os::raw::c_void,
        level: ::std::os::raw::c_int,
        fmt: *const ::std::os::raw::c_char,
        vl: va_list,
        line: *mut ::std::os::raw::c_char,
        line_size: ::std::os::raw::c_int,
        print_prefix: *mut ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn av_log_set_flags(arg: ::std::os::raw::c_int);
}
extern "C" {
    pub fn av_log_get_flags() -> ::std::os::raw::c_int;
}
pub const AVPixelFormat_AV_PIX_FMT_NONE: AVPixelFormat = -1;
#[doc = "< planar YUV 4:2:0, 12bpp, (1 Cr & Cb sample per 2x2 Y samples)"]
pub const AVPixelFormat_AV_PIX_FMT_YUV420P: AVPixelFormat = 0;
#[doc = "< packed YUV 4:2:2, 16bpp, Y0 Cb Y1 Cr"]
pub const AVPixelFormat_AV_PIX_FMT_YUYV422: AVPixelFormat = 1;
#[doc = "< packed RGB 8:8:8, 24bpp, RGBRGB..."]
pub const AVPixelFormat_AV_PIX_FMT_RGB24: AVPixelFormat = 2;
#[doc = "< packed RGB 8:8:8, 24bpp, BGRBGR..."]
pub const AVPixelFormat_AV_PIX_FMT_BGR24: AVPixelFormat = 3;
#[doc = "< planar YUV 4:2:2, 16bpp, (1 Cr & Cb sample per 2x1 Y samples)"]
pub const AVPixelFormat_AV_PIX_FMT_YUV422P: AVPixelFormat = 4;
#[doc = "< planar YUV 4:4:4, 24bpp, (1 Cr & Cb sample per 1x1 Y samples)"]
pub const AVPixelFormat_AV_PIX_FMT_YUV444P: AVPixelFormat = 5;
#[doc = "< planar YUV 4:1:0,  9bpp, (1 Cr & Cb sample per 4x4 Y samples)"]
pub const AVPixelFormat_AV_PIX_FMT_YUV410P: AVPixelFormat = 6;
#[doc = "< planar YUV 4:1:1, 12bpp, (1 Cr & Cb sample per 4x1 Y samples)"]
pub const AVPixelFormat_AV_PIX_FMT_YUV411P: AVPixelFormat = 7;
#[doc = "<        Y        ,  8bpp"]
pub const AVPixelFormat_AV_PIX_FMT_GRAY8: AVPixelFormat = 8;
#[doc = "<        Y        ,  1bpp, 0 is white, 1 is black, in each byte pixels are ordered from the msb to the lsb"]
pub const AVPixelFormat_AV_PIX_FMT_MONOWHITE: AVPixelFormat = 9;
#[doc = "<        Y        ,  1bpp, 0 is black, 1 is white, in each byte pixels are ordered from the msb to the lsb"]
pub const AVPixelFormat_AV_PIX_FMT_MONOBLACK: AVPixelFormat = 10;
#[doc = "< 8 bits with AV_PIX_FMT_RGB32 palette"]
pub const AVPixelFormat_AV_PIX_FMT_PAL8: AVPixelFormat = 11;
#[doc = "< planar YUV 4:2:0, 12bpp, full scale (JPEG), deprecated in favor of AV_PIX_FMT_YUV420P and setting color_range"]
pub const AVPixelFormat_AV_PIX_FMT_YUVJ420P: AVPixelFormat = 12;
#[doc = "< planar YUV 4:2:2, 16bpp, full scale (JPEG), deprecated in favor of AV_PIX_FMT_YUV422P and setting color_range"]
pub const AVPixelFormat_AV_PIX_FMT_YUVJ422P: AVPixelFormat = 13;
#[doc = "< planar YUV 4:4:4, 24bpp, full scale (JPEG), deprecated in favor of AV_PIX_FMT_YUV444P and setting color_range"]
pub const AVPixelFormat_AV_PIX_FMT_YUVJ444P: AVPixelFormat = 14;
#[doc = "< packed YUV 4:2:2, 16bpp, Cb Y0 Cr Y1"]
pub const AVPixelFormat_AV_PIX_FMT_UYVY422: AVPixelFormat = 15;
#[doc = "< packed YUV 4:1:1, 12bpp, Cb Y0 Y1 Cr Y2 Y3"]
pub const AVPixelFormat_AV_PIX_FMT_UYYVYY411: AVPixelFormat = 16;
#[doc = "< packed RGB 3:3:2,  8bpp, (msb)2B 3G 3R(lsb)"]
pub const AVPixelFormat_AV_PIX_FMT_BGR8: AVPixelFormat = 17;
#[doc = "< packed RGB 1:2:1 bitstream,  4bpp, (msb)1B 2G 1R(lsb), a byte contains two pixels, the first pixel in the byte is the one composed by the 4 msb bits"]
pub const AVPixelFormat_AV_PIX_FMT_BGR4: AVPixelFormat = 18;
#[doc = "< packed RGB 1:2:1,  8bpp, (msb)1B 2G 1R(lsb)"]
pub const AVPixelFormat_AV_PIX_FMT_BGR4_BYTE: AVPixelFormat = 19;
#[doc = "< packed RGB 3:3:2,  8bpp, (msb)3R 3G 2B(lsb)"]
pub const AVPixelFormat_AV_PIX_FMT_RGB8: AVPixelFormat = 20;
#[doc = "< packed RGB 1:2:1 bitstream,  4bpp, (msb)1R 2G 1B(lsb), a byte contains two pixels, the first pixel in the byte is the one composed by the 4 msb bits"]
pub const AVPixelFormat_AV_PIX_FMT_RGB4: AVPixelFormat = 21;
#[doc = "< packed RGB 1:2:1,  8bpp, (msb)1R 2G 1B(lsb)"]
pub const AVPixelFormat_AV_PIX_FMT_RGB4_BYTE: AVPixelFormat = 22;
#[doc = "< planar YUV 4:2:0, 12bpp, 1 plane for Y and 1 plane for the UV components, which are interleaved (first byte U and the following byte V)"]
pub const AVPixelFormat_AV_PIX_FMT_NV12: AVPixelFormat = 23;
#[doc = "< as above, but U and V bytes are swapped"]
pub const AVPixelFormat_AV_PIX_FMT_NV21: AVPixelFormat = 24;
#[doc = "< packed ARGB 8:8:8:8, 32bpp, ARGBARGB..."]
pub const AVPixelFormat_AV_PIX_FMT_ARGB: AVPixelFormat = 25;
#[doc = "< packed RGBA 8:8:8:8, 32bpp, RGBARGBA..."]
pub const AVPixelFormat_AV_PIX_FMT_RGBA: AVPixelFormat = 26;
#[doc = "< packed ABGR 8:8:8:8, 32bpp, ABGRABGR..."]
pub const AVPixelFormat_AV_PIX_FMT_ABGR: AVPixelFormat = 27;
#[doc = "< packed BGRA 8:8:8:8, 32bpp, BGRABGRA..."]
pub const AVPixelFormat_AV_PIX_FMT_BGRA: AVPixelFormat = 28;
#[doc = "<        Y        , 16bpp, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GRAY16BE: AVPixelFormat = 29;
#[doc = "<        Y        , 16bpp, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GRAY16LE: AVPixelFormat = 30;
#[doc = "< planar YUV 4:4:0 (1 Cr & Cb sample per 1x2 Y samples)"]
pub const AVPixelFormat_AV_PIX_FMT_YUV440P: AVPixelFormat = 31;
#[doc = "< planar YUV 4:4:0 full scale (JPEG), deprecated in favor of AV_PIX_FMT_YUV440P and setting color_range"]
pub const AVPixelFormat_AV_PIX_FMT_YUVJ440P: AVPixelFormat = 32;
#[doc = "< planar YUV 4:2:0, 20bpp, (1 Cr & Cb sample per 2x2 Y & A samples)"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA420P: AVPixelFormat = 33;
#[doc = "< packed RGB 16:16:16, 48bpp, 16R, 16G, 16B, the 2-byte value for each R/G/B component is stored as big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_RGB48BE: AVPixelFormat = 34;
#[doc = "< packed RGB 16:16:16, 48bpp, 16R, 16G, 16B, the 2-byte value for each R/G/B component is stored as little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_RGB48LE: AVPixelFormat = 35;
#[doc = "< packed RGB 5:6:5, 16bpp, (msb)   5R 6G 5B(lsb), big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_RGB565BE: AVPixelFormat = 36;
#[doc = "< packed RGB 5:6:5, 16bpp, (msb)   5R 6G 5B(lsb), little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_RGB565LE: AVPixelFormat = 37;
#[doc = "< packed RGB 5:5:5, 16bpp, (msb)1X 5R 5G 5B(lsb), big-endian   , X=unused/undefined"]
pub const AVPixelFormat_AV_PIX_FMT_RGB555BE: AVPixelFormat = 38;
#[doc = "< packed RGB 5:5:5, 16bpp, (msb)1X 5R 5G 5B(lsb), little-endian, X=unused/undefined"]
pub const AVPixelFormat_AV_PIX_FMT_RGB555LE: AVPixelFormat = 39;
#[doc = "< packed BGR 5:6:5, 16bpp, (msb)   5B 6G 5R(lsb), big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_BGR565BE: AVPixelFormat = 40;
#[doc = "< packed BGR 5:6:5, 16bpp, (msb)   5B 6G 5R(lsb), little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_BGR565LE: AVPixelFormat = 41;
#[doc = "< packed BGR 5:5:5, 16bpp, (msb)1X 5B 5G 5R(lsb), big-endian   , X=unused/undefined"]
pub const AVPixelFormat_AV_PIX_FMT_BGR555BE: AVPixelFormat = 42;
#[doc = "< packed BGR 5:5:5, 16bpp, (msb)1X 5B 5G 5R(lsb), little-endian, X=unused/undefined"]
pub const AVPixelFormat_AV_PIX_FMT_BGR555LE: AVPixelFormat = 43;
#[doc = "  Hardware acceleration through VA-API, data[3] contains a\n  VASurfaceID."]
pub const AVPixelFormat_AV_PIX_FMT_VAAPI: AVPixelFormat = 44;
#[doc = "< planar YUV 4:2:0, 24bpp, (1 Cr & Cb sample per 2x2 Y samples), little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV420P16LE: AVPixelFormat = 45;
#[doc = "< planar YUV 4:2:0, 24bpp, (1 Cr & Cb sample per 2x2 Y samples), big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV420P16BE: AVPixelFormat = 46;
#[doc = "< planar YUV 4:2:2, 32bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV422P16LE: AVPixelFormat = 47;
#[doc = "< planar YUV 4:2:2, 32bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV422P16BE: AVPixelFormat = 48;
#[doc = "< planar YUV 4:4:4, 48bpp, (1 Cr & Cb sample per 1x1 Y samples), little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV444P16LE: AVPixelFormat = 49;
#[doc = "< planar YUV 4:4:4, 48bpp, (1 Cr & Cb sample per 1x1 Y samples), big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV444P16BE: AVPixelFormat = 50;
#[doc = "< HW decoding through DXVA2, Picture.data[3] contains a LPDIRECT3DSURFACE9 pointer"]
pub const AVPixelFormat_AV_PIX_FMT_DXVA2_VLD: AVPixelFormat = 51;
#[doc = "< packed RGB 4:4:4, 16bpp, (msb)4X 4R 4G 4B(lsb), little-endian, X=unused/undefined"]
pub const AVPixelFormat_AV_PIX_FMT_RGB444LE: AVPixelFormat = 52;
#[doc = "< packed RGB 4:4:4, 16bpp, (msb)4X 4R 4G 4B(lsb), big-endian,    X=unused/undefined"]
pub const AVPixelFormat_AV_PIX_FMT_RGB444BE: AVPixelFormat = 53;
#[doc = "< packed BGR 4:4:4, 16bpp, (msb)4X 4B 4G 4R(lsb), little-endian, X=unused/undefined"]
pub const AVPixelFormat_AV_PIX_FMT_BGR444LE: AVPixelFormat = 54;
#[doc = "< packed BGR 4:4:4, 16bpp, (msb)4X 4B 4G 4R(lsb), big-endian,    X=unused/undefined"]
pub const AVPixelFormat_AV_PIX_FMT_BGR444BE: AVPixelFormat = 55;
#[doc = "< 8 bits gray, 8 bits alpha"]
pub const AVPixelFormat_AV_PIX_FMT_YA8: AVPixelFormat = 56;
#[doc = "< alias for AV_PIX_FMT_YA8"]
pub const AVPixelFormat_AV_PIX_FMT_Y400A: AVPixelFormat = 56;
#[doc = "< alias for AV_PIX_FMT_YA8"]
pub const AVPixelFormat_AV_PIX_FMT_GRAY8A: AVPixelFormat = 56;
#[doc = "< packed RGB 16:16:16, 48bpp, 16B, 16G, 16R, the 2-byte value for each R/G/B component is stored as big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_BGR48BE: AVPixelFormat = 57;
#[doc = "< packed RGB 16:16:16, 48bpp, 16B, 16G, 16R, the 2-byte value for each R/G/B component is stored as little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_BGR48LE: AVPixelFormat = 58;
#[doc = "< planar YUV 4:2:0, 13.5bpp, (1 Cr & Cb sample per 2x2 Y samples), big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV420P9BE: AVPixelFormat = 59;
#[doc = "< planar YUV 4:2:0, 13.5bpp, (1 Cr & Cb sample per 2x2 Y samples), little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV420P9LE: AVPixelFormat = 60;
#[doc = "< planar YUV 4:2:0, 15bpp, (1 Cr & Cb sample per 2x2 Y samples), big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV420P10BE: AVPixelFormat = 61;
#[doc = "< planar YUV 4:2:0, 15bpp, (1 Cr & Cb sample per 2x2 Y samples), little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV420P10LE: AVPixelFormat = 62;
#[doc = "< planar YUV 4:2:2, 20bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV422P10BE: AVPixelFormat = 63;
#[doc = "< planar YUV 4:2:2, 20bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV422P10LE: AVPixelFormat = 64;
#[doc = "< planar YUV 4:4:4, 27bpp, (1 Cr & Cb sample per 1x1 Y samples), big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV444P9BE: AVPixelFormat = 65;
#[doc = "< planar YUV 4:4:4, 27bpp, (1 Cr & Cb sample per 1x1 Y samples), little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV444P9LE: AVPixelFormat = 66;
#[doc = "< planar YUV 4:4:4, 30bpp, (1 Cr & Cb sample per 1x1 Y samples), big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV444P10BE: AVPixelFormat = 67;
#[doc = "< planar YUV 4:4:4, 30bpp, (1 Cr & Cb sample per 1x1 Y samples), little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV444P10LE: AVPixelFormat = 68;
#[doc = "< planar YUV 4:2:2, 18bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV422P9BE: AVPixelFormat = 69;
#[doc = "< planar YUV 4:2:2, 18bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV422P9LE: AVPixelFormat = 70;
#[doc = "< planar GBR 4:4:4 24bpp"]
pub const AVPixelFormat_AV_PIX_FMT_GBRP: AVPixelFormat = 71;
pub const AVPixelFormat_AV_PIX_FMT_GBR24P: AVPixelFormat = 71;
#[doc = "< planar GBR 4:4:4 27bpp, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GBRP9BE: AVPixelFormat = 72;
#[doc = "< planar GBR 4:4:4 27bpp, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GBRP9LE: AVPixelFormat = 73;
#[doc = "< planar GBR 4:4:4 30bpp, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GBRP10BE: AVPixelFormat = 74;
#[doc = "< planar GBR 4:4:4 30bpp, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GBRP10LE: AVPixelFormat = 75;
#[doc = "< planar GBR 4:4:4 48bpp, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GBRP16BE: AVPixelFormat = 76;
#[doc = "< planar GBR 4:4:4 48bpp, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GBRP16LE: AVPixelFormat = 77;
#[doc = "< planar YUV 4:2:2 24bpp, (1 Cr & Cb sample per 2x1 Y & A samples)"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA422P: AVPixelFormat = 78;
#[doc = "< planar YUV 4:4:4 32bpp, (1 Cr & Cb sample per 1x1 Y & A samples)"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA444P: AVPixelFormat = 79;
#[doc = "< planar YUV 4:2:0 22.5bpp, (1 Cr & Cb sample per 2x2 Y & A samples), big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA420P9BE: AVPixelFormat = 80;
#[doc = "< planar YUV 4:2:0 22.5bpp, (1 Cr & Cb sample per 2x2 Y & A samples), little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA420P9LE: AVPixelFormat = 81;
#[doc = "< planar YUV 4:2:2 27bpp, (1 Cr & Cb sample per 2x1 Y & A samples), big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA422P9BE: AVPixelFormat = 82;
#[doc = "< planar YUV 4:2:2 27bpp, (1 Cr & Cb sample per 2x1 Y & A samples), little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA422P9LE: AVPixelFormat = 83;
#[doc = "< planar YUV 4:4:4 36bpp, (1 Cr & Cb sample per 1x1 Y & A samples), big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA444P9BE: AVPixelFormat = 84;
#[doc = "< planar YUV 4:4:4 36bpp, (1 Cr & Cb sample per 1x1 Y & A samples), little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA444P9LE: AVPixelFormat = 85;
#[doc = "< planar YUV 4:2:0 25bpp, (1 Cr & Cb sample per 2x2 Y & A samples, big-endian)"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA420P10BE: AVPixelFormat = 86;
#[doc = "< planar YUV 4:2:0 25bpp, (1 Cr & Cb sample per 2x2 Y & A samples, little-endian)"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA420P10LE: AVPixelFormat = 87;
#[doc = "< planar YUV 4:2:2 30bpp, (1 Cr & Cb sample per 2x1 Y & A samples, big-endian)"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA422P10BE: AVPixelFormat = 88;
#[doc = "< planar YUV 4:2:2 30bpp, (1 Cr & Cb sample per 2x1 Y & A samples, little-endian)"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA422P10LE: AVPixelFormat = 89;
#[doc = "< planar YUV 4:4:4 40bpp, (1 Cr & Cb sample per 1x1 Y & A samples, big-endian)"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA444P10BE: AVPixelFormat = 90;
#[doc = "< planar YUV 4:4:4 40bpp, (1 Cr & Cb sample per 1x1 Y & A samples, little-endian)"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA444P10LE: AVPixelFormat = 91;
#[doc = "< planar YUV 4:2:0 40bpp, (1 Cr & Cb sample per 2x2 Y & A samples, big-endian)"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA420P16BE: AVPixelFormat = 92;
#[doc = "< planar YUV 4:2:0 40bpp, (1 Cr & Cb sample per 2x2 Y & A samples, little-endian)"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA420P16LE: AVPixelFormat = 93;
#[doc = "< planar YUV 4:2:2 48bpp, (1 Cr & Cb sample per 2x1 Y & A samples, big-endian)"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA422P16BE: AVPixelFormat = 94;
#[doc = "< planar YUV 4:2:2 48bpp, (1 Cr & Cb sample per 2x1 Y & A samples, little-endian)"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA422P16LE: AVPixelFormat = 95;
#[doc = "< planar YUV 4:4:4 64bpp, (1 Cr & Cb sample per 1x1 Y & A samples, big-endian)"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA444P16BE: AVPixelFormat = 96;
#[doc = "< planar YUV 4:4:4 64bpp, (1 Cr & Cb sample per 1x1 Y & A samples, little-endian)"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA444P16LE: AVPixelFormat = 97;
#[doc = "< HW acceleration through VDPAU, Picture.data[3] contains a VdpVideoSurface"]
pub const AVPixelFormat_AV_PIX_FMT_VDPAU: AVPixelFormat = 98;
#[doc = "< packed XYZ 4:4:4, 36 bpp, (msb) 12X, 12Y, 12Z (lsb), the 2-byte value for each X/Y/Z is stored as little-endian, the 4 lower bits are set to 0"]
pub const AVPixelFormat_AV_PIX_FMT_XYZ12LE: AVPixelFormat = 99;
#[doc = "< packed XYZ 4:4:4, 36 bpp, (msb) 12X, 12Y, 12Z (lsb), the 2-byte value for each X/Y/Z is stored as big-endian, the 4 lower bits are set to 0"]
pub const AVPixelFormat_AV_PIX_FMT_XYZ12BE: AVPixelFormat = 100;
#[doc = "< interleaved chroma YUV 4:2:2, 16bpp, (1 Cr & Cb sample per 2x1 Y samples)"]
pub const AVPixelFormat_AV_PIX_FMT_NV16: AVPixelFormat = 101;
#[doc = "< interleaved chroma YUV 4:2:2, 20bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_NV20LE: AVPixelFormat = 102;
#[doc = "< interleaved chroma YUV 4:2:2, 20bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_NV20BE: AVPixelFormat = 103;
#[doc = "< packed RGBA 16:16:16:16, 64bpp, 16R, 16G, 16B, 16A, the 2-byte value for each R/G/B/A component is stored as big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_RGBA64BE: AVPixelFormat = 104;
#[doc = "< packed RGBA 16:16:16:16, 64bpp, 16R, 16G, 16B, 16A, the 2-byte value for each R/G/B/A component is stored as little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_RGBA64LE: AVPixelFormat = 105;
#[doc = "< packed RGBA 16:16:16:16, 64bpp, 16B, 16G, 16R, 16A, the 2-byte value for each R/G/B/A component is stored as big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_BGRA64BE: AVPixelFormat = 106;
#[doc = "< packed RGBA 16:16:16:16, 64bpp, 16B, 16G, 16R, 16A, the 2-byte value for each R/G/B/A component is stored as little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_BGRA64LE: AVPixelFormat = 107;
#[doc = "< packed YUV 4:2:2, 16bpp, Y0 Cr Y1 Cb"]
pub const AVPixelFormat_AV_PIX_FMT_YVYU422: AVPixelFormat = 108;
#[doc = "< 16 bits gray, 16 bits alpha (big-endian)"]
pub const AVPixelFormat_AV_PIX_FMT_YA16BE: AVPixelFormat = 109;
#[doc = "< 16 bits gray, 16 bits alpha (little-endian)"]
pub const AVPixelFormat_AV_PIX_FMT_YA16LE: AVPixelFormat = 110;
#[doc = "< planar GBRA 4:4:4:4 32bpp"]
pub const AVPixelFormat_AV_PIX_FMT_GBRAP: AVPixelFormat = 111;
#[doc = "< planar GBRA 4:4:4:4 64bpp, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GBRAP16BE: AVPixelFormat = 112;
#[doc = "< planar GBRA 4:4:4:4 64bpp, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GBRAP16LE: AVPixelFormat = 113;
#[doc = " HW acceleration through QSV, data[3] contains a pointer to the\n mfxFrameSurface1 structure.\n\n Before FFmpeg 5.0:\n mfxFrameSurface1.Data.MemId contains a pointer when importing\n the following frames as QSV frames:\n\n VAAPI:\n mfxFrameSurface1.Data.MemId contains a pointer to VASurfaceID\n\n DXVA2:\n mfxFrameSurface1.Data.MemId contains a pointer to IDirect3DSurface9\n\n FFmpeg 5.0 and above:\n mfxFrameSurface1.Data.MemId contains a pointer to the mfxHDLPair\n structure when importing the following frames as QSV frames:\n\n VAAPI:\n mfxHDLPair.first contains a VASurfaceID pointer.\n mfxHDLPair.second is always MFX_INFINITE.\n\n DXVA2:\n mfxHDLPair.first contains IDirect3DSurface9 pointer.\n mfxHDLPair.second is always MFX_INFINITE.\n\n D3D11:\n mfxHDLPair.first contains a ID3D11Texture2D pointer.\n mfxHDLPair.second contains the texture array index of the frame if the\n ID3D11Texture2D is an array texture, or always MFX_INFINITE if it is a\n normal texture."]
pub const AVPixelFormat_AV_PIX_FMT_QSV: AVPixelFormat = 114;
#[doc = " HW acceleration though MMAL, data[3] contains a pointer to the\n MMAL_BUFFER_HEADER_T structure."]
pub const AVPixelFormat_AV_PIX_FMT_MMAL: AVPixelFormat = 115;
#[doc = "< HW decoding through Direct3D11 via old API, Picture.data[3] contains a ID3D11VideoDecoderOutputView pointer"]
pub const AVPixelFormat_AV_PIX_FMT_D3D11VA_VLD: AVPixelFormat = 116;
#[doc = " HW acceleration through CUDA. data[i] contain CUdeviceptr pointers\n exactly as for system memory frames."]
pub const AVPixelFormat_AV_PIX_FMT_CUDA: AVPixelFormat = 117;
#[doc = "< packed RGB 8:8:8, 32bpp, XRGBXRGB...   X=unused/undefined"]
pub const AVPixelFormat_AV_PIX_FMT_0RGB: AVPixelFormat = 118;
#[doc = "< packed RGB 8:8:8, 32bpp, RGBXRGBX...   X=unused/undefined"]
pub const AVPixelFormat_AV_PIX_FMT_RGB0: AVPixelFormat = 119;
#[doc = "< packed BGR 8:8:8, 32bpp, XBGRXBGR...   X=unused/undefined"]
pub const AVPixelFormat_AV_PIX_FMT_0BGR: AVPixelFormat = 120;
#[doc = "< packed BGR 8:8:8, 32bpp, BGRXBGRX...   X=unused/undefined"]
pub const AVPixelFormat_AV_PIX_FMT_BGR0: AVPixelFormat = 121;
#[doc = "< planar YUV 4:2:0,18bpp, (1 Cr & Cb sample per 2x2 Y samples), big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV420P12BE: AVPixelFormat = 122;
#[doc = "< planar YUV 4:2:0,18bpp, (1 Cr & Cb sample per 2x2 Y samples), little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV420P12LE: AVPixelFormat = 123;
#[doc = "< planar YUV 4:2:0,21bpp, (1 Cr & Cb sample per 2x2 Y samples), big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV420P14BE: AVPixelFormat = 124;
#[doc = "< planar YUV 4:2:0,21bpp, (1 Cr & Cb sample per 2x2 Y samples), little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV420P14LE: AVPixelFormat = 125;
#[doc = "< planar YUV 4:2:2,24bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV422P12BE: AVPixelFormat = 126;
#[doc = "< planar YUV 4:2:2,24bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV422P12LE: AVPixelFormat = 127;
#[doc = "< planar YUV 4:2:2,28bpp, (1 Cr & Cb sample per 2x1 Y samples), big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV422P14BE: AVPixelFormat = 128;
#[doc = "< planar YUV 4:2:2,28bpp, (1 Cr & Cb sample per 2x1 Y samples), little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV422P14LE: AVPixelFormat = 129;
#[doc = "< planar YUV 4:4:4,36bpp, (1 Cr & Cb sample per 1x1 Y samples), big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV444P12BE: AVPixelFormat = 130;
#[doc = "< planar YUV 4:4:4,36bpp, (1 Cr & Cb sample per 1x1 Y samples), little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV444P12LE: AVPixelFormat = 131;
#[doc = "< planar YUV 4:4:4,42bpp, (1 Cr & Cb sample per 1x1 Y samples), big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV444P14BE: AVPixelFormat = 132;
#[doc = "< planar YUV 4:4:4,42bpp, (1 Cr & Cb sample per 1x1 Y samples), little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV444P14LE: AVPixelFormat = 133;
#[doc = "< planar GBR 4:4:4 36bpp, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GBRP12BE: AVPixelFormat = 134;
#[doc = "< planar GBR 4:4:4 36bpp, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GBRP12LE: AVPixelFormat = 135;
#[doc = "< planar GBR 4:4:4 42bpp, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GBRP14BE: AVPixelFormat = 136;
#[doc = "< planar GBR 4:4:4 42bpp, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GBRP14LE: AVPixelFormat = 137;
#[doc = "< planar YUV 4:1:1, 12bpp, (1 Cr & Cb sample per 4x1 Y samples) full scale (JPEG), deprecated in favor of AV_PIX_FMT_YUV411P and setting color_range"]
pub const AVPixelFormat_AV_PIX_FMT_YUVJ411P: AVPixelFormat = 138;
#[doc = "< bayer, BGBG..(odd line), GRGR..(even line), 8-bit samples"]
pub const AVPixelFormat_AV_PIX_FMT_BAYER_BGGR8: AVPixelFormat = 139;
#[doc = "< bayer, RGRG..(odd line), GBGB..(even line), 8-bit samples"]
pub const AVPixelFormat_AV_PIX_FMT_BAYER_RGGB8: AVPixelFormat = 140;
#[doc = "< bayer, GBGB..(odd line), RGRG..(even line), 8-bit samples"]
pub const AVPixelFormat_AV_PIX_FMT_BAYER_GBRG8: AVPixelFormat = 141;
#[doc = "< bayer, GRGR..(odd line), BGBG..(even line), 8-bit samples"]
pub const AVPixelFormat_AV_PIX_FMT_BAYER_GRBG8: AVPixelFormat = 142;
#[doc = "< bayer, BGBG..(odd line), GRGR..(even line), 16-bit samples, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_BAYER_BGGR16LE: AVPixelFormat = 143;
#[doc = "< bayer, BGBG..(odd line), GRGR..(even line), 16-bit samples, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_BAYER_BGGR16BE: AVPixelFormat = 144;
#[doc = "< bayer, RGRG..(odd line), GBGB..(even line), 16-bit samples, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_BAYER_RGGB16LE: AVPixelFormat = 145;
#[doc = "< bayer, RGRG..(odd line), GBGB..(even line), 16-bit samples, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_BAYER_RGGB16BE: AVPixelFormat = 146;
#[doc = "< bayer, GBGB..(odd line), RGRG..(even line), 16-bit samples, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_BAYER_GBRG16LE: AVPixelFormat = 147;
#[doc = "< bayer, GBGB..(odd line), RGRG..(even line), 16-bit samples, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_BAYER_GBRG16BE: AVPixelFormat = 148;
#[doc = "< bayer, GRGR..(odd line), BGBG..(even line), 16-bit samples, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_BAYER_GRBG16LE: AVPixelFormat = 149;
#[doc = "< bayer, GRGR..(odd line), BGBG..(even line), 16-bit samples, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_BAYER_GRBG16BE: AVPixelFormat = 150;
#[doc = "< planar YUV 4:4:0,20bpp, (1 Cr & Cb sample per 1x2 Y samples), little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV440P10LE: AVPixelFormat = 151;
#[doc = "< planar YUV 4:4:0,20bpp, (1 Cr & Cb sample per 1x2 Y samples), big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV440P10BE: AVPixelFormat = 152;
#[doc = "< planar YUV 4:4:0,24bpp, (1 Cr & Cb sample per 1x2 Y samples), little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV440P12LE: AVPixelFormat = 153;
#[doc = "< planar YUV 4:4:0,24bpp, (1 Cr & Cb sample per 1x2 Y samples), big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUV440P12BE: AVPixelFormat = 154;
#[doc = "< packed AYUV 4:4:4,64bpp (1 Cr & Cb sample per 1x1 Y & A samples), little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_AYUV64LE: AVPixelFormat = 155;
#[doc = "< packed AYUV 4:4:4,64bpp (1 Cr & Cb sample per 1x1 Y & A samples), big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_AYUV64BE: AVPixelFormat = 156;
#[doc = "< hardware decoding through Videotoolbox"]
pub const AVPixelFormat_AV_PIX_FMT_VIDEOTOOLBOX: AVPixelFormat = 157;
#[doc = "< like NV12, with 10bpp per component, data in the high bits, zeros in the low bits, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_P010LE: AVPixelFormat = 158;
#[doc = "< like NV12, with 10bpp per component, data in the high bits, zeros in the low bits, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_P010BE: AVPixelFormat = 159;
#[doc = "< planar GBR 4:4:4:4 48bpp, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GBRAP12BE: AVPixelFormat = 160;
#[doc = "< planar GBR 4:4:4:4 48bpp, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GBRAP12LE: AVPixelFormat = 161;
#[doc = "< planar GBR 4:4:4:4 40bpp, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GBRAP10BE: AVPixelFormat = 162;
#[doc = "< planar GBR 4:4:4:4 40bpp, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GBRAP10LE: AVPixelFormat = 163;
#[doc = "< hardware decoding through MediaCodec"]
pub const AVPixelFormat_AV_PIX_FMT_MEDIACODEC: AVPixelFormat = 164;
#[doc = "<        Y        , 12bpp, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GRAY12BE: AVPixelFormat = 165;
#[doc = "<        Y        , 12bpp, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GRAY12LE: AVPixelFormat = 166;
#[doc = "<        Y        , 10bpp, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GRAY10BE: AVPixelFormat = 167;
#[doc = "<        Y        , 10bpp, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GRAY10LE: AVPixelFormat = 168;
#[doc = "< like NV12, with 16bpp per component, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_P016LE: AVPixelFormat = 169;
#[doc = "< like NV12, with 16bpp per component, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_P016BE: AVPixelFormat = 170;
#[doc = " Hardware surfaces for Direct3D11.\n\n This is preferred over the legacy AV_PIX_FMT_D3D11VA_VLD. The new D3D11\n hwaccel API and filtering support AV_PIX_FMT_D3D11 only.\n\n data[0] contains a ID3D11Texture2D pointer, and data[1] contains the\n texture array index of the frame as intptr_t if the ID3D11Texture2D is\n an array texture (or always 0 if it's a normal texture)."]
pub const AVPixelFormat_AV_PIX_FMT_D3D11: AVPixelFormat = 171;
#[doc = "<        Y        , 9bpp, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GRAY9BE: AVPixelFormat = 172;
#[doc = "<        Y        , 9bpp, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GRAY9LE: AVPixelFormat = 173;
#[doc = "< IEEE-754 single precision planar GBR 4:4:4,     96bpp, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GBRPF32BE: AVPixelFormat = 174;
#[doc = "< IEEE-754 single precision planar GBR 4:4:4,     96bpp, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GBRPF32LE: AVPixelFormat = 175;
#[doc = "< IEEE-754 single precision planar GBRA 4:4:4:4, 128bpp, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GBRAPF32BE: AVPixelFormat = 176;
#[doc = "< IEEE-754 single precision planar GBRA 4:4:4:4, 128bpp, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GBRAPF32LE: AVPixelFormat = 177;
#[doc = " DRM-managed buffers exposed through PRIME buffer sharing.\n\n data[0] points to an AVDRMFrameDescriptor."]
pub const AVPixelFormat_AV_PIX_FMT_DRM_PRIME: AVPixelFormat = 178;
#[doc = " Hardware surfaces for OpenCL.\n\n data[i] contain 2D image objects (typed in C as cl_mem, used\n in OpenCL as image2d_t) for each plane of the surface."]
pub const AVPixelFormat_AV_PIX_FMT_OPENCL: AVPixelFormat = 179;
#[doc = "<        Y        , 14bpp, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GRAY14BE: AVPixelFormat = 180;
#[doc = "<        Y        , 14bpp, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GRAY14LE: AVPixelFormat = 181;
#[doc = "< IEEE-754 single precision Y, 32bpp, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GRAYF32BE: AVPixelFormat = 182;
#[doc = "< IEEE-754 single precision Y, 32bpp, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GRAYF32LE: AVPixelFormat = 183;
#[doc = "< planar YUV 4:2:2,24bpp, (1 Cr & Cb sample per 2x1 Y samples), 12b alpha, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA422P12BE: AVPixelFormat = 184;
#[doc = "< planar YUV 4:2:2,24bpp, (1 Cr & Cb sample per 2x1 Y samples), 12b alpha, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA422P12LE: AVPixelFormat = 185;
#[doc = "< planar YUV 4:4:4,36bpp, (1 Cr & Cb sample per 1x1 Y samples), 12b alpha, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA444P12BE: AVPixelFormat = 186;
#[doc = "< planar YUV 4:4:4,36bpp, (1 Cr & Cb sample per 1x1 Y samples), 12b alpha, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_YUVA444P12LE: AVPixelFormat = 187;
#[doc = "< planar YUV 4:4:4, 24bpp, 1 plane for Y and 1 plane for the UV components, which are interleaved (first byte U and the following byte V)"]
pub const AVPixelFormat_AV_PIX_FMT_NV24: AVPixelFormat = 188;
#[doc = "< as above, but U and V bytes are swapped"]
pub const AVPixelFormat_AV_PIX_FMT_NV42: AVPixelFormat = 189;
#[doc = " Vulkan hardware images.\n\n data[0] points to an AVVkFrame"]
pub const AVPixelFormat_AV_PIX_FMT_VULKAN: AVPixelFormat = 190;
#[doc = "< packed YUV 4:2:2 like YUYV422, 20bpp, data in the high bits, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_Y210BE: AVPixelFormat = 191;
#[doc = "< packed YUV 4:2:2 like YUYV422, 20bpp, data in the high bits, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_Y210LE: AVPixelFormat = 192;
#[doc = "< packed RGB 10:10:10, 30bpp, (msb)2X 10R 10G 10B(lsb), little-endian, X=unused/undefined"]
pub const AVPixelFormat_AV_PIX_FMT_X2RGB10LE: AVPixelFormat = 193;
#[doc = "< packed RGB 10:10:10, 30bpp, (msb)2X 10R 10G 10B(lsb), big-endian, X=unused/undefined"]
pub const AVPixelFormat_AV_PIX_FMT_X2RGB10BE: AVPixelFormat = 194;
#[doc = "< packed BGR 10:10:10, 30bpp, (msb)2X 10B 10G 10R(lsb), little-endian, X=unused/undefined"]
pub const AVPixelFormat_AV_PIX_FMT_X2BGR10LE: AVPixelFormat = 195;
#[doc = "< packed BGR 10:10:10, 30bpp, (msb)2X 10B 10G 10R(lsb), big-endian, X=unused/undefined"]
pub const AVPixelFormat_AV_PIX_FMT_X2BGR10BE: AVPixelFormat = 196;
#[doc = "< interleaved chroma YUV 4:2:2, 20bpp, data in the high bits, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_P210BE: AVPixelFormat = 197;
#[doc = "< interleaved chroma YUV 4:2:2, 20bpp, data in the high bits, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_P210LE: AVPixelFormat = 198;
#[doc = "< interleaved chroma YUV 4:4:4, 30bpp, data in the high bits, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_P410BE: AVPixelFormat = 199;
#[doc = "< interleaved chroma YUV 4:4:4, 30bpp, data in the high bits, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_P410LE: AVPixelFormat = 200;
#[doc = "< interleaved chroma YUV 4:2:2, 32bpp, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_P216BE: AVPixelFormat = 201;
#[doc = "< interleaved chroma YUV 4:2:2, 32bpp, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_P216LE: AVPixelFormat = 202;
#[doc = "< interleaved chroma YUV 4:4:4, 48bpp, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_P416BE: AVPixelFormat = 203;
#[doc = "< interleaved chroma YUV 4:4:4, 48bpp, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_P416LE: AVPixelFormat = 204;
#[doc = "< packed VUYA 4:4:4, 32bpp, VUYAVUYA..."]
pub const AVPixelFormat_AV_PIX_FMT_VUYA: AVPixelFormat = 205;
#[doc = "< IEEE-754 half precision packed RGBA 16:16:16:16, 64bpp, RGBARGBA..., big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_RGBAF16BE: AVPixelFormat = 206;
#[doc = "< IEEE-754 half precision packed RGBA 16:16:16:16, 64bpp, RGBARGBA..., little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_RGBAF16LE: AVPixelFormat = 207;
#[doc = "< packed VUYX 4:4:4, 32bpp, Variant of VUYA where alpha channel is left undefined"]
pub const AVPixelFormat_AV_PIX_FMT_VUYX: AVPixelFormat = 208;
#[doc = "< like NV12, with 12bpp per component, data in the high bits, zeros in the low bits, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_P012LE: AVPixelFormat = 209;
#[doc = "< like NV12, with 12bpp per component, data in the high bits, zeros in the low bits, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_P012BE: AVPixelFormat = 210;
#[doc = "< packed YUV 4:2:2 like YUYV422, 24bpp, data in the high bits, zeros in the low bits, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_Y212BE: AVPixelFormat = 211;
#[doc = "< packed YUV 4:2:2 like YUYV422, 24bpp, data in the high bits, zeros in the low bits, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_Y212LE: AVPixelFormat = 212;
#[doc = "< packed XVYU 4:4:4, 32bpp, (msb)2X 10V 10Y 10U(lsb), big-endian, variant of Y410 where alpha channel is left undefined"]
pub const AVPixelFormat_AV_PIX_FMT_XV30BE: AVPixelFormat = 213;
#[doc = "< packed XVYU 4:4:4, 32bpp, (msb)2X 10V 10Y 10U(lsb), little-endian, variant of Y410 where alpha channel is left undefined"]
pub const AVPixelFormat_AV_PIX_FMT_XV30LE: AVPixelFormat = 214;
#[doc = "< packed XVYU 4:4:4, 48bpp, data in the high bits, zeros in the low bits, big-endian, variant of Y412 where alpha channel is left undefined"]
pub const AVPixelFormat_AV_PIX_FMT_XV36BE: AVPixelFormat = 215;
#[doc = "< packed XVYU 4:4:4, 48bpp, data in the high bits, zeros in the low bits, little-endian, variant of Y412 where alpha channel is left undefined"]
pub const AVPixelFormat_AV_PIX_FMT_XV36LE: AVPixelFormat = 216;
#[doc = "< IEEE-754 single precision packed RGB 32:32:32, 96bpp, RGBRGB..., big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_RGBF32BE: AVPixelFormat = 217;
#[doc = "< IEEE-754 single precision packed RGB 32:32:32, 96bpp, RGBRGB..., little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_RGBF32LE: AVPixelFormat = 218;
#[doc = "< IEEE-754 single precision packed RGBA 32:32:32:32, 128bpp, RGBARGBA..., big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_RGBAF32BE: AVPixelFormat = 219;
#[doc = "< IEEE-754 single precision packed RGBA 32:32:32:32, 128bpp, RGBARGBA..., little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_RGBAF32LE: AVPixelFormat = 220;
#[doc = "< interleaved chroma YUV 4:2:2, 24bpp, data in the high bits, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_P212BE: AVPixelFormat = 221;
#[doc = "< interleaved chroma YUV 4:2:2, 24bpp, data in the high bits, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_P212LE: AVPixelFormat = 222;
#[doc = "< interleaved chroma YUV 4:4:4, 36bpp, data in the high bits, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_P412BE: AVPixelFormat = 223;
#[doc = "< interleaved chroma YUV 4:4:4, 36bpp, data in the high bits, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_P412LE: AVPixelFormat = 224;
#[doc = "< planar GBR 4:4:4:4 56bpp, big-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GBRAP14BE: AVPixelFormat = 225;
#[doc = "< planar GBR 4:4:4:4 56bpp, little-endian"]
pub const AVPixelFormat_AV_PIX_FMT_GBRAP14LE: AVPixelFormat = 226;
#[doc = " Hardware surfaces for Direct3D 12.\n\n data[0] points to an AVD3D12VAFrame"]
pub const AVPixelFormat_AV_PIX_FMT_D3D12: AVPixelFormat = 227;
#[doc = "< number of pixel formats, DO NOT USE THIS if you want to link with shared libav* because the number of formats might differ between versions"]
pub const AVPixelFormat_AV_PIX_FMT_NB: AVPixelFormat = 228;
#[doc = " Pixel format.\n\n @note\n AV_PIX_FMT_RGB32 is handled in an endian-specific manner. An RGBA\n color is put together as:\n  (A << 24) | (R << 16) | (G << 8) | B\n This is stored as BGRA on little-endian CPU architectures and ARGB on\n big-endian CPUs.\n\n @note\n If the resolution is not a multiple of the chroma subsampling factor\n then the chroma plane resolution must be rounded up.\n\n @par\n When the pixel format is palettized RGB32 (AV_PIX_FMT_PAL8), the palettized\n image data is stored in AVFrame.data[0]. The palette is transported in\n AVFrame.data[1], is 1024 bytes long (256 4-byte entries) and is\n formatted the same as in AV_PIX_FMT_RGB32 described above (i.e., it is\n also endian-specific). Note also that the individual RGB32 palette\n components stored in AVFrame.data[1] should be in the range 0..255.\n This is important as many custom PAL8 video codecs that were designed\n to run on the IBM VGA graphics adapter use 6-bit palette components.\n\n @par\n For all the 8 bits per pixel formats, an RGB32 palette is in data[1] like\n for pal8. This palette is filled in automatically by the function\n allocating the picture."]
pub type AVPixelFormat = ::std::os::raw::c_int;
pub const AVColorPrimaries_AVCOL_PRI_RESERVED0: AVColorPrimaries = 0;
#[doc = "< also ITU-R BT1361 / IEC 61966-2-4 / SMPTE RP 177 Annex B"]
pub const AVColorPrimaries_AVCOL_PRI_BT709: AVColorPrimaries = 1;
pub const AVColorPrimaries_AVCOL_PRI_UNSPECIFIED: AVColorPrimaries = 2;
pub const AVColorPrimaries_AVCOL_PRI_RESERVED: AVColorPrimaries = 3;
#[doc = "< also FCC Title 47 Code of Federal Regulations 73.682 (a)(20)"]
pub const AVColorPrimaries_AVCOL_PRI_BT470M: AVColorPrimaries = 4;
#[doc = "< also ITU-R BT601-6 625 / ITU-R BT1358 625 / ITU-R BT1700 625 PAL & SECAM"]
pub const AVColorPrimaries_AVCOL_PRI_BT470BG: AVColorPrimaries = 5;
#[doc = "< also ITU-R BT601-6 525 / ITU-R BT1358 525 / ITU-R BT1700 NTSC"]
pub const AVColorPrimaries_AVCOL_PRI_SMPTE170M: AVColorPrimaries = 6;
#[doc = "< identical to above, also called \"SMPTE C\" even though it uses D65"]
pub const AVColorPrimaries_AVCOL_PRI_SMPTE240M: AVColorPrimaries = 7;
#[doc = "< colour filters using Illuminant C"]
pub const AVColorPrimaries_AVCOL_PRI_FILM: AVColorPrimaries = 8;
#[doc = "< ITU-R BT2020"]
pub const AVColorPrimaries_AVCOL_PRI_BT2020: AVColorPrimaries = 9;
#[doc = "< SMPTE ST 428-1 (CIE 1931 XYZ)"]
pub const AVColorPrimaries_AVCOL_PRI_SMPTE428: AVColorPrimaries = 10;
pub const AVColorPrimaries_AVCOL_PRI_SMPTEST428_1: AVColorPrimaries = 10;
#[doc = "< SMPTE ST 431-2 (2011) / DCI P3"]
pub const AVColorPrimaries_AVCOL_PRI_SMPTE431: AVColorPrimaries = 11;
#[doc = "< SMPTE ST 432-1 (2010) / P3 D65 / Display P3"]
pub const AVColorPrimaries_AVCOL_PRI_SMPTE432: AVColorPrimaries = 12;
#[doc = "< EBU Tech. 3213-E (nothing there) / one of JEDEC P22 group phosphors"]
pub const AVColorPrimaries_AVCOL_PRI_EBU3213: AVColorPrimaries = 22;
pub const AVColorPrimaries_AVCOL_PRI_JEDEC_P22: AVColorPrimaries = 22;
#[doc = "< Not part of ABI"]
pub const AVColorPrimaries_AVCOL_PRI_NB: AVColorPrimaries = 23;
#[doc = " Chromaticity coordinates of the source primaries.\n These values match the ones defined by ISO/IEC 23091-2_2019 subclause 8.1 and ITU-T H.273."]
pub type AVColorPrimaries = ::std::os::raw::c_uint;
pub const AVColorTransferCharacteristic_AVCOL_TRC_RESERVED0: AVColorTransferCharacteristic = 0;
#[doc = "< also ITU-R BT1361"]
pub const AVColorTransferCharacteristic_AVCOL_TRC_BT709: AVColorTransferCharacteristic = 1;
pub const AVColorTransferCharacteristic_AVCOL_TRC_UNSPECIFIED: AVColorTransferCharacteristic = 2;
pub const AVColorTransferCharacteristic_AVCOL_TRC_RESERVED: AVColorTransferCharacteristic = 3;
#[doc = "< also ITU-R BT470M / ITU-R BT1700 625 PAL & SECAM"]
pub const AVColorTransferCharacteristic_AVCOL_TRC_GAMMA22: AVColorTransferCharacteristic = 4;
#[doc = "< also ITU-R BT470BG"]
pub const AVColorTransferCharacteristic_AVCOL_TRC_GAMMA28: AVColorTransferCharacteristic = 5;
#[doc = "< also ITU-R BT601-6 525 or 625 / ITU-R BT1358 525 or 625 / ITU-R BT1700 NTSC"]
pub const AVColorTransferCharacteristic_AVCOL_TRC_SMPTE170M: AVColorTransferCharacteristic = 6;
pub const AVColorTransferCharacteristic_AVCOL_TRC_SMPTE240M: AVColorTransferCharacteristic = 7;
#[doc = "< \"Linear transfer characteristics\""]
pub const AVColorTransferCharacteristic_AVCOL_TRC_LINEAR: AVColorTransferCharacteristic = 8;
#[doc = "< \"Logarithmic transfer characteristic (100:1 range)\""]
pub const AVColorTransferCharacteristic_AVCOL_TRC_LOG: AVColorTransferCharacteristic = 9;
#[doc = "< \"Logarithmic transfer characteristic (100 * Sqrt(10) : 1 range)\""]
pub const AVColorTransferCharacteristic_AVCOL_TRC_LOG_SQRT: AVColorTransferCharacteristic = 10;
#[doc = "< IEC 61966-2-4"]
pub const AVColorTransferCharacteristic_AVCOL_TRC_IEC61966_2_4: AVColorTransferCharacteristic = 11;
#[doc = "< ITU-R BT1361 Extended Colour Gamut"]
pub const AVColorTransferCharacteristic_AVCOL_TRC_BT1361_ECG: AVColorTransferCharacteristic = 12;
#[doc = "< IEC 61966-2-1 (sRGB or sYCC)"]
pub const AVColorTransferCharacteristic_AVCOL_TRC_IEC61966_2_1: AVColorTransferCharacteristic = 13;
#[doc = "< ITU-R BT2020 for 10-bit system"]
pub const AVColorTransferCharacteristic_AVCOL_TRC_BT2020_10: AVColorTransferCharacteristic = 14;
#[doc = "< ITU-R BT2020 for 12-bit system"]
pub const AVColorTransferCharacteristic_AVCOL_TRC_BT2020_12: AVColorTransferCharacteristic = 15;
#[doc = "< SMPTE ST 2084 for 10-, 12-, 14- and 16-bit systems"]
pub const AVColorTransferCharacteristic_AVCOL_TRC_SMPTE2084: AVColorTransferCharacteristic = 16;
pub const AVColorTransferCharacteristic_AVCOL_TRC_SMPTEST2084: AVColorTransferCharacteristic = 16;
#[doc = "< SMPTE ST 428-1"]
pub const AVColorTransferCharacteristic_AVCOL_TRC_SMPTE428: AVColorTransferCharacteristic = 17;
pub const AVColorTransferCharacteristic_AVCOL_TRC_SMPTEST428_1: AVColorTransferCharacteristic = 17;
#[doc = "< ARIB STD-B67, known as \"Hybrid log-gamma\""]
pub const AVColorTransferCharacteristic_AVCOL_TRC_ARIB_STD_B67: AVColorTransferCharacteristic = 18;
#[doc = "< Not part of ABI"]
pub const AVColorTransferCharacteristic_AVCOL_TRC_NB: AVColorTransferCharacteristic = 19;
#[doc = " Color Transfer Characteristic.\n These values match the ones defined by ISO/IEC 23091-2_2019 subclause 8.2."]
pub type AVColorTransferCharacteristic = ::std::os::raw::c_uint;
#[doc = "< order of coefficients is actually GBR, also IEC 61966-2-1 (sRGB), YZX and ST 428-1"]
pub const AVColorSpace_AVCOL_SPC_RGB: AVColorSpace = 0;
#[doc = "< also ITU-R BT1361 / IEC 61966-2-4 xvYCC709 / derived in SMPTE RP 177 Annex B"]
pub const AVColorSpace_AVCOL_SPC_BT709: AVColorSpace = 1;
pub const AVColorSpace_AVCOL_SPC_UNSPECIFIED: AVColorSpace = 2;
#[doc = "< reserved for future use by ITU-T and ISO/IEC just like 15-255 are"]
pub const AVColorSpace_AVCOL_SPC_RESERVED: AVColorSpace = 3;
#[doc = "< FCC Title 47 Code of Federal Regulations 73.682 (a)(20)"]
pub const AVColorSpace_AVCOL_SPC_FCC: AVColorSpace = 4;
#[doc = "< also ITU-R BT601-6 625 / ITU-R BT1358 625 / ITU-R BT1700 625 PAL & SECAM / IEC 61966-2-4 xvYCC601"]
pub const AVColorSpace_AVCOL_SPC_BT470BG: AVColorSpace = 5;
#[doc = "< also ITU-R BT601-6 525 / ITU-R BT1358 525 / ITU-R BT1700 NTSC / functionally identical to above"]
pub const AVColorSpace_AVCOL_SPC_SMPTE170M: AVColorSpace = 6;
#[doc = "< derived from 170M primaries and D65 white point, 170M is derived from BT470 System M's primaries"]
pub const AVColorSpace_AVCOL_SPC_SMPTE240M: AVColorSpace = 7;
#[doc = "< used by Dirac / VC-2 and H.264 FRext, see ITU-T SG16"]
pub const AVColorSpace_AVCOL_SPC_YCGCO: AVColorSpace = 8;
pub const AVColorSpace_AVCOL_SPC_YCOCG: AVColorSpace = 8;
#[doc = "< ITU-R BT2020 non-constant luminance system"]
pub const AVColorSpace_AVCOL_SPC_BT2020_NCL: AVColorSpace = 9;
#[doc = "< ITU-R BT2020 constant luminance system"]
pub const AVColorSpace_AVCOL_SPC_BT2020_CL: AVColorSpace = 10;
#[doc = "< SMPTE 2085, Y'D'zD'x"]
pub const AVColorSpace_AVCOL_SPC_SMPTE2085: AVColorSpace = 11;
#[doc = "< Chromaticity-derived non-constant luminance system"]
pub const AVColorSpace_AVCOL_SPC_CHROMA_DERIVED_NCL: AVColorSpace = 12;
#[doc = "< Chromaticity-derived constant luminance system"]
pub const AVColorSpace_AVCOL_SPC_CHROMA_DERIVED_CL: AVColorSpace = 13;
#[doc = "< ITU-R BT.2100-0, ICtCp"]
pub const AVColorSpace_AVCOL_SPC_ICTCP: AVColorSpace = 14;
#[doc = "< SMPTE ST 2128, IPT-C2"]
pub const AVColorSpace_AVCOL_SPC_IPT_C2: AVColorSpace = 15;
#[doc = "< YCgCo-R, even addition of bits"]
pub const AVColorSpace_AVCOL_SPC_YCGCO_RE: AVColorSpace = 16;
#[doc = "< YCgCo-R, odd addition of bits"]
pub const AVColorSpace_AVCOL_SPC_YCGCO_RO: AVColorSpace = 17;
#[doc = "< Not part of ABI"]
pub const AVColorSpace_AVCOL_SPC_NB: AVColorSpace = 18;
#[doc = " YUV colorspace type.\n These values match the ones defined by ISO/IEC 23091-2_2019 subclause 8.3."]
pub type AVColorSpace = ::std::os::raw::c_uint;
pub const AVColorRange_AVCOL_RANGE_UNSPECIFIED: AVColorRange = 0;
#[doc = " Narrow or limited range content.\n\n - For luma planes:\n\n       (219 * E + 16) * 2^(n-8)\n\n   F.ex. the range of 16-235 for 8 bits\n\n - For chroma planes:\n\n       (224 * E + 128) * 2^(n-8)\n\n   F.ex. the range of 16-240 for 8 bits"]
pub const AVColorRange_AVCOL_RANGE_MPEG: AVColorRange = 1;
#[doc = " Full range content.\n\n - For RGB and luma planes:\n\n       (2^n - 1) * E\n\n   F.ex. the range of 0-255 for 8 bits\n\n - For chroma planes:\n\n       (2^n - 1) * E + 2^(n - 1)\n\n   F.ex. the range of 1-255 for 8 bits"]
pub const AVColorRange_AVCOL_RANGE_JPEG: AVColorRange = 2;
#[doc = "< Not part of ABI"]
pub const AVColorRange_AVCOL_RANGE_NB: AVColorRange = 3;
#[doc = " Visual content value range.\n\n These values are based on definitions that can be found in multiple\n specifications, such as ITU-T BT.709 (3.4 - Quantization of RGB, luminance\n and colour-difference signals), ITU-T BT.2020 (Table 5 - Digital\n Representation) as well as ITU-T BT.2100 (Table 9 - Digital 10- and 12-bit\n integer representation). At the time of writing, the BT.2100 one is\n recommended, as it also defines the full range representation.\n\n Common definitions:\n   - For RGB and luma planes such as Y in YCbCr and I in ICtCp,\n     'E' is the original value in range of 0.0 to 1.0.\n   - For chroma planes such as Cb,Cr and Ct,Cp, 'E' is the original\n     value in range of -0.5 to 0.5.\n   - 'n' is the output bit depth.\n   - For additional definitions such as rounding and clipping to valid n\n     bit unsigned integer range, please refer to BT.2100 (Table 9)."]
pub type AVColorRange = ::std::os::raw::c_uint;
pub const AVChromaLocation_AVCHROMA_LOC_UNSPECIFIED: AVChromaLocation = 0;
#[doc = "< MPEG-2/4 4:2:0, H.264 default for 4:2:0"]
pub const AVChromaLocation_AVCHROMA_LOC_LEFT: AVChromaLocation = 1;
#[doc = "< MPEG-1 4:2:0, JPEG 4:2:0, H.263 4:2:0"]
pub const AVChromaLocation_AVCHROMA_LOC_CENTER: AVChromaLocation = 2;
#[doc = "< ITU-R 601, SMPTE 274M 296M S314M(DV 4:1:1), mpeg2 4:2:2"]
pub const AVChromaLocation_AVCHROMA_LOC_TOPLEFT: AVChromaLocation = 3;
pub const AVChromaLocation_AVCHROMA_LOC_TOP: AVChromaLocation = 4;
pub const AVChromaLocation_AVCHROMA_LOC_BOTTOMLEFT: AVChromaLocation = 5;
pub const AVChromaLocation_AVCHROMA_LOC_BOTTOM: AVChromaLocation = 6;
#[doc = "< Not part of ABI"]
pub const AVChromaLocation_AVCHROMA_LOC_NB: AVChromaLocation = 7;
#[doc = " Location of chroma samples.\n\n Illustration showing the location of the first (top left) chroma sample of the\n image, the left shows only luma, the right\n shows the location of the chroma sample, the 2 could be imagined to overlay\n each other but are drawn separately due to limitations of ASCII\n\n                1st 2nd       1st 2nd horizontal luma sample positions\n                 v   v         v   v\n                 ______        ______\n1st luma line > |X   X ...    |3 4 X ...     X are luma samples,\n                |             |1 2           1-6 are possible chroma positions\n2nd luma line > |X   X ...    |5 6 X ...     0 is undefined/unknown position"]
pub type AVChromaLocation = ::std::os::raw::c_uint;
extern "C" {
    #[doc = " Compute the length of an integer list.\n\n @param elsize  size in bytes of each list element (only 1, 2, 4 or 8)\n @param term    list terminator (usually 0 or -1)\n @param list    pointer to the list\n @return  length of the list, in elements, not counting the terminator"]
    pub fn av_int_list_length_for_size(
        elsize: ::std::os::raw::c_uint,
        list: *const ::std::os::raw::c_void,
        term: u64,
    ) -> ::std::os::raw::c_uint;
}
extern "C" {
    #[doc = " Return the fractional representation of the internal time base."]
    pub fn av_get_time_base_q() -> AVRational;
}
extern "C" {
    #[doc = " Fill the provided buffer with a string containing a FourCC (four-character\n code) representation.\n\n @param buf    a buffer with size in bytes of at least AV_FOURCC_MAX_STRING_SIZE\n @param fourcc the fourcc to represent\n @return the buffer in input"]
    pub fn av_fourcc_make_string(
        buf: *mut ::std::os::raw::c_char,
        fourcc: u32,
    ) -> *mut ::std::os::raw::c_char;
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct AVBuffer {
    _unused: [u8; 0],
}
#[doc = " A reference to a data buffer.\n\n The size of this struct is not a part of the public ABI and it is not meant\n to be allocated directly."]
#[repr(C)]
#[derive(Debug, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVBufferRef {
    pub buffer: *mut AVBuffer,
    #[doc = " The data buffer. It is considered writable if and only if\n this is the only reference to the buffer, in which case\n av_buffer_is_writable() returns 1."]
    pub data: *mut u8,
    #[doc = " Size of data in bytes."]
    pub size: usize,
}
impl Default for AVBufferRef {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
extern "C" {
    #[doc = " Allocate an AVBuffer of the given size using av_malloc().\n\n @return an AVBufferRef of given size or NULL when out of memory"]
    pub fn av_buffer_alloc(size: usize) -> *mut AVBufferRef;
}
extern "C" {
    #[doc = " Same as av_buffer_alloc(), except the returned buffer will be initialized\n to zero."]
    pub fn av_buffer_allocz(size: usize) -> *mut AVBufferRef;
}
extern "C" {
    #[doc = " Create an AVBuffer from an existing array.\n\n If this function is successful, data is owned by the AVBuffer. The caller may\n only access data through the returned AVBufferRef and references derived from\n it.\n If this function fails, data is left untouched.\n @param data   data array\n @param size   size of data in bytes\n @param free   a callback for freeing this buffer's data\n @param opaque parameter to be got for processing or passed to free\n @param flags  a combination of AV_BUFFER_FLAG_*\n\n @return an AVBufferRef referring to data on success, NULL on failure."]
    pub fn av_buffer_create(
        data: *mut u8,
        size: usize,
        free: ::std::option::Option<
            unsafe extern "C" fn(opaque: *mut ::std::os::raw::c_void, data: *mut u8),
        >,
        opaque: *mut ::std::os::raw::c_void,
        flags: ::std::os::raw::c_int,
    ) -> *mut AVBufferRef;
}
extern "C" {
    #[doc = " Default free callback, which calls av_free() on the buffer data.\n This function is meant to be passed to av_buffer_create(), not called\n directly."]
    pub fn av_buffer_default_free(opaque: *mut ::std::os::raw::c_void, data: *mut u8);
}
extern "C" {
    #[doc = " Create a new reference to an AVBuffer.\n\n @return a new AVBufferRef referring to the same AVBuffer as buf or NULL on\n failure."]
    pub fn av_buffer_ref(buf: *const AVBufferRef) -> *mut AVBufferRef;
}
extern "C" {
    #[doc = " Free a given reference and automatically free the buffer if there are no more\n references to it.\n\n @param buf the reference to be freed. The pointer is set to NULL on return."]
    pub fn av_buffer_unref(buf: *mut *mut AVBufferRef);
}
extern "C" {
    #[doc = " @return 1 if the caller may write to the data referred to by buf (which is\n true if and only if buf is the only reference to the underlying AVBuffer).\n Return 0 otherwise.\n A positive answer is valid until av_buffer_ref() is called on buf."]
    pub fn av_buffer_is_writable(buf: *const AVBufferRef) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " @return the opaque parameter set by av_buffer_create."]
    pub fn av_buffer_get_opaque(buf: *const AVBufferRef) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    pub fn av_buffer_get_ref_count(buf: *const AVBufferRef) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Create a writable reference from a given buffer reference, avoiding data copy\n if possible.\n\n @param buf buffer reference to make writable. On success, buf is either left\n            untouched, or it is unreferenced and a new writable AVBufferRef is\n            written in its place. On failure, buf is left untouched.\n @return 0 on success, a negative AVERROR on failure."]
    pub fn av_buffer_make_writable(buf: *mut *mut AVBufferRef) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Reallocate a given buffer.\n\n @param buf  a buffer reference to reallocate. On success, buf will be\n             unreferenced and a new reference with the required size will be\n             written in its place. On failure buf will be left untouched. *buf\n             may be NULL, then a new buffer is allocated.\n @param size required new buffer size.\n @return 0 on success, a negative AVERROR on failure.\n\n @note the buffer is actually reallocated with av_realloc() only if it was\n initially allocated through av_buffer_realloc(NULL) and there is only one\n reference to it (i.e. the one passed to this function). In all other cases\n a new buffer is allocated and the data is copied."]
    pub fn av_buffer_realloc(buf: *mut *mut AVBufferRef, size: usize) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Ensure dst refers to the same data as src.\n\n When *dst is already equivalent to src, do nothing. Otherwise unreference dst\n and replace it with a new reference to src.\n\n @param dst Pointer to either a valid buffer reference or NULL. On success,\n            this will point to a buffer reference equivalent to src. On\n            failure, dst will be left untouched.\n @param src A buffer reference to replace dst with. May be NULL, then this\n            function is equivalent to av_buffer_unref(dst).\n @return 0 on success\n         AVERROR(ENOMEM) on memory allocation failure."]
    pub fn av_buffer_replace(
        dst: *mut *mut AVBufferRef,
        src: *const AVBufferRef,
    ) -> ::std::os::raw::c_int;
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct AVBufferPool {
    _unused: [u8; 0],
}
extern "C" {
    #[doc = " Allocate and initialize a buffer pool.\n\n @param size size of each buffer in this pool\n @param alloc a function that will be used to allocate new buffers when the\n pool is empty. May be NULL, then the default allocator will be used\n (av_buffer_alloc()).\n @return newly created buffer pool on success, NULL on error."]
    pub fn av_buffer_pool_init(
        size: usize,
        alloc: ::std::option::Option<unsafe extern "C" fn(size: usize) -> *mut AVBufferRef>,
    ) -> *mut AVBufferPool;
}
extern "C" {
    #[doc = " Allocate and initialize a buffer pool with a more complex allocator.\n\n @param size size of each buffer in this pool\n @param opaque arbitrary user data used by the allocator\n @param alloc a function that will be used to allocate new buffers when the\n              pool is empty. May be NULL, then the default allocator will be\n              used (av_buffer_alloc()).\n @param pool_free a function that will be called immediately before the pool\n                  is freed. I.e. after av_buffer_pool_uninit() is called\n                  by the caller and all the frames are returned to the pool\n                  and freed. It is intended to uninitialize the user opaque\n                  data. May be NULL.\n @return newly created buffer pool on success, NULL on error."]
    pub fn av_buffer_pool_init2(
        size: usize,
        opaque: *mut ::std::os::raw::c_void,
        alloc: ::std::option::Option<
            unsafe extern "C" fn(
                opaque: *mut ::std::os::raw::c_void,
                size: usize,
            ) -> *mut AVBufferRef,
        >,
        pool_free: ::std::option::Option<unsafe extern "C" fn(opaque: *mut ::std::os::raw::c_void)>,
    ) -> *mut AVBufferPool;
}
extern "C" {
    #[doc = " Mark the pool as being available for freeing. It will actually be freed only\n once all the allocated buffers associated with the pool are released. Thus it\n is safe to call this function while some of the allocated buffers are still\n in use.\n\n @param pool pointer to the pool to be freed. It will be set to NULL."]
    pub fn av_buffer_pool_uninit(pool: *mut *mut AVBufferPool);
}
extern "C" {
    #[doc = " Allocate a new AVBuffer, reusing an old buffer from the pool when available.\n This function may be called simultaneously from multiple threads.\n\n @return a reference to the new buffer on success, NULL on error."]
    pub fn av_buffer_pool_get(pool: *mut AVBufferPool) -> *mut AVBufferRef;
}
extern "C" {
    #[doc = " Query the original opaque parameter of an allocated buffer in the pool.\n\n @param ref a buffer reference to a buffer returned by av_buffer_pool_get.\n @return the opaque parameter set by the buffer allocator function of the\n         buffer pool.\n\n @note the opaque parameter of ref is used by the buffer pool implementation,\n therefore you have to use this function to access the original opaque\n parameter of an allocated buffer."]
    pub fn av_buffer_pool_buffer_get_opaque(
        ref_: *const AVBufferRef,
    ) -> *mut ::std::os::raw::c_void;
}
pub const AVChannel_AV_CHAN_NONE: AVChannel = -1;
pub const AVChannel_AV_CHAN_FRONT_LEFT: AVChannel = 0;
pub const AVChannel_AV_CHAN_FRONT_RIGHT: AVChannel = 1;
pub const AVChannel_AV_CHAN_FRONT_CENTER: AVChannel = 2;
pub const AVChannel_AV_CHAN_LOW_FREQUENCY: AVChannel = 3;
pub const AVChannel_AV_CHAN_BACK_LEFT: AVChannel = 4;
pub const AVChannel_AV_CHAN_BACK_RIGHT: AVChannel = 5;
pub const AVChannel_AV_CHAN_FRONT_LEFT_OF_CENTER: AVChannel = 6;
pub const AVChannel_AV_CHAN_FRONT_RIGHT_OF_CENTER: AVChannel = 7;
pub const AVChannel_AV_CHAN_BACK_CENTER: AVChannel = 8;
pub const AVChannel_AV_CHAN_SIDE_LEFT: AVChannel = 9;
pub const AVChannel_AV_CHAN_SIDE_RIGHT: AVChannel = 10;
pub const AVChannel_AV_CHAN_TOP_CENTER: AVChannel = 11;
pub const AVChannel_AV_CHAN_TOP_FRONT_LEFT: AVChannel = 12;
pub const AVChannel_AV_CHAN_TOP_FRONT_CENTER: AVChannel = 13;
pub const AVChannel_AV_CHAN_TOP_FRONT_RIGHT: AVChannel = 14;
pub const AVChannel_AV_CHAN_TOP_BACK_LEFT: AVChannel = 15;
pub const AVChannel_AV_CHAN_TOP_BACK_CENTER: AVChannel = 16;
pub const AVChannel_AV_CHAN_TOP_BACK_RIGHT: AVChannel = 17;
#[doc = " Stereo downmix."]
pub const AVChannel_AV_CHAN_STEREO_LEFT: AVChannel = 29;
#[doc = " See above."]
pub const AVChannel_AV_CHAN_STEREO_RIGHT: AVChannel = 30;
#[doc = " See above."]
pub const AVChannel_AV_CHAN_WIDE_LEFT: AVChannel = 31;
#[doc = " See above."]
pub const AVChannel_AV_CHAN_WIDE_RIGHT: AVChannel = 32;
#[doc = " See above."]
pub const AVChannel_AV_CHAN_SURROUND_DIRECT_LEFT: AVChannel = 33;
#[doc = " See above."]
pub const AVChannel_AV_CHAN_SURROUND_DIRECT_RIGHT: AVChannel = 34;
#[doc = " See above."]
pub const AVChannel_AV_CHAN_LOW_FREQUENCY_2: AVChannel = 35;
#[doc = " See above."]
pub const AVChannel_AV_CHAN_TOP_SIDE_LEFT: AVChannel = 36;
#[doc = " See above."]
pub const AVChannel_AV_CHAN_TOP_SIDE_RIGHT: AVChannel = 37;
#[doc = " See above."]
pub const AVChannel_AV_CHAN_BOTTOM_FRONT_CENTER: AVChannel = 38;
#[doc = " See above."]
pub const AVChannel_AV_CHAN_BOTTOM_FRONT_LEFT: AVChannel = 39;
#[doc = " See above."]
pub const AVChannel_AV_CHAN_BOTTOM_FRONT_RIGHT: AVChannel = 40;
#[doc = " Channel is empty can be safely skipped."]
pub const AVChannel_AV_CHAN_UNUSED: AVChannel = 512;
#[doc = " Channel contains data, but its position is unknown."]
pub const AVChannel_AV_CHAN_UNKNOWN: AVChannel = 768;
#[doc = " Range of channels between AV_CHAN_AMBISONIC_BASE and\n AV_CHAN_AMBISONIC_END represent Ambisonic components using the ACN system.\n\n Given a channel id `<i>` between AV_CHAN_AMBISONIC_BASE and\n AV_CHAN_AMBISONIC_END (inclusive), the ACN index of the channel `<n>` is\n `<n> = <i> - AV_CHAN_AMBISONIC_BASE`.\n\n @note these values are only used for AV_CHANNEL_ORDER_CUSTOM channel\n orderings, the AV_CHANNEL_ORDER_AMBISONIC ordering orders the channels\n implicitly by their position in the stream."]
pub const AVChannel_AV_CHAN_AMBISONIC_BASE: AVChannel = 1024;
#[doc = " Range of channels between AV_CHAN_AMBISONIC_BASE and\n AV_CHAN_AMBISONIC_END represent Ambisonic components using the ACN system.\n\n Given a channel id `<i>` between AV_CHAN_AMBISONIC_BASE and\n AV_CHAN_AMBISONIC_END (inclusive), the ACN index of the channel `<n>` is\n `<n> = <i> - AV_CHAN_AMBISONIC_BASE`.\n\n @note these values are only used for AV_CHANNEL_ORDER_CUSTOM channel\n orderings, the AV_CHANNEL_ORDER_AMBISONIC ordering orders the channels\n implicitly by their position in the stream."]
pub const AVChannel_AV_CHAN_AMBISONIC_END: AVChannel = 2047;
#[doc = " @defgroup lavu_audio_channels Audio channels\n @ingroup lavu_audio\n\n Audio channel layout utility functions\n\n @{"]
pub type AVChannel = ::std::os::raw::c_int;
#[doc = " Only the channel count is specified, without any further information\n about the channel order."]
pub const AVChannelOrder_AV_CHANNEL_ORDER_UNSPEC: AVChannelOrder = 0;
#[doc = " The native channel order, i.e. the channels are in the same order in\n which they are defined in the AVChannel enum. This supports up to 63\n different channels."]
pub const AVChannelOrder_AV_CHANNEL_ORDER_NATIVE: AVChannelOrder = 1;
#[doc = " The channel order does not correspond to any other predefined order and\n is stored as an explicit map. For example, this could be used to support\n layouts with 64 or more channels, or with empty/skipped (AV_CHAN_UNUSED)\n channels at arbitrary positions."]
pub const AVChannelOrder_AV_CHANNEL_ORDER_CUSTOM: AVChannelOrder = 2;
#[doc = " The audio is represented as the decomposition of the sound field into\n spherical harmonics. Each channel corresponds to a single expansion\n component. Channels are ordered according to ACN (Ambisonic Channel\n Number).\n\n The channel with the index n in the stream contains the spherical\n harmonic of degree l and order m given by\n @code{.unparsed}\n   l   = floor(sqrt(n)),\n   m   = n - l * (l + 1).\n @endcode\n\n Conversely given a spherical harmonic of degree l and order m, the\n corresponding channel index n is given by\n @code{.unparsed}\n   n = l * (l + 1) + m.\n @endcode\n\n Normalization is assumed to be SN3D (Schmidt Semi-Normalization)\n as defined in AmbiX format $ 2.1."]
pub const AVChannelOrder_AV_CHANNEL_ORDER_AMBISONIC: AVChannelOrder = 3;
#[doc = " Number of channel orders, not part of ABI/API"]
pub const AVChannelOrder_FF_CHANNEL_ORDER_NB: AVChannelOrder = 4;
pub type AVChannelOrder = ::std::os::raw::c_uint;
pub const AVMatrixEncoding_AV_MATRIX_ENCODING_NONE: AVMatrixEncoding = 0;
pub const AVMatrixEncoding_AV_MATRIX_ENCODING_DOLBY: AVMatrixEncoding = 1;
pub const AVMatrixEncoding_AV_MATRIX_ENCODING_DPLII: AVMatrixEncoding = 2;
pub const AVMatrixEncoding_AV_MATRIX_ENCODING_DPLIIX: AVMatrixEncoding = 3;
pub const AVMatrixEncoding_AV_MATRIX_ENCODING_DPLIIZ: AVMatrixEncoding = 4;
pub const AVMatrixEncoding_AV_MATRIX_ENCODING_DOLBYEX: AVMatrixEncoding = 5;
pub const AVMatrixEncoding_AV_MATRIX_ENCODING_DOLBYHEADPHONE: AVMatrixEncoding = 6;
pub const AVMatrixEncoding_AV_MATRIX_ENCODING_NB: AVMatrixEncoding = 7;
pub type AVMatrixEncoding = ::std::os::raw::c_uint;
#[doc = " An AVChannelCustom defines a single channel within a custom order layout\n\n Unlike most structures in FFmpeg, sizeof(AVChannelCustom) is a part of the\n public ABI.\n\n No new fields may be added to it without a major version bump."]
#[repr(C)]
#[derive(Debug, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVChannelCustom {
    pub id: AVChannel,
    pub name: [::std::os::raw::c_char; 16usize],
    pub opaque: *mut ::std::os::raw::c_void,
}
impl Default for AVChannelCustom {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = " An AVChannelLayout holds information about the channel layout of audio data.\n\n A channel layout here is defined as a set of channels ordered in a specific\n way (unless the channel order is AV_CHANNEL_ORDER_UNSPEC, in which case an\n AVChannelLayout carries only the channel count).\n All orders may be treated as if they were AV_CHANNEL_ORDER_UNSPEC by\n ignoring everything but the channel count, as long as av_channel_layout_check()\n considers they are valid.\n\n Unlike most structures in FFmpeg, sizeof(AVChannelLayout) is a part of the\n public ABI and may be used by the caller. E.g. it may be allocated on stack\n or embedded in caller-defined structs.\n\n AVChannelLayout can be initialized as follows:\n - default initialization with {0}, followed by setting all used fields\n   correctly;\n - by assigning one of the predefined AV_CHANNEL_LAYOUT_* initializers;\n - with a constructor function, such as av_channel_layout_default(),\n   av_channel_layout_from_mask() or av_channel_layout_from_string().\n\n The channel layout must be unitialized with av_channel_layout_uninit()\n\n Copying an AVChannelLayout via assigning is forbidden,\n av_channel_layout_copy() must be used instead (and its return value should\n be checked)\n\n No new fields may be added to it without a major version bump, except for\n new elements of the union fitting in sizeof(uint64_t)."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct AVChannelLayout {
    #[doc = " Channel order used in this layout.\n This is a mandatory field."]
    pub order: AVChannelOrder,
    #[doc = " Number of channels in this layout. Mandatory field."]
    pub nb_channels: ::std::os::raw::c_int,
    pub u: AVChannelLayout__bindgen_ty_1,
    #[doc = " For some private data of the user."]
    pub opaque: *mut ::std::os::raw::c_void,
}
#[doc = " Details about which channels are present in this layout.\n For AV_CHANNEL_ORDER_UNSPEC, this field is undefined and must not be\n used."]
#[repr(C)]
#[derive(Copy, Clone)]
pub union AVChannelLayout__bindgen_ty_1 {
    #[doc = " This member must be used for AV_CHANNEL_ORDER_NATIVE, and may be used\n for AV_CHANNEL_ORDER_AMBISONIC to signal non-diegetic channels.\n It is a bitmask, where the position of each set bit means that the\n AVChannel with the corresponding value is present.\n\n I.e. when (mask & (1 << AV_CHAN_FOO)) is non-zero, then AV_CHAN_FOO\n is present in the layout. Otherwise it is not present.\n\n @note when a channel layout using a bitmask is constructed or\n modified manually (i.e.  not using any of the av_channel_layout_*\n functions), the code doing it must ensure that the number of set bits\n is equal to nb_channels."]
    pub mask: u64,
    #[doc = " This member must be used when the channel order is\n AV_CHANNEL_ORDER_CUSTOM. It is a nb_channels-sized array, with each\n element signalling the presence of the AVChannel with the\n corresponding value in map[i].id.\n\n I.e. when map[i].id is equal to AV_CHAN_FOO, then AV_CH_FOO is the\n i-th channel in the audio data.\n\n When map[i].id is in the range between AV_CHAN_AMBISONIC_BASE and\n AV_CHAN_AMBISONIC_END (inclusive), the channel contains an ambisonic\n component with ACN index (as defined above)\n n = map[i].id - AV_CHAN_AMBISONIC_BASE.\n\n map[i].name may be filled with a 0-terminated string, in which case\n it will be used for the purpose of identifying the channel with the\n convenience functions below. Otherise it must be zeroed."]
    pub map: *mut AVChannelCustom,
}
impl Default for AVChannelLayout__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
impl Default for AVChannelLayout {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = " @}"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct AVBPrint {
    _unused: [u8; 0],
}
extern "C" {
    #[doc = " Get a human readable string in an abbreviated form describing a given channel.\n This is the inverse function of @ref av_channel_from_string().\n\n @param buf pre-allocated buffer where to put the generated string\n @param buf_size size in bytes of the buffer.\n @param channel the AVChannel whose name to get\n @return amount of bytes needed to hold the output string, or a negative AVERROR\n         on failure. If the returned value is bigger than buf_size, then the\n         string was truncated."]
    pub fn av_channel_name(
        buf: *mut ::std::os::raw::c_char,
        buf_size: usize,
        channel: AVChannel,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " bprint variant of av_channel_name().\n\n @note the string will be appended to the bprint buffer."]
    pub fn av_channel_name_bprint(bp: *mut AVBPrint, channel_id: AVChannel);
}
extern "C" {
    #[doc = " Get a human readable string describing a given channel.\n\n @param buf pre-allocated buffer where to put the generated string\n @param buf_size size in bytes of the buffer.\n @param channel the AVChannel whose description to get\n @return amount of bytes needed to hold the output string, or a negative AVERROR\n         on failure. If the returned value is bigger than buf_size, then the\n         string was truncated."]
    pub fn av_channel_description(
        buf: *mut ::std::os::raw::c_char,
        buf_size: usize,
        channel: AVChannel,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " bprint variant of av_channel_description().\n\n @note the string will be appended to the bprint buffer."]
    pub fn av_channel_description_bprint(bp: *mut AVBPrint, channel_id: AVChannel);
}
extern "C" {
    #[doc = " This is the inverse function of @ref av_channel_name().\n\n @return the channel with the given name\n         AV_CHAN_NONE when name does not identify a known channel"]
    pub fn av_channel_from_string(name: *const ::std::os::raw::c_char) -> AVChannel;
}
extern "C" {
    #[doc = " Initialize a custom channel layout with the specified number of channels.\n The channel map will be allocated and the designation of all channels will\n be set to AV_CHAN_UNKNOWN.\n\n This is only a convenience helper function, a custom channel layout can also\n be constructed without using this.\n\n @param channel_layout the layout structure to be initialized\n @param nb_channels the number of channels\n\n @return 0 on success\n         AVERROR(EINVAL) if the number of channels <= 0\n         AVERROR(ENOMEM) if the channel map could not be allocated"]
    pub fn av_channel_layout_custom_init(
        channel_layout: *mut AVChannelLayout,
        nb_channels: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Initialize a native channel layout from a bitmask indicating which channels\n are present.\n\n @param channel_layout the layout structure to be initialized\n @param mask bitmask describing the channel layout\n\n @return 0 on success\n         AVERROR(EINVAL) for invalid mask values"]
    pub fn av_channel_layout_from_mask(
        channel_layout: *mut AVChannelLayout,
        mask: u64,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Initialize a channel layout from a given string description.\n The input string can be represented by:\n  - the formal channel layout name (returned by av_channel_layout_describe())\n  - single or multiple channel names (returned by av_channel_name(), eg. \"FL\",\n    or concatenated with \"+\", each optionally containing a custom name after\n    a \"@\", eg. \"FL@Left+FR@Right+LFE\")\n  - a decimal or hexadecimal value of a native channel layout (eg. \"4\" or \"0x4\")\n  - the number of channels with default layout (eg. \"4c\")\n  - the number of unordered channels (eg. \"4C\" or \"4 channels\")\n  - the ambisonic order followed by optional non-diegetic channels (eg.\n    \"ambisonic 2+stereo\")\n On error, the channel layout will remain uninitialized, but not necessarily\n untouched.\n\n @param channel_layout uninitialized channel layout for the result\n @param str string describing the channel layout\n @return 0 on success parsing the channel layout\n         AVERROR(EINVAL) if an invalid channel layout string was provided\n         AVERROR(ENOMEM) if there was not enough memory"]
    pub fn av_channel_layout_from_string(
        channel_layout: *mut AVChannelLayout,
        str_: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get the default channel layout for a given number of channels.\n\n @param ch_layout the layout structure to be initialized\n @param nb_channels number of channels"]
    pub fn av_channel_layout_default(
        ch_layout: *mut AVChannelLayout,
        nb_channels: ::std::os::raw::c_int,
    );
}
extern "C" {
    #[doc = " Iterate over all standard channel layouts.\n\n @param opaque a pointer where libavutil will store the iteration state. Must\n               point to NULL to start the iteration.\n\n @return the standard channel layout or NULL when the iteration is\n         finished"]
    pub fn av_channel_layout_standard(
        opaque: *mut *mut ::std::os::raw::c_void,
    ) -> *const AVChannelLayout;
}
extern "C" {
    #[doc = " Free any allocated data in the channel layout and reset the channel\n count to 0.\n\n @param channel_layout the layout structure to be uninitialized"]
    pub fn av_channel_layout_uninit(channel_layout: *mut AVChannelLayout);
}
extern "C" {
    #[doc = " Make a copy of a channel layout. This differs from just assigning src to dst\n in that it allocates and copies the map for AV_CHANNEL_ORDER_CUSTOM.\n\n @note the destination channel_layout will be always uninitialized before copy.\n\n @param dst destination channel layout\n @param src source channel layout\n @return 0 on success, a negative AVERROR on error."]
    pub fn av_channel_layout_copy(
        dst: *mut AVChannelLayout,
        src: *const AVChannelLayout,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get a human-readable string describing the channel layout properties.\n The string will be in the same format that is accepted by\n @ref av_channel_layout_from_string(), allowing to rebuild the same\n channel layout, except for opaque pointers.\n\n @param channel_layout channel layout to be described\n @param buf pre-allocated buffer where to put the generated string\n @param buf_size size in bytes of the buffer.\n @return amount of bytes needed to hold the output string, or a negative AVERROR\n         on failure. If the returned value is bigger than buf_size, then the\n         string was truncated."]
    pub fn av_channel_layout_describe(
        channel_layout: *const AVChannelLayout,
        buf: *mut ::std::os::raw::c_char,
        buf_size: usize,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " bprint variant of av_channel_layout_describe().\n\n @note the string will be appended to the bprint buffer.\n @return 0 on success, or a negative AVERROR value on failure."]
    pub fn av_channel_layout_describe_bprint(
        channel_layout: *const AVChannelLayout,
        bp: *mut AVBPrint,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get the channel with the given index in a channel layout.\n\n @param channel_layout input channel layout\n @param idx index of the channel\n @return channel with the index idx in channel_layout on success or\n         AV_CHAN_NONE on failure (if idx is not valid or the channel order is\n         unspecified)"]
    pub fn av_channel_layout_channel_from_index(
        channel_layout: *const AVChannelLayout,
        idx: ::std::os::raw::c_uint,
    ) -> AVChannel;
}
extern "C" {
    #[doc = " Get the index of a given channel in a channel layout. In case multiple\n channels are found, only the first match will be returned.\n\n @param channel_layout input channel layout\n @param channel the channel whose index to obtain\n @return index of channel in channel_layout on success or a negative number if\n         channel is not present in channel_layout."]
    pub fn av_channel_layout_index_from_channel(
        channel_layout: *const AVChannelLayout,
        channel: AVChannel,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get the index in a channel layout of a channel described by the given string.\n In case multiple channels are found, only the first match will be returned.\n\n This function accepts channel names in the same format as\n @ref av_channel_from_string().\n\n @param channel_layout input channel layout\n @param name string describing the channel whose index to obtain\n @return a channel index described by the given string, or a negative AVERROR\n         value."]
    pub fn av_channel_layout_index_from_string(
        channel_layout: *const AVChannelLayout,
        name: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get a channel described by the given string.\n\n This function accepts channel names in the same format as\n @ref av_channel_from_string().\n\n @param channel_layout input channel layout\n @param name string describing the channel to obtain\n @return a channel described by the given string in channel_layout on success\n         or AV_CHAN_NONE on failure (if the string is not valid or the channel\n         order is unspecified)"]
    pub fn av_channel_layout_channel_from_string(
        channel_layout: *const AVChannelLayout,
        name: *const ::std::os::raw::c_char,
    ) -> AVChannel;
}
extern "C" {
    #[doc = " Find out what channels from a given set are present in a channel layout,\n without regard for their positions.\n\n @param channel_layout input channel layout\n @param mask a combination of AV_CH_* representing a set of channels\n @return a bitfield representing all the channels from mask that are present\n         in channel_layout"]
    pub fn av_channel_layout_subset(channel_layout: *const AVChannelLayout, mask: u64) -> u64;
}
extern "C" {
    #[doc = " Check whether a channel layout is valid, i.e. can possibly describe audio\n data.\n\n @param channel_layout input channel layout\n @return 1 if channel_layout is valid, 0 otherwise."]
    pub fn av_channel_layout_check(channel_layout: *const AVChannelLayout)
        -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Check whether two channel layouts are semantically the same, i.e. the same\n channels are present on the same positions in both.\n\n If one of the channel layouts is AV_CHANNEL_ORDER_UNSPEC, while the other is\n not, they are considered to be unequal. If both are AV_CHANNEL_ORDER_UNSPEC,\n they are considered equal iff the channel counts are the same in both.\n\n @param chl input channel layout\n @param chl1 input channel layout\n @return 0 if chl and chl1 are equal, 1 if they are not equal. A negative\n         AVERROR code if one or both are invalid."]
    pub fn av_channel_layout_compare(
        chl: *const AVChannelLayout,
        chl1: *const AVChannelLayout,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Change the AVChannelOrder of a channel layout.\n\n Change of AVChannelOrder can be either lossless or lossy. In case of a\n lossless conversion all the channel designations and the associated channel\n names (if any) are kept. On a lossy conversion the channel names and channel\n designations might be lost depending on the capabilities of the desired\n AVChannelOrder. Note that some conversions are simply not possible in which\n case this function returns AVERROR(ENOSYS).\n\n The following conversions are supported:\n\n Any       -> Custom     : Always possible, always lossless.\n Any       -> Unspecified: Always possible, lossless if channel designations\n   are all unknown and channel names are not used, lossy otherwise.\n Custom    -> Ambisonic  : Possible if it contains ambisonic channels with\n   optional non-diegetic channels in the end. Lossy if the channels have\n   custom names, lossless otherwise.\n Custom    -> Native     : Possible if it contains native channels in native\n     order. Lossy if the channels have custom names, lossless otherwise.\n\n On error this function keeps the original channel layout untouched.\n\n @param channel_layout channel layout which will be changed\n @param order the desired channel layout order\n @param flags a combination of AV_CHANNEL_LAYOUT_RETYPE_FLAG_* constants\n @return 0 if the conversion was successful and lossless or if the channel\n           layout was already in the desired order\n         >0 if the conversion was successful but lossy\n         AVERROR(ENOSYS) if the conversion was not possible (or would be\n           lossy and AV_CHANNEL_LAYOUT_RETYPE_FLAG_LOSSLESS was specified)\n         AVERROR(EINVAL), AVERROR(ENOMEM) on error"]
    pub fn av_channel_layout_retype(
        channel_layout: *mut AVChannelLayout,
        order: AVChannelOrder,
        flags: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
#[doc = " @}"]
#[repr(C)]
#[derive(Debug, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVDictionaryEntry {
    pub key: *mut ::std::os::raw::c_char,
    pub value: *mut ::std::os::raw::c_char,
}
impl Default for AVDictionaryEntry {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct AVDictionary {
    _unused: [u8; 0],
}
extern "C" {
    #[doc = " Get a dictionary entry with matching key.\n\n The returned entry key or value must not be changed, or it will\n cause undefined behavior.\n\n @param prev  Set to the previous matching element to find the next.\n              If set to NULL the first matching element is returned.\n @param key   Matching key\n @param flags A collection of AV_DICT_* flags controlling how the\n              entry is retrieved\n\n @return      Found entry or NULL in case no matching entry was found in the dictionary"]
    pub fn av_dict_get(
        m: *const AVDictionary,
        key: *const ::std::os::raw::c_char,
        prev: *const AVDictionaryEntry,
        flags: ::std::os::raw::c_int,
    ) -> *mut AVDictionaryEntry;
}
extern "C" {
    #[doc = " Iterate over a dictionary\n\n Iterates through all entries in the dictionary.\n\n @warning The returned AVDictionaryEntry key/value must not be changed.\n\n @warning As av_dict_set() invalidates all previous entries returned\n by this function, it must not be called while iterating over the dict.\n\n Typical usage:\n @code\n const AVDictionaryEntry *e = NULL;\n while ((e = av_dict_iterate(m, e))) {\n     // ...\n }\n @endcode\n\n @param m     The dictionary to iterate over\n @param prev  Pointer to the previous AVDictionaryEntry, NULL initially\n\n @retval AVDictionaryEntry* The next element in the dictionary\n @retval NULL               No more elements in the dictionary"]
    pub fn av_dict_iterate(
        m: *const AVDictionary,
        prev: *const AVDictionaryEntry,
    ) -> *const AVDictionaryEntry;
}
extern "C" {
    #[doc = " Get number of entries in dictionary.\n\n @param m dictionary\n @return  number of entries in dictionary"]
    pub fn av_dict_count(m: *const AVDictionary) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Set the given entry in *pm, overwriting an existing entry.\n\n Note: If AV_DICT_DONT_STRDUP_KEY or AV_DICT_DONT_STRDUP_VAL is set,\n these arguments will be freed on error.\n\n @warning Adding a new entry to a dictionary invalidates all existing entries\n previously returned with av_dict_get() or av_dict_iterate().\n\n @param pm        Pointer to a pointer to a dictionary struct. If *pm is NULL\n                  a dictionary struct is allocated and put in *pm.\n @param key       Entry key to add to *pm (will either be av_strduped or added as a new key depending on flags)\n @param value     Entry value to add to *pm (will be av_strduped or added as a new key depending on flags).\n                  Passing a NULL value will cause an existing entry to be deleted.\n\n @return          >= 0 on success otherwise an error code <0"]
    pub fn av_dict_set(
        pm: *mut *mut AVDictionary,
        key: *const ::std::os::raw::c_char,
        value: *const ::std::os::raw::c_char,
        flags: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Convenience wrapper for av_dict_set() that converts the value to a string\n and stores it.\n\n Note: If ::AV_DICT_DONT_STRDUP_KEY is set, key will be freed on error."]
    pub fn av_dict_set_int(
        pm: *mut *mut AVDictionary,
        key: *const ::std::os::raw::c_char,
        value: i64,
        flags: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Parse the key/value pairs list and add the parsed entries to a dictionary.\n\n In case of failure, all the successfully set entries are stored in\n *pm. You may need to manually free the created dictionary.\n\n @param key_val_sep  A 0-terminated list of characters used to separate\n                     key from value\n @param pairs_sep    A 0-terminated list of characters used to separate\n                     two pairs from each other\n @param flags        Flags to use when adding to the dictionary.\n                     ::AV_DICT_DONT_STRDUP_KEY and ::AV_DICT_DONT_STRDUP_VAL\n                     are ignored since the key/value tokens will always\n                     be duplicated.\n\n @return             0 on success, negative AVERROR code on failure"]
    pub fn av_dict_parse_string(
        pm: *mut *mut AVDictionary,
        str_: *const ::std::os::raw::c_char,
        key_val_sep: *const ::std::os::raw::c_char,
        pairs_sep: *const ::std::os::raw::c_char,
        flags: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Copy entries from one AVDictionary struct into another.\n\n @note Metadata is read using the ::AV_DICT_IGNORE_SUFFIX flag\n\n @param dst   Pointer to a pointer to a AVDictionary struct to copy into. If *dst is NULL,\n              this function will allocate a struct for you and put it in *dst\n @param src   Pointer to the source AVDictionary struct to copy items from.\n @param flags Flags to use when setting entries in *dst\n\n @return 0 on success, negative AVERROR code on failure. If dst was allocated\n           by this function, callers should free the associated memory."]
    pub fn av_dict_copy(
        dst: *mut *mut AVDictionary,
        src: *const AVDictionary,
        flags: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Free all the memory allocated for an AVDictionary struct\n and all keys and values."]
    pub fn av_dict_free(m: *mut *mut AVDictionary);
}
extern "C" {
    #[doc = " Get dictionary entries as a string.\n\n Create a string containing dictionary's entries.\n Such string may be passed back to av_dict_parse_string().\n @note String is escaped with backslashes ('\\').\n\n @warning Separators cannot be neither '\\\\' nor '\\0'. They also cannot be the same.\n\n @param[in]  m             The dictionary\n @param[out] buffer        Pointer to buffer that will be allocated with string containg entries.\n                           Buffer must be freed by the caller when is no longer needed.\n @param[in]  key_val_sep   Character used to separate key from value\n @param[in]  pairs_sep     Character used to separate two pairs from each other\n\n @return                   >= 0 on success, negative on error"]
    pub fn av_dict_get_string(
        m: *const AVDictionary,
        buffer: *mut *mut ::std::os::raw::c_char,
        key_val_sep: ::std::os::raw::c_char,
        pairs_sep: ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
#[doc = " The data is the AVPanScan struct defined in libavcodec."]
pub const AVFrameSideDataType_AV_FRAME_DATA_PANSCAN: AVFrameSideDataType = 0;
#[doc = " ATSC A53 Part 4 Closed Captions.\n A53 CC bitstream is stored as uint8_t in AVFrameSideData.data.\n The number of bytes of CC data is AVFrameSideData.size."]
pub const AVFrameSideDataType_AV_FRAME_DATA_A53_CC: AVFrameSideDataType = 1;
#[doc = " Stereoscopic 3d metadata.\n The data is the AVStereo3D struct defined in libavutil/stereo3d.h."]
pub const AVFrameSideDataType_AV_FRAME_DATA_STEREO3D: AVFrameSideDataType = 2;
#[doc = " The data is the AVMatrixEncoding enum defined in libavutil/channel_layout.h."]
pub const AVFrameSideDataType_AV_FRAME_DATA_MATRIXENCODING: AVFrameSideDataType = 3;
#[doc = " Metadata relevant to a downmix procedure.\n The data is the AVDownmixInfo struct defined in libavutil/downmix_info.h."]
pub const AVFrameSideDataType_AV_FRAME_DATA_DOWNMIX_INFO: AVFrameSideDataType = 4;
#[doc = " ReplayGain information in the form of the AVReplayGain struct."]
pub const AVFrameSideDataType_AV_FRAME_DATA_REPLAYGAIN: AVFrameSideDataType = 5;
#[doc = " This side data contains a 3x3 transformation matrix describing an affine\n transformation that needs to be applied to the frame for correct\n presentation.\n\n See libavutil/display.h for a detailed description of the data."]
pub const AVFrameSideDataType_AV_FRAME_DATA_DISPLAYMATRIX: AVFrameSideDataType = 6;
#[doc = " Active Format Description data consisting of a single byte as specified\n in ETSI TS 101 154 using AVActiveFormatDescription enum."]
pub const AVFrameSideDataType_AV_FRAME_DATA_AFD: AVFrameSideDataType = 7;
#[doc = " Motion vectors exported by some codecs (on demand through the export_mvs\n flag set in the libavcodec AVCodecContext flags2 option).\n The data is the AVMotionVector struct defined in\n libavutil/motion_vector.h."]
pub const AVFrameSideDataType_AV_FRAME_DATA_MOTION_VECTORS: AVFrameSideDataType = 8;
#[doc = " Recommmends skipping the specified number of samples. This is exported\n only if the \"skip_manual\" AVOption is set in libavcodec.\n This has the same format as AV_PKT_DATA_SKIP_SAMPLES.\n @code\n u32le number of samples to skip from start of this packet\n u32le number of samples to skip from end of this packet\n u8    reason for start skip\n u8    reason for end   skip (0=padding silence, 1=convergence)\n @endcode"]
pub const AVFrameSideDataType_AV_FRAME_DATA_SKIP_SAMPLES: AVFrameSideDataType = 9;
#[doc = " This side data must be associated with an audio frame and corresponds to\n enum AVAudioServiceType defined in avcodec.h."]
pub const AVFrameSideDataType_AV_FRAME_DATA_AUDIO_SERVICE_TYPE: AVFrameSideDataType = 10;
#[doc = " Mastering display metadata associated with a video frame. The payload is\n an AVMasteringDisplayMetadata type and contains information about the\n mastering display color volume."]
pub const AVFrameSideDataType_AV_FRAME_DATA_MASTERING_DISPLAY_METADATA: AVFrameSideDataType = 11;
#[doc = " The GOP timecode in 25 bit timecode format. Data format is 64-bit integer.\n This is set on the first frame of a GOP that has a temporal reference of 0."]
pub const AVFrameSideDataType_AV_FRAME_DATA_GOP_TIMECODE: AVFrameSideDataType = 12;
#[doc = " The data represents the AVSphericalMapping structure defined in\n libavutil/spherical.h."]
pub const AVFrameSideDataType_AV_FRAME_DATA_SPHERICAL: AVFrameSideDataType = 13;
#[doc = " Content light level (based on CTA-861.3). This payload contains data in\n the form of the AVContentLightMetadata struct."]
pub const AVFrameSideDataType_AV_FRAME_DATA_CONTENT_LIGHT_LEVEL: AVFrameSideDataType = 14;
#[doc = " The data contains an ICC profile as an opaque octet buffer following the\n format described by ISO 15076-1 with an optional name defined in the\n metadata key entry \"name\"."]
pub const AVFrameSideDataType_AV_FRAME_DATA_ICC_PROFILE: AVFrameSideDataType = 15;
#[doc = " Timecode which conforms to SMPTE ST 12-1. The data is an array of 4 uint32_t\n where the first uint32_t describes how many (1-3) of the other timecodes are used.\n The timecode format is described in the documentation of av_timecode_get_smpte_from_framenum()\n function in libavutil/timecode.h."]
pub const AVFrameSideDataType_AV_FRAME_DATA_S12M_TIMECODE: AVFrameSideDataType = 16;
#[doc = " HDR dynamic metadata associated with a video frame. The payload is\n an AVDynamicHDRPlus type and contains information for color\n volume transform - application 4 of SMPTE 2094-40:2016 standard."]
pub const AVFrameSideDataType_AV_FRAME_DATA_DYNAMIC_HDR_PLUS: AVFrameSideDataType = 17;
#[doc = " Regions Of Interest, the data is an array of AVRegionOfInterest type, the number of\n array element is implied by AVFrameSideData.size / AVRegionOfInterest.self_size."]
pub const AVFrameSideDataType_AV_FRAME_DATA_REGIONS_OF_INTEREST: AVFrameSideDataType = 18;
#[doc = " Encoding parameters for a video frame, as described by AVVideoEncParams."]
pub const AVFrameSideDataType_AV_FRAME_DATA_VIDEO_ENC_PARAMS: AVFrameSideDataType = 19;
#[doc = " User data unregistered metadata associated with a video frame.\n This is the H.26[45] UDU SEI message, and shouldn't be used for any other purpose\n The data is stored as uint8_t in AVFrameSideData.data which is 16 bytes of\n uuid_iso_iec_11578 followed by AVFrameSideData.size - 16 bytes of user_data_payload_byte."]
pub const AVFrameSideDataType_AV_FRAME_DATA_SEI_UNREGISTERED: AVFrameSideDataType = 20;
#[doc = " Film grain parameters for a frame, described by AVFilmGrainParams.\n Must be present for every frame which should have film grain applied.\n\n May be present multiple times, for example when there are multiple\n alternative parameter sets for different video signal characteristics.\n The user should select the most appropriate set for the application."]
pub const AVFrameSideDataType_AV_FRAME_DATA_FILM_GRAIN_PARAMS: AVFrameSideDataType = 21;
#[doc = " Bounding boxes for object detection and classification,\n as described by AVDetectionBBoxHeader."]
pub const AVFrameSideDataType_AV_FRAME_DATA_DETECTION_BBOXES: AVFrameSideDataType = 22;
#[doc = " Dolby Vision RPU raw data, suitable for passing to x265\n or other libraries. Array of uint8_t, with NAL emulation\n bytes intact."]
pub const AVFrameSideDataType_AV_FRAME_DATA_DOVI_RPU_BUFFER: AVFrameSideDataType = 23;
#[doc = " Parsed Dolby Vision metadata, suitable for passing to a software\n implementation. The payload is the AVDOVIMetadata struct defined in\n libavutil/dovi_meta.h."]
pub const AVFrameSideDataType_AV_FRAME_DATA_DOVI_METADATA: AVFrameSideDataType = 24;
#[doc = " HDR Vivid dynamic metadata associated with a video frame. The payload is\n an AVDynamicHDRVivid type and contains information for color\n volume transform - CUVA 005.1-2021."]
pub const AVFrameSideDataType_AV_FRAME_DATA_DYNAMIC_HDR_VIVID: AVFrameSideDataType = 25;
#[doc = " Ambient viewing environment metadata, as defined by H.274."]
pub const AVFrameSideDataType_AV_FRAME_DATA_AMBIENT_VIEWING_ENVIRONMENT: AVFrameSideDataType = 26;
#[doc = " Provide encoder-specific hinting information about changed/unchanged\n portions of a frame.  It can be used to pass information about which\n macroblocks can be skipped because they didn't change from the\n corresponding ones in the previous frame. This could be useful for\n applications which know this information in advance to speed up\n encoding."]
pub const AVFrameSideDataType_AV_FRAME_DATA_VIDEO_HINT: AVFrameSideDataType = 27;
#[doc = " @defgroup lavu_frame AVFrame\n @ingroup lavu_data\n\n @{\n AVFrame is an abstraction for reference-counted raw multimedia data."]
pub type AVFrameSideDataType = ::std::os::raw::c_uint;
pub const AVActiveFormatDescription_AV_AFD_SAME: AVActiveFormatDescription = 8;
pub const AVActiveFormatDescription_AV_AFD_4_3: AVActiveFormatDescription = 9;
pub const AVActiveFormatDescription_AV_AFD_16_9: AVActiveFormatDescription = 10;
pub const AVActiveFormatDescription_AV_AFD_14_9: AVActiveFormatDescription = 11;
pub const AVActiveFormatDescription_AV_AFD_4_3_SP_14_9: AVActiveFormatDescription = 13;
pub const AVActiveFormatDescription_AV_AFD_16_9_SP_14_9: AVActiveFormatDescription = 14;
pub const AVActiveFormatDescription_AV_AFD_SP_4_3: AVActiveFormatDescription = 15;
pub type AVActiveFormatDescription = ::std::os::raw::c_uint;
#[doc = " Structure to hold side data for an AVFrame.\n\n sizeof(AVFrameSideData) is not a part of the public ABI, so new fields may be added\n to the end with a minor bump."]
#[repr(C)]
#[derive(Debug, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVFrameSideData {
    pub type_: AVFrameSideDataType,
    pub data: *mut u8,
    pub size: usize,
    pub metadata: *mut AVDictionary,
    pub buf: *mut AVBufferRef,
}
impl Default for AVFrameSideData {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = " The side data type can be used in stream-global structures.\n Side data types without this property are only meaningful on per-frame\n basis."]
pub const AVSideDataProps_AV_SIDE_DATA_PROP_GLOBAL: AVSideDataProps = 1;
#[doc = " Multiple instances of this side data type can be meaningfully present in\n a single side data array."]
pub const AVSideDataProps_AV_SIDE_DATA_PROP_MULTI: AVSideDataProps = 2;
pub type AVSideDataProps = ::std::os::raw::c_uint;
#[doc = " This struct describes the properties of a side data type. Its instance\n corresponding to a given type can be obtained from av_frame_side_data_desc()."]
#[repr(C)]
#[derive(Debug, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVSideDataDescriptor {
    #[doc = " Human-readable side data description."]
    pub name: *const ::std::os::raw::c_char,
    #[doc = " Side data property flags, a combination of AVSideDataProps values."]
    pub props: ::std::os::raw::c_uint,
}
impl Default for AVSideDataDescriptor {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = " Structure describing a single Region Of Interest.\n\n When multiple regions are defined in a single side-data block, they\n should be ordered from most to least important - some encoders are only\n capable of supporting a limited number of distinct regions, so will have\n to truncate the list.\n\n When overlapping regions are defined, the first region containing a given\n area of the frame applies."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVRegionOfInterest {
    #[doc = " Must be set to the size of this data structure (that is,\n sizeof(AVRegionOfInterest))."]
    pub self_size: u32,
    #[doc = " Distance in pixels from the top edge of the frame to the top and\n bottom edges and from the left edge of the frame to the left and\n right edges of the rectangle defining this region of interest.\n\n The constraints on a region are encoder dependent, so the region\n actually affected may be slightly larger for alignment or other\n reasons."]
    pub top: ::std::os::raw::c_int,
    pub bottom: ::std::os::raw::c_int,
    pub left: ::std::os::raw::c_int,
    pub right: ::std::os::raw::c_int,
    #[doc = " Quantisation offset.\n\n Must be in the range -1 to +1.  A value of zero indicates no quality\n change.  A negative value asks for better quality (less quantisation),\n while a positive value asks for worse quality (greater quantisation).\n\n The range is calibrated so that the extreme values indicate the\n largest possible offset - if the rest of the frame is encoded with the\n worst possible quality, an offset of -1 indicates that this region\n should be encoded with the best possible quality anyway.  Intermediate\n values are then interpolated in some codec-dependent way.\n\n For example, in 10-bit H.264 the quantisation parameter varies between\n -12 and 51.  A typical qoffset value of -1/10 therefore indicates that\n this region should be encoded with a QP around one-tenth of the full\n range better than the rest of the frame.  So, if most of the frame\n were to be encoded with a QP of around 30, this region would get a QP\n of around 24 (an offset of approximately -1/10 * (51 - -12) = -6.3).\n An extreme value of -1 would indicate that this region should be\n encoded with the best possible quality regardless of the treatment of\n the rest of the frame - that is, should be encoded at a QP of -12."]
    pub qoffset: AVRational,
}
#[doc = " This structure describes decoded (raw) audio or video data.\n\n AVFrame must be allocated using av_frame_alloc(). Note that this only\n allocates the AVFrame itself, the buffers for the data must be managed\n through other means (see below).\n AVFrame must be freed with av_frame_free().\n\n AVFrame is typically allocated once and then reused multiple times to hold\n different data (e.g. a single AVFrame to hold frames received from a\n decoder). In such a case, av_frame_unref() will free any references held by\n the frame and reset it to its original clean state before it\n is reused again.\n\n The data described by an AVFrame is usually reference counted through the\n AVBuffer API. The underlying buffer references are stored in AVFrame.buf /\n AVFrame.extended_buf. An AVFrame is considered to be reference counted if at\n least one reference is set, i.e. if AVFrame.buf[0] != NULL. In such a case,\n every single data plane must be contained in one of the buffers in\n AVFrame.buf or AVFrame.extended_buf.\n There may be a single buffer for all the data, or one separate buffer for\n each plane, or anything in between.\n\n sizeof(AVFrame) is not a part of the public ABI, so new fields may be added\n to the end with a minor bump.\n\n Fields can be accessed through AVOptions, the name string used, matches the\n C structure field name for fields accessible through AVOptions."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct AVFrame {
    #[doc = " pointer to the picture/channel planes.\n This might be different from the first allocated byte. For video,\n it could even point to the end of the image data.\n\n All pointers in data and extended_data must point into one of the\n AVBufferRef in buf or extended_buf.\n\n Some decoders access areas outside 0,0 - width,height, please\n see avcodec_align_dimensions2(). Some filters and swscale can read\n up to 16 bytes beyond the planes, if these filters are to be used,\n then 16 extra bytes must be allocated.\n\n NOTE: Pointers not needed by the format MUST be set to NULL.\n\n @attention In case of video, the data[] pointers can point to the\n end of image data in order to reverse line order, when used in\n combination with negative values in the linesize[] array."]
    pub data: [*mut u8; 8usize],
    #[doc = " For video, a positive or negative value, which is typically indicating\n the size in bytes of each picture line, but it can also be:\n - the negative byte size of lines for vertical flipping\n   (with data[n] pointing to the end of the data\n - a positive or negative multiple of the byte size as for accessing\n   even and odd fields of a frame (possibly flipped)\n\n For audio, only linesize[0] may be set. For planar audio, each channel\n plane must be the same size.\n\n For video the linesizes should be multiples of the CPUs alignment\n preference, this is 16 or 32 for modern desktop CPUs.\n Some code requires such alignment other code can be slower without\n correct alignment, for yet other it makes no difference.\n\n @note The linesize may be larger than the size of usable data -- there\n may be extra padding present for performance reasons.\n\n @attention In case of video, line size values can be negative to achieve\n a vertically inverted iteration over image lines."]
    pub linesize: [::std::os::raw::c_int; 8usize],
    #[doc = " pointers to the data planes/channels.\n\n For video, this should simply point to data[].\n\n For planar audio, each channel has a separate data pointer, and\n linesize[0] contains the size of each channel buffer.\n For packed audio, there is just one data pointer, and linesize[0]\n contains the total size of the buffer for all channels.\n\n Note: Both data and extended_data should always be set in a valid frame,\n but for planar audio with more channels that can fit in data,\n extended_data must be used in order to access all channels."]
    pub extended_data: *mut *mut u8,
    #[doc = " @name Video dimensions\n Video frames only. The coded dimensions (in pixels) of the video frame,\n i.e. the size of the rectangle that contains some well-defined values.\n\n @note The part of the frame intended for display/presentation is further\n restricted by the @ref cropping \"Cropping rectangle\".\n @{"]
    pub width: ::std::os::raw::c_int,
    #[doc = " @name Video dimensions\n Video frames only. The coded dimensions (in pixels) of the video frame,\n i.e. the size of the rectangle that contains some well-defined values.\n\n @note The part of the frame intended for display/presentation is further\n restricted by the @ref cropping \"Cropping rectangle\".\n @{"]
    pub height: ::std::os::raw::c_int,
    #[doc = " number of audio samples (per channel) described by this frame"]
    pub nb_samples: ::std::os::raw::c_int,
    #[doc = " format of the frame, -1 if unknown or unset\n Values correspond to enum AVPixelFormat for video frames,\n enum AVSampleFormat for audio)"]
    pub format: ::std::os::raw::c_int,
    #[doc = " 1 -> keyframe, 0-> not\n\n @deprecated Use AV_FRAME_FLAG_KEY instead"]
    pub key_frame: ::std::os::raw::c_int,
    #[doc = " Picture type of the frame."]
    pub pict_type: AVPictureType,
    #[doc = " Sample aspect ratio for the video frame, 0/1 if unknown/unspecified."]
    pub sample_aspect_ratio: AVRational,
    #[doc = " Presentation timestamp in time_base units (time when frame should be shown to user)."]
    pub pts: i64,
    #[doc = " DTS copied from the AVPacket that triggered returning this frame. (if frame threading isn't used)\n This is also the Presentation time of this AVFrame calculated from\n only AVPacket.dts values without pts values."]
    pub pkt_dts: i64,
    #[doc = " Time base for the timestamps in this frame.\n In the future, this field may be set on frames output by decoders or\n filters, but its value will be by default ignored on input to encoders\n or filters."]
    pub time_base: AVRational,
    #[doc = " quality (between 1 (good) and FF_LAMBDA_MAX (bad))"]
    pub quality: ::std::os::raw::c_int,
    #[doc = " Frame owner's private data.\n\n This field may be set by the code that allocates/owns the frame data.\n It is then not touched by any library functions, except:\n - it is copied to other references by av_frame_copy_props() (and hence by\n   av_frame_ref());\n - it is set to NULL when the frame is cleared by av_frame_unref()\n - on the caller's explicit request. E.g. libavcodec encoders/decoders\n   will copy this field to/from @ref AVPacket \"AVPackets\" if the caller sets\n   @ref AV_CODEC_FLAG_COPY_OPAQUE.\n\n @see opaque_ref the reference-counted analogue"]
    pub opaque: *mut ::std::os::raw::c_void,
    #[doc = " Number of fields in this frame which should be repeated, i.e. the total\n duration of this frame should be repeat_pict + 2 normal field durations.\n\n For interlaced frames this field may be set to 1, which signals that this\n frame should be presented as 3 fields: beginning with the first field (as\n determined by AV_FRAME_FLAG_TOP_FIELD_FIRST being set or not), followed\n by the second field, and then the first field again.\n\n For progressive frames this field may be set to a multiple of 2, which\n signals that this frame's duration should be (repeat_pict + 2) / 2\n normal frame durations.\n\n @note This field is computed from MPEG2 repeat_first_field flag and its\n associated flags, H.264 pic_struct from picture timing SEI, and\n their analogues in other codecs. Typically it should only be used when\n higher-layer timing information is not available."]
    pub repeat_pict: ::std::os::raw::c_int,
    #[doc = " The content of the picture is interlaced.\n\n @deprecated Use AV_FRAME_FLAG_INTERLACED instead"]
    pub interlaced_frame: ::std::os::raw::c_int,
    #[doc = " If the content is interlaced, is top field displayed first.\n\n @deprecated Use AV_FRAME_FLAG_TOP_FIELD_FIRST instead"]
    pub top_field_first: ::std::os::raw::c_int,
    #[doc = " Tell user application that palette has changed from previous frame."]
    pub palette_has_changed: ::std::os::raw::c_int,
    #[doc = " Sample rate of the audio data."]
    pub sample_rate: ::std::os::raw::c_int,
    #[doc = " AVBuffer references backing the data for this frame. All the pointers in\n data and extended_data must point inside one of the buffers in buf or\n extended_buf. This array must be filled contiguously -- if buf[i] is\n non-NULL then buf[j] must also be non-NULL for all j < i.\n\n There may be at most one AVBuffer per data plane, so for video this array\n always contains all the references. For planar audio with more than\n AV_NUM_DATA_POINTERS channels, there may be more buffers than can fit in\n this array. Then the extra AVBufferRef pointers are stored in the\n extended_buf array."]
    pub buf: [*mut AVBufferRef; 8usize],
    #[doc = " For planar audio which requires more than AV_NUM_DATA_POINTERS\n AVBufferRef pointers, this array will hold all the references which\n cannot fit into AVFrame.buf.\n\n Note that this is different from AVFrame.extended_data, which always\n contains all the pointers. This array only contains the extra pointers,\n which cannot fit into AVFrame.buf.\n\n This array is always allocated using av_malloc() by whoever constructs\n the frame. It is freed in av_frame_unref()."]
    pub extended_buf: *mut *mut AVBufferRef,
    #[doc = " Number of elements in extended_buf."]
    pub nb_extended_buf: ::std::os::raw::c_int,
    pub side_data: *mut *mut AVFrameSideData,
    pub nb_side_data: ::std::os::raw::c_int,
    #[doc = " Frame flags, a combination of @ref lavu_frame_flags"]
    pub flags: ::std::os::raw::c_int,
    #[doc = " MPEG vs JPEG YUV range.\n - encoding: Set by user\n - decoding: Set by libavcodec"]
    pub color_range: AVColorRange,
    pub color_primaries: AVColorPrimaries,
    pub color_trc: AVColorTransferCharacteristic,
    #[doc = " YUV colorspace type.\n - encoding: Set by user\n - decoding: Set by libavcodec"]
    pub colorspace: AVColorSpace,
    pub chroma_location: AVChromaLocation,
    #[doc = " frame timestamp estimated using various heuristics, in stream time base\n - encoding: unused\n - decoding: set by libavcodec, read by user."]
    pub best_effort_timestamp: i64,
    #[doc = " reordered pos from the last AVPacket that has been input into the decoder\n - encoding: unused\n - decoding: Read by user.\n @deprecated use AV_CODEC_FLAG_COPY_OPAQUE to pass through arbitrary user\n             data from packets to frames"]
    pub pkt_pos: i64,
    #[doc = " metadata.\n - encoding: Set by user.\n - decoding: Set by libavcodec."]
    pub metadata: *mut AVDictionary,
    #[doc = " decode error flags of the frame, set to a combination of\n FF_DECODE_ERROR_xxx flags if the decoder produced a frame, but there\n were errors during the decoding.\n - encoding: unused\n - decoding: set by libavcodec, read by user."]
    pub decode_error_flags: ::std::os::raw::c_int,
    #[doc = " size of the corresponding packet containing the compressed\n frame.\n It is set to a negative value if unknown.\n - encoding: unused\n - decoding: set by libavcodec, read by user.\n @deprecated use AV_CODEC_FLAG_COPY_OPAQUE to pass through arbitrary user\n             data from packets to frames"]
    pub pkt_size: ::std::os::raw::c_int,
    #[doc = " For hwaccel-format frames, this should be a reference to the\n AVHWFramesContext describing the frame."]
    pub hw_frames_ctx: *mut AVBufferRef,
    #[doc = " Frame owner's private data.\n\n This field may be set by the code that allocates/owns the frame data.\n It is then not touched by any library functions, except:\n - a new reference to the underlying buffer is propagated by\n   av_frame_copy_props() (and hence by av_frame_ref());\n - it is unreferenced in av_frame_unref();\n - on the caller's explicit request. E.g. libavcodec encoders/decoders\n   will propagate a new reference to/from @ref AVPacket \"AVPackets\" if the\n   caller sets @ref AV_CODEC_FLAG_COPY_OPAQUE.\n\n @see opaque the plain pointer analogue"]
    pub opaque_ref: *mut AVBufferRef,
    #[doc = " @anchor cropping\n @name Cropping\n Video frames only. The number of pixels to discard from the the\n top/bottom/left/right border of the frame to obtain the sub-rectangle of\n the frame intended for presentation.\n @{"]
    pub crop_top: usize,
    pub crop_bottom: usize,
    pub crop_left: usize,
    pub crop_right: usize,
    #[doc = " AVBufferRef for internal use by a single libav* library.\n Must not be used to transfer data between libraries.\n Has to be NULL when ownership of the frame leaves the respective library.\n\n Code outside the FFmpeg libs should never check or change the contents of the buffer ref.\n\n FFmpeg calls av_buffer_unref() on it when the frame is unreferenced.\n av_frame_copy_props() calls create a new reference with av_buffer_ref()\n for the target frame's private_ref field."]
    pub private_ref: *mut AVBufferRef,
    #[doc = " Channel layout of the audio data."]
    pub ch_layout: AVChannelLayout,
    #[doc = " Duration of the frame, in the same units as pts. 0 if unknown."]
    pub duration: i64,
}
impl Default for AVFrame {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
extern "C" {
    #[doc = " Allocate an AVFrame and set its fields to default values.  The resulting\n struct must be freed using av_frame_free().\n\n @return An AVFrame filled with default values or NULL on failure.\n\n @note this only allocates the AVFrame itself, not the data buffers. Those\n must be allocated through other means, e.g. with av_frame_get_buffer() or\n manually."]
    pub fn av_frame_alloc() -> *mut AVFrame;
}
extern "C" {
    #[doc = " Free the frame and any dynamically allocated objects in it,\n e.g. extended_data. If the frame is reference counted, it will be\n unreferenced first.\n\n @param frame frame to be freed. The pointer will be set to NULL."]
    pub fn av_frame_free(frame: *mut *mut AVFrame);
}
extern "C" {
    #[doc = " Set up a new reference to the data described by the source frame.\n\n Copy frame properties from src to dst and create a new reference for each\n AVBufferRef from src.\n\n If src is not reference counted, new buffers are allocated and the data is\n copied.\n\n @warning: dst MUST have been either unreferenced with av_frame_unref(dst),\n           or newly allocated with av_frame_alloc() before calling this\n           function, or undefined behavior will occur.\n\n @return 0 on success, a negative AVERROR on error"]
    pub fn av_frame_ref(dst: *mut AVFrame, src: *const AVFrame) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Ensure the destination frame refers to the same data described by the source\n frame, either by creating a new reference for each AVBufferRef from src if\n they differ from those in dst, by allocating new buffers and copying data if\n src is not reference counted, or by unrefencing it if src is empty.\n\n Frame properties on dst will be replaced by those from src.\n\n @return 0 on success, a negative AVERROR on error. On error, dst is\n         unreferenced."]
    pub fn av_frame_replace(dst: *mut AVFrame, src: *const AVFrame) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Create a new frame that references the same data as src.\n\n This is a shortcut for av_frame_alloc()+av_frame_ref().\n\n @return newly created AVFrame on success, NULL on error."]
    pub fn av_frame_clone(src: *const AVFrame) -> *mut AVFrame;
}
extern "C" {
    #[doc = " Unreference all the buffers referenced by frame and reset the frame fields."]
    pub fn av_frame_unref(frame: *mut AVFrame);
}
extern "C" {
    #[doc = " Move everything contained in src to dst and reset src.\n\n @warning: dst is not unreferenced, but directly overwritten without reading\n           or deallocating its contents. Call av_frame_unref(dst) manually\n           before calling this function to ensure that no memory is leaked."]
    pub fn av_frame_move_ref(dst: *mut AVFrame, src: *mut AVFrame);
}
extern "C" {
    #[doc = " Allocate new buffer(s) for audio or video data.\n\n The following fields must be set on frame before calling this function:\n - format (pixel format for video, sample format for audio)\n - width and height for video\n - nb_samples and ch_layout for audio\n\n This function will fill AVFrame.data and AVFrame.buf arrays and, if\n necessary, allocate and fill AVFrame.extended_data and AVFrame.extended_buf.\n For planar formats, one buffer will be allocated for each plane.\n\n @warning: if frame already has been allocated, calling this function will\n           leak memory. In addition, undefined behavior can occur in certain\n           cases.\n\n @param frame frame in which to store the new buffers.\n @param align Required buffer size alignment. If equal to 0, alignment will be\n              chosen automatically for the current CPU. It is highly\n              recommended to pass 0 here unless you know what you are doing.\n\n @return 0 on success, a negative AVERROR on error."]
    pub fn av_frame_get_buffer(
        frame: *mut AVFrame,
        align: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Check if the frame data is writable.\n\n @return A positive value if the frame data is writable (which is true if and\n only if each of the underlying buffers has only one reference, namely the one\n stored in this frame). Return 0 otherwise.\n\n If 1 is returned the answer is valid until av_buffer_ref() is called on any\n of the underlying AVBufferRefs (e.g. through av_frame_ref() or directly).\n\n @see av_frame_make_writable(), av_buffer_is_writable()"]
    pub fn av_frame_is_writable(frame: *mut AVFrame) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Ensure that the frame data is writable, avoiding data copy if possible.\n\n Do nothing if the frame is writable, allocate new buffers and copy the data\n if it is not. Non-refcounted frames behave as non-writable, i.e. a copy\n is always made.\n\n @return 0 on success, a negative AVERROR on error.\n\n @see av_frame_is_writable(), av_buffer_is_writable(),\n av_buffer_make_writable()"]
    pub fn av_frame_make_writable(frame: *mut AVFrame) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Copy the frame data from src to dst.\n\n This function does not allocate anything, dst must be already initialized and\n allocated with the same parameters as src.\n\n This function only copies the frame data (i.e. the contents of the data /\n extended data arrays), not any other properties.\n\n @return >= 0 on success, a negative AVERROR on error."]
    pub fn av_frame_copy(dst: *mut AVFrame, src: *const AVFrame) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Copy only \"metadata\" fields from src to dst.\n\n Metadata for the purpose of this function are those fields that do not affect\n the data layout in the buffers.  E.g. pts, sample rate (for audio) or sample\n aspect ratio (for video), but not width/height or channel layout.\n Side data is also copied."]
    pub fn av_frame_copy_props(dst: *mut AVFrame, src: *const AVFrame) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get the buffer reference a given data plane is stored in.\n\n @param frame the frame to get the plane's buffer from\n @param plane index of the data plane of interest in frame->extended_data.\n\n @return the buffer reference that contains the plane or NULL if the input\n frame is not valid."]
    pub fn av_frame_get_plane_buffer(
        frame: *const AVFrame,
        plane: ::std::os::raw::c_int,
    ) -> *mut AVBufferRef;
}
extern "C" {
    #[doc = " Add a new side data to a frame.\n\n @param frame a frame to which the side data should be added\n @param type type of the added side data\n @param size size of the side data\n\n @return newly added side data on success, NULL on error"]
    pub fn av_frame_new_side_data(
        frame: *mut AVFrame,
        type_: AVFrameSideDataType,
        size: usize,
    ) -> *mut AVFrameSideData;
}
extern "C" {
    #[doc = " Add a new side data to a frame from an existing AVBufferRef\n\n @param frame a frame to which the side data should be added\n @param type  the type of the added side data\n @param buf   an AVBufferRef to add as side data. The ownership of\n              the reference is transferred to the frame.\n\n @return newly added side data on success, NULL on error. On failure\n         the frame is unchanged and the AVBufferRef remains owned by\n         the caller."]
    pub fn av_frame_new_side_data_from_buf(
        frame: *mut AVFrame,
        type_: AVFrameSideDataType,
        buf: *mut AVBufferRef,
    ) -> *mut AVFrameSideData;
}
extern "C" {
    #[doc = " @return a pointer to the side data of a given type on success, NULL if there\n is no side data with such type in this frame."]
    pub fn av_frame_get_side_data(
        frame: *const AVFrame,
        type_: AVFrameSideDataType,
    ) -> *mut AVFrameSideData;
}
extern "C" {
    #[doc = " Remove and free all side data instances of the given type."]
    pub fn av_frame_remove_side_data(frame: *mut AVFrame, type_: AVFrameSideDataType);
}
#[doc = " Apply the maximum possible cropping, even if it requires setting the\n AVFrame.data[] entries to unaligned pointers. Passing unaligned data\n to FFmpeg API is generally not allowed, and causes undefined behavior\n (such as crashes). You can pass unaligned data only to FFmpeg APIs that\n are explicitly documented to accept it. Use this flag only if you\n absolutely know what you are doing."]
pub const AV_FRAME_CROP_UNALIGNED: _bindgen_ty_1 = 1;
#[doc = " Flags for frame cropping."]
pub type _bindgen_ty_1 = ::std::os::raw::c_uint;
extern "C" {
    #[doc = " Crop the given video AVFrame according to its crop_left/crop_top/crop_right/\n crop_bottom fields. If cropping is successful, the function will adjust the\n data pointers and the width/height fields, and set the crop fields to 0.\n\n In all cases, the cropping boundaries will be rounded to the inherent\n alignment of the pixel format. In some cases, such as for opaque hwaccel\n formats, the left/top cropping is ignored. The crop fields are set to 0 even\n if the cropping was rounded or ignored.\n\n @param frame the frame which should be cropped\n @param flags Some combination of AV_FRAME_CROP_* flags, or 0.\n\n @return >= 0 on success, a negative AVERROR on error. If the cropping fields\n were invalid, AVERROR(ERANGE) is returned, and nothing is changed."]
    pub fn av_frame_apply_cropping(
        frame: *mut AVFrame,
        flags: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " @return a string identifying the side data type"]
    pub fn av_frame_side_data_name(type_: AVFrameSideDataType) -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " @return side data descriptor corresponding to a given side data type, NULL\n         when not available."]
    pub fn av_frame_side_data_desc(type_: AVFrameSideDataType) -> *const AVSideDataDescriptor;
}
extern "C" {
    #[doc = " Free all side data entries and their contents, then zeroes out the\n values which the pointers are pointing to.\n\n @param sd    pointer to array of side data to free. Will be set to NULL\n              upon return.\n @param nb_sd pointer to an integer containing the number of entries in\n              the array. Will be set to 0 upon return."]
    pub fn av_frame_side_data_free(
        sd: *mut *mut *mut AVFrameSideData,
        nb_sd: *mut ::std::os::raw::c_int,
    );
}
extern "C" {
    #[doc = " Add new side data entry to an array.\n\n @param sd    pointer to array of side data to which to add another entry,\n              or to NULL in order to start a new array.\n @param nb_sd pointer to an integer containing the number of entries in\n              the array.\n @param type  type of the added side data\n @param size  size of the side data\n @param flags Some combination of AV_FRAME_SIDE_DATA_FLAG_* flags, or 0.\n\n @return newly added side data on success, NULL on error.\n @note In case of AV_FRAME_SIDE_DATA_FLAG_UNIQUE being set, entries of\n       matching AVFrameSideDataType will be removed before the addition\n       is attempted.\n @note In case of AV_FRAME_SIDE_DATA_FLAG_REPLACE being set, if an\n       entry of the same type already exists, it will be replaced instead."]
    pub fn av_frame_side_data_new(
        sd: *mut *mut *mut AVFrameSideData,
        nb_sd: *mut ::std::os::raw::c_int,
        type_: AVFrameSideDataType,
        size: usize,
        flags: ::std::os::raw::c_uint,
    ) -> *mut AVFrameSideData;
}
extern "C" {
    #[doc = " Add a new side data entry to an array from an existing AVBufferRef.\n\n @param sd    pointer to array of side data to which to add another entry,\n              or to NULL in order to start a new array.\n @param nb_sd pointer to an integer containing the number of entries in\n              the array.\n @param type  type of the added side data\n @param buf   Pointer to AVBufferRef to add to the array. On success,\n              the function takes ownership of the AVBufferRef and *buf is\n              set to NULL, unless AV_FRAME_SIDE_DATA_FLAG_NEW_REF is set\n              in which case the ownership will remain with the caller.\n @param flags Some combination of AV_FRAME_SIDE_DATA_FLAG_* flags, or 0.\n\n @return newly added side data on success, NULL on error.\n @note In case of AV_FRAME_SIDE_DATA_FLAG_UNIQUE being set, entries of\n       matching AVFrameSideDataType will be removed before the addition\n       is attempted.\n @note In case of AV_FRAME_SIDE_DATA_FLAG_REPLACE being set, if an\n       entry of the same type already exists, it will be replaced instead.\n"]
    pub fn av_frame_side_data_add(
        sd: *mut *mut *mut AVFrameSideData,
        nb_sd: *mut ::std::os::raw::c_int,
        type_: AVFrameSideDataType,
        buf: *mut *mut AVBufferRef,
        flags: ::std::os::raw::c_uint,
    ) -> *mut AVFrameSideData;
}
extern "C" {
    #[doc = " Add a new side data entry to an array based on existing side data, taking\n a reference towards the contained AVBufferRef.\n\n @param sd    pointer to array of side data to which to add another entry,\n              or to NULL in order to start a new array.\n @param nb_sd pointer to an integer containing the number of entries in\n              the array.\n @param src   side data to be cloned, with a new reference utilized\n              for the buffer.\n @param flags Some combination of AV_FRAME_SIDE_DATA_FLAG_* flags, or 0.\n\n @return negative error code on failure, >=0 on success.\n @note In case of AV_FRAME_SIDE_DATA_FLAG_UNIQUE being set, entries of\n       matching AVFrameSideDataType will be removed before the addition\n       is attempted.\n @note In case of AV_FRAME_SIDE_DATA_FLAG_REPLACE being set, if an\n       entry of the same type already exists, it will be replaced instead."]
    pub fn av_frame_side_data_clone(
        sd: *mut *mut *mut AVFrameSideData,
        nb_sd: *mut ::std::os::raw::c_int,
        src: *const AVFrameSideData,
        flags: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get a side data entry of a specific type from an array.\n\n @param sd    array of side data.\n @param nb_sd integer containing the number of entries in the array.\n @param type  type of side data to be queried\n\n @return a pointer to the side data of a given type on success, NULL if there\n         is no side data with such type in this set."]
    pub fn av_frame_side_data_get_c(
        sd: *const *const AVFrameSideData,
        nb_sd: ::std::os::raw::c_int,
        type_: AVFrameSideDataType,
    ) -> *const AVFrameSideData;
}
extern "C" {
    #[doc = " Remove and free all side data instances of the given type from an array."]
    pub fn av_frame_side_data_remove(
        sd: *mut *mut *mut AVFrameSideData,
        nb_sd: *mut ::std::os::raw::c_int,
        type_: AVFrameSideDataType,
    );
}
pub const AVHWDeviceType_AV_HWDEVICE_TYPE_NONE: AVHWDeviceType = 0;
pub const AVHWDeviceType_AV_HWDEVICE_TYPE_VDPAU: AVHWDeviceType = 1;
pub const AVHWDeviceType_AV_HWDEVICE_TYPE_CUDA: AVHWDeviceType = 2;
pub const AVHWDeviceType_AV_HWDEVICE_TYPE_VAAPI: AVHWDeviceType = 3;
pub const AVHWDeviceType_AV_HWDEVICE_TYPE_DXVA2: AVHWDeviceType = 4;
pub const AVHWDeviceType_AV_HWDEVICE_TYPE_QSV: AVHWDeviceType = 5;
pub const AVHWDeviceType_AV_HWDEVICE_TYPE_VIDEOTOOLBOX: AVHWDeviceType = 6;
pub const AVHWDeviceType_AV_HWDEVICE_TYPE_D3D11VA: AVHWDeviceType = 7;
pub const AVHWDeviceType_AV_HWDEVICE_TYPE_DRM: AVHWDeviceType = 8;
pub const AVHWDeviceType_AV_HWDEVICE_TYPE_OPENCL: AVHWDeviceType = 9;
pub const AVHWDeviceType_AV_HWDEVICE_TYPE_MEDIACODEC: AVHWDeviceType = 10;
pub const AVHWDeviceType_AV_HWDEVICE_TYPE_VULKAN: AVHWDeviceType = 11;
pub const AVHWDeviceType_AV_HWDEVICE_TYPE_D3D12VA: AVHWDeviceType = 12;
pub type AVHWDeviceType = ::std::os::raw::c_uint;
#[doc = " This struct aggregates all the (hardware/vendor-specific) \"high-level\" state,\n i.e. state that is not tied to a concrete processing configuration.\n E.g., in an API that supports hardware-accelerated encoding and decoding,\n this struct will (if possible) wrap the state that is common to both encoding\n and decoding and from which specific instances of encoders or decoders can be\n derived.\n\n This struct is reference-counted with the AVBuffer mechanism. The\n av_hwdevice_ctx_alloc() constructor yields a reference, whose data field\n points to the actual AVHWDeviceContext. Further objects derived from\n AVHWDeviceContext (such as AVHWFramesContext, describing a frame pool with\n specific properties) will hold an internal reference to it. After all the\n references are released, the AVHWDeviceContext itself will be freed,\n optionally invoking a user-specified callback for uninitializing the hardware\n state."]
#[repr(C)]
#[derive(Debug, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVHWDeviceContext {
    #[doc = " A class for logging. Set by av_hwdevice_ctx_alloc()."]
    pub av_class: *const AVClass,
    #[doc = " This field identifies the underlying API used for hardware access.\n\n This field is set when this struct is allocated and never changed\n afterwards."]
    pub type_: AVHWDeviceType,
    #[doc = " The format-specific data, allocated and freed by libavutil along with\n this context.\n\n Should be cast by the user to the format-specific context defined in the\n corresponding header (hwcontext_*.h) and filled as described in the\n documentation before calling av_hwdevice_ctx_init().\n\n After calling av_hwdevice_ctx_init() this struct should not be modified\n by the caller."]
    pub hwctx: *mut ::std::os::raw::c_void,
    #[doc = " This field may be set by the caller before calling av_hwdevice_ctx_init().\n\n If non-NULL, this callback will be called when the last reference to\n this context is unreferenced, immediately before it is freed.\n\n @note when other objects (e.g an AVHWFramesContext) are derived from this\n       struct, this callback will be invoked after all such child objects\n       are fully uninitialized and their respective destructors invoked."]
    pub free: ::std::option::Option<unsafe extern "C" fn(ctx: *mut AVHWDeviceContext)>,
    #[doc = " Arbitrary user data, to be used e.g. by the free() callback."]
    pub user_opaque: *mut ::std::os::raw::c_void,
}
impl Default for AVHWDeviceContext {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = " This struct describes a set or pool of \"hardware\" frames (i.e. those with\n data not located in normal system memory). All the frames in the pool are\n assumed to be allocated in the same way and interchangeable.\n\n This struct is reference-counted with the AVBuffer mechanism and tied to a\n given AVHWDeviceContext instance. The av_hwframe_ctx_alloc() constructor\n yields a reference, whose data field points to the actual AVHWFramesContext\n struct."]
#[repr(C)]
#[derive(Debug, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVHWFramesContext {
    #[doc = " A class for logging."]
    pub av_class: *const AVClass,
    #[doc = " A reference to the parent AVHWDeviceContext. This reference is owned and\n managed by the enclosing AVHWFramesContext, but the caller may derive\n additional references from it."]
    pub device_ref: *mut AVBufferRef,
    #[doc = " The parent AVHWDeviceContext. This is simply a pointer to\n device_ref->data provided for convenience.\n\n Set by libavutil in av_hwframe_ctx_init()."]
    pub device_ctx: *mut AVHWDeviceContext,
    #[doc = " The format-specific data, allocated and freed automatically along with\n this context.\n\n The user shall ignore this field if the corresponding format-specific\n header (hwcontext_*.h) does not define a context to be used as\n AVHWFramesContext.hwctx.\n\n Otherwise, it should be cast by the user to said context and filled\n as described in the documentation before calling av_hwframe_ctx_init().\n\n After any frames using this context are created, the contents of this\n struct should not be modified by the caller."]
    pub hwctx: *mut ::std::os::raw::c_void,
    #[doc = " This field may be set by the caller before calling av_hwframe_ctx_init().\n\n If non-NULL, this callback will be called when the last reference to\n this context is unreferenced, immediately before it is freed."]
    pub free: ::std::option::Option<unsafe extern "C" fn(ctx: *mut AVHWFramesContext)>,
    #[doc = " Arbitrary user data, to be used e.g. by the free() callback."]
    pub user_opaque: *mut ::std::os::raw::c_void,
    #[doc = " A pool from which the frames are allocated by av_hwframe_get_buffer().\n This field may be set by the caller before calling av_hwframe_ctx_init().\n The buffers returned by calling av_buffer_pool_get() on this pool must\n have the properties described in the documentation in the corresponding hw\n type's header (hwcontext_*.h). The pool will be freed strictly before\n this struct's free() callback is invoked.\n\n This field may be NULL, then libavutil will attempt to allocate a pool\n internally. Note that certain device types enforce pools allocated at\n fixed size (frame count), which cannot be extended dynamically. In such a\n case, initial_pool_size must be set appropriately."]
    pub pool: *mut AVBufferPool,
    #[doc = " Initial size of the frame pool. If a device type does not support\n dynamically resizing the pool, then this is also the maximum pool size.\n\n May be set by the caller before calling av_hwframe_ctx_init(). Must be\n set if pool is NULL and the device type does not support dynamic pools."]
    pub initial_pool_size: ::std::os::raw::c_int,
    #[doc = " The pixel format identifying the underlying HW surface type.\n\n Must be a hwaccel format, i.e. the corresponding descriptor must have the\n AV_PIX_FMT_FLAG_HWACCEL flag set.\n\n Must be set by the user before calling av_hwframe_ctx_init()."]
    pub format: AVPixelFormat,
    #[doc = " The pixel format identifying the actual data layout of the hardware\n frames.\n\n Must be set by the caller before calling av_hwframe_ctx_init().\n\n @note when the underlying API does not provide the exact data layout, but\n only the colorspace/bit depth, this field should be set to the fully\n planar version of that format (e.g. for 8-bit 420 YUV it should be\n AV_PIX_FMT_YUV420P, not AV_PIX_FMT_NV12 or anything else)."]
    pub sw_format: AVPixelFormat,
    #[doc = " The allocated dimensions of the frames in this pool.\n\n Must be set by the user before calling av_hwframe_ctx_init()."]
    pub width: ::std::os::raw::c_int,
    #[doc = " The allocated dimensions of the frames in this pool.\n\n Must be set by the user before calling av_hwframe_ctx_init()."]
    pub height: ::std::os::raw::c_int,
}
impl Default for AVHWFramesContext {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
extern "C" {
    #[doc = " Look up an AVHWDeviceType by name.\n\n @param name String name of the device type (case-insensitive).\n @return The type from enum AVHWDeviceType, or AV_HWDEVICE_TYPE_NONE if\n         not found."]
    pub fn av_hwdevice_find_type_by_name(name: *const ::std::os::raw::c_char) -> AVHWDeviceType;
}
extern "C" {
    #[doc = " Get the string name of an AVHWDeviceType.\n\n @param type Type from enum AVHWDeviceType.\n @return Pointer to a static string containing the name, or NULL if the type\n         is not valid."]
    pub fn av_hwdevice_get_type_name(type_: AVHWDeviceType) -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Iterate over supported device types.\n\n @param prev AV_HWDEVICE_TYPE_NONE initially, then the previous type\n             returned by this function in subsequent iterations.\n @return The next usable device type from enum AVHWDeviceType, or\n         AV_HWDEVICE_TYPE_NONE if there are no more."]
    pub fn av_hwdevice_iterate_types(prev: AVHWDeviceType) -> AVHWDeviceType;
}
extern "C" {
    #[doc = " Allocate an AVHWDeviceContext for a given hardware type.\n\n @param type the type of the hardware device to allocate.\n @return a reference to the newly created AVHWDeviceContext on success or NULL\n         on failure."]
    pub fn av_hwdevice_ctx_alloc(type_: AVHWDeviceType) -> *mut AVBufferRef;
}
extern "C" {
    #[doc = " Finalize the device context before use. This function must be called after\n the context is filled with all the required information and before it is\n used in any way.\n\n @param ref a reference to the AVHWDeviceContext\n @return 0 on success, a negative AVERROR code on failure"]
    pub fn av_hwdevice_ctx_init(ref_: *mut AVBufferRef) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Open a device of the specified type and create an AVHWDeviceContext for it.\n\n This is a convenience function intended to cover the simple cases. Callers\n who need to fine-tune device creation/management should open the device\n manually and then wrap it in an AVHWDeviceContext using\n av_hwdevice_ctx_alloc()/av_hwdevice_ctx_init().\n\n The returned context is already initialized and ready for use, the caller\n should not call av_hwdevice_ctx_init() on it. The user_opaque/free fields of\n the created AVHWDeviceContext are set by this function and should not be\n touched by the caller.\n\n @param device_ctx On success, a reference to the newly-created device context\n                   will be written here. The reference is owned by the caller\n                   and must be released with av_buffer_unref() when no longer\n                   needed. On failure, NULL will be written to this pointer.\n @param type The type of the device to create.\n @param device A type-specific string identifying the device to open.\n @param opts A dictionary of additional (type-specific) options to use in\n             opening the device. The dictionary remains owned by the caller.\n @param flags currently unused\n\n @return 0 on success, a negative AVERROR code on failure."]
    pub fn av_hwdevice_ctx_create(
        device_ctx: *mut *mut AVBufferRef,
        type_: AVHWDeviceType,
        device: *const ::std::os::raw::c_char,
        opts: *mut AVDictionary,
        flags: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Create a new device of the specified type from an existing device.\n\n If the source device is a device of the target type or was originally\n derived from such a device (possibly through one or more intermediate\n devices of other types), then this will return a reference to the\n existing device of the same type as is requested.\n\n Otherwise, it will attempt to derive a new device from the given source\n device.  If direct derivation to the new type is not implemented, it will\n attempt the same derivation from each ancestor of the source device in\n turn looking for an implemented derivation method.\n\n @param dst_ctx On success, a reference to the newly-created\n                AVHWDeviceContext.\n @param type    The type of the new device to create.\n @param src_ctx A reference to an existing AVHWDeviceContext which will be\n                used to create the new device.\n @param flags   Currently unused; should be set to zero.\n @return        Zero on success, a negative AVERROR code on failure."]
    pub fn av_hwdevice_ctx_create_derived(
        dst_ctx: *mut *mut AVBufferRef,
        type_: AVHWDeviceType,
        src_ctx: *mut AVBufferRef,
        flags: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Create a new device of the specified type from an existing device.\n\n This function performs the same action as av_hwdevice_ctx_create_derived,\n however, it is able to set options for the new device to be derived.\n\n @param dst_ctx On success, a reference to the newly-created\n                AVHWDeviceContext.\n @param type    The type of the new device to create.\n @param src_ctx A reference to an existing AVHWDeviceContext which will be\n                used to create the new device.\n @param options Options for the new device to create, same format as in\n                av_hwdevice_ctx_create.\n @param flags   Currently unused; should be set to zero.\n @return        Zero on success, a negative AVERROR code on failure."]
    pub fn av_hwdevice_ctx_create_derived_opts(
        dst_ctx: *mut *mut AVBufferRef,
        type_: AVHWDeviceType,
        src_ctx: *mut AVBufferRef,
        options: *mut AVDictionary,
        flags: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Allocate an AVHWFramesContext tied to a given device context.\n\n @param device_ctx a reference to a AVHWDeviceContext. This function will make\n                   a new reference for internal use, the one passed to the\n                   function remains owned by the caller.\n @return a reference to the newly created AVHWFramesContext on success or NULL\n         on failure."]
    pub fn av_hwframe_ctx_alloc(device_ctx: *mut AVBufferRef) -> *mut AVBufferRef;
}
extern "C" {
    #[doc = " Finalize the context before use. This function must be called after the\n context is filled with all the required information and before it is attached\n to any frames.\n\n @param ref a reference to the AVHWFramesContext\n @return 0 on success, a negative AVERROR code on failure"]
    pub fn av_hwframe_ctx_init(ref_: *mut AVBufferRef) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Allocate a new frame attached to the given AVHWFramesContext.\n\n @param hwframe_ctx a reference to an AVHWFramesContext\n @param frame an empty (freshly allocated or unreffed) frame to be filled with\n              newly allocated buffers.\n @param flags currently unused, should be set to zero\n @return 0 on success, a negative AVERROR code on failure"]
    pub fn av_hwframe_get_buffer(
        hwframe_ctx: *mut AVBufferRef,
        frame: *mut AVFrame,
        flags: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Copy data to or from a hw surface. At least one of dst/src must have an\n AVHWFramesContext attached.\n\n If src has an AVHWFramesContext attached, then the format of dst (if set)\n must use one of the formats returned by av_hwframe_transfer_get_formats(src,\n AV_HWFRAME_TRANSFER_DIRECTION_FROM).\n If dst has an AVHWFramesContext attached, then the format of src must use one\n of the formats returned by av_hwframe_transfer_get_formats(dst,\n AV_HWFRAME_TRANSFER_DIRECTION_TO)\n\n dst may be \"clean\" (i.e. with data/buf pointers unset), in which case the\n data buffers will be allocated by this function using av_frame_get_buffer().\n If dst->format is set, then this format will be used, otherwise (when\n dst->format is AV_PIX_FMT_NONE) the first acceptable format will be chosen.\n\n The two frames must have matching allocated dimensions (i.e. equal to\n AVHWFramesContext.width/height), since not all device types support\n transferring a sub-rectangle of the whole surface. The display dimensions\n (i.e. AVFrame.width/height) may be smaller than the allocated dimensions, but\n also have to be equal for both frames. When the display dimensions are\n smaller than the allocated dimensions, the content of the padding in the\n destination frame is unspecified.\n\n @param dst the destination frame. dst is not touched on failure.\n @param src the source frame.\n @param flags currently unused, should be set to zero\n @return 0 on success, a negative AVERROR error code on failure."]
    pub fn av_hwframe_transfer_data(
        dst: *mut AVFrame,
        src: *const AVFrame,
        flags: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
#[doc = " Transfer the data from the queried hw frame."]
pub const AVHWFrameTransferDirection_AV_HWFRAME_TRANSFER_DIRECTION_FROM:
    AVHWFrameTransferDirection = 0;
#[doc = " Transfer the data to the queried hw frame."]
pub const AVHWFrameTransferDirection_AV_HWFRAME_TRANSFER_DIRECTION_TO: AVHWFrameTransferDirection =
    1;
pub type AVHWFrameTransferDirection = ::std::os::raw::c_uint;
extern "C" {
    #[doc = " Get a list of possible source or target formats usable in\n av_hwframe_transfer_data().\n\n @param hwframe_ctx the frame context to obtain the information for\n @param dir the direction of the transfer\n @param formats the pointer to the output format list will be written here.\n                The list is terminated with AV_PIX_FMT_NONE and must be freed\n                by the caller when no longer needed using av_free().\n                If this function returns successfully, the format list will\n                have at least one item (not counting the terminator).\n                On failure, the contents of this pointer are unspecified.\n @param flags currently unused, should be set to zero\n @return 0 on success, a negative AVERROR code on failure."]
    pub fn av_hwframe_transfer_get_formats(
        hwframe_ctx: *mut AVBufferRef,
        dir: AVHWFrameTransferDirection,
        formats: *mut *mut AVPixelFormat,
        flags: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
#[doc = " This struct describes the constraints on hardware frames attached to\n a given device with a hardware-specific configuration.  This is returned\n by av_hwdevice_get_hwframe_constraints() and must be freed by\n av_hwframe_constraints_free() after use."]
#[repr(C)]
#[derive(Debug, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVHWFramesConstraints {
    #[doc = " A list of possible values for format in the hw_frames_ctx,\n terminated by AV_PIX_FMT_NONE.  This member will always be filled."]
    pub valid_hw_formats: *mut AVPixelFormat,
    #[doc = " A list of possible values for sw_format in the hw_frames_ctx,\n terminated by AV_PIX_FMT_NONE.  Can be NULL if this information is\n not known."]
    pub valid_sw_formats: *mut AVPixelFormat,
    #[doc = " The minimum size of frames in this hw_frames_ctx.\n (Zero if not known.)"]
    pub min_width: ::std::os::raw::c_int,
    pub min_height: ::std::os::raw::c_int,
    #[doc = " The maximum size of frames in this hw_frames_ctx.\n (INT_MAX if not known / no limit.)"]
    pub max_width: ::std::os::raw::c_int,
    pub max_height: ::std::os::raw::c_int,
}
impl Default for AVHWFramesConstraints {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
extern "C" {
    #[doc = " Allocate a HW-specific configuration structure for a given HW device.\n After use, the user must free all members as required by the specific\n hardware structure being used, then free the structure itself with\n av_free().\n\n @param device_ctx a reference to the associated AVHWDeviceContext.\n @return The newly created HW-specific configuration structure on\n         success or NULL on failure."]
    pub fn av_hwdevice_hwconfig_alloc(device_ctx: *mut AVBufferRef) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    #[doc = " Get the constraints on HW frames given a device and the HW-specific\n configuration to be used with that device.  If no HW-specific\n configuration is provided, returns the maximum possible capabilities\n of the device.\n\n @param ref a reference to the associated AVHWDeviceContext.\n @param hwconfig a filled HW-specific configuration structure, or NULL\n        to return the maximum possible capabilities of the device.\n @return AVHWFramesConstraints structure describing the constraints\n         on the device, or NULL if not available."]
    pub fn av_hwdevice_get_hwframe_constraints(
        ref_: *mut AVBufferRef,
        hwconfig: *const ::std::os::raw::c_void,
    ) -> *mut AVHWFramesConstraints;
}
extern "C" {
    #[doc = " Free an AVHWFrameConstraints structure.\n\n @param constraints The (filled or unfilled) AVHWFrameConstraints structure."]
    pub fn av_hwframe_constraints_free(constraints: *mut *mut AVHWFramesConstraints);
}
#[doc = " The mapping must be readable."]
pub const AV_HWFRAME_MAP_READ: _bindgen_ty_2 = 1;
#[doc = " The mapping must be writeable."]
pub const AV_HWFRAME_MAP_WRITE: _bindgen_ty_2 = 2;
#[doc = " The mapped frame will be overwritten completely in subsequent\n operations, so the current frame data need not be loaded.  Any values\n which are not overwritten are unspecified."]
pub const AV_HWFRAME_MAP_OVERWRITE: _bindgen_ty_2 = 4;
#[doc = " The mapping must be direct.  That is, there must not be any copying in\n the map or unmap steps.  Note that performance of direct mappings may\n be much lower than normal memory."]
pub const AV_HWFRAME_MAP_DIRECT: _bindgen_ty_2 = 8;
#[doc = " Flags to apply to frame mappings."]
pub type _bindgen_ty_2 = ::std::os::raw::c_uint;
extern "C" {
    #[doc = " Map a hardware frame.\n\n This has a number of different possible effects, depending on the format\n and origin of the src and dst frames.  On input, src should be a usable\n frame with valid buffers and dst should be blank (typically as just created\n by av_frame_alloc()).  src should have an associated hwframe context, and\n dst may optionally have a format and associated hwframe context.\n\n If src was created by mapping a frame from the hwframe context of dst,\n then this function undoes the mapping - dst is replaced by a reference to\n the frame that src was originally mapped from.\n\n If both src and dst have an associated hwframe context, then this function\n attempts to map the src frame from its hardware context to that of dst and\n then fill dst with appropriate data to be usable there.  This will only be\n possible if the hwframe contexts and associated devices are compatible -\n given compatible devices, av_hwframe_ctx_create_derived() can be used to\n create a hwframe context for dst in which mapping should be possible.\n\n If src has a hwframe context but dst does not, then the src frame is\n mapped to normal memory and should thereafter be usable as a normal frame.\n If the format is set on dst, then the mapping will attempt to create dst\n with that format and fail if it is not possible.  If format is unset (is\n AV_PIX_FMT_NONE) then dst will be mapped with whatever the most appropriate\n format to use is (probably the sw_format of the src hwframe context).\n\n A return value of AVERROR(ENOSYS) indicates that the mapping is not\n possible with the given arguments and hwframe setup, while other return\n values indicate that it failed somehow.\n\n On failure, the destination frame will be left blank, except for the\n hw_frames_ctx/format fields thay may have been set by the caller - those will\n be preserved as they were.\n\n @param dst Destination frame, to contain the mapping.\n @param src Source frame, to be mapped.\n @param flags Some combination of AV_HWFRAME_MAP_* flags.\n @return Zero on success, negative AVERROR code on failure."]
    pub fn av_hwframe_map(
        dst: *mut AVFrame,
        src: *const AVFrame,
        flags: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Create and initialise an AVHWFramesContext as a mapping of another existing\n AVHWFramesContext on a different device.\n\n av_hwframe_ctx_init() should not be called after this.\n\n @param derived_frame_ctx  On success, a reference to the newly created\n                           AVHWFramesContext.\n @param format             The AVPixelFormat for the derived context.\n @param derived_device_ctx A reference to the device to create the new\n                           AVHWFramesContext on.\n @param source_frame_ctx   A reference to an existing AVHWFramesContext\n                           which will be mapped to the derived context.\n @param flags  Some combination of AV_HWFRAME_MAP_* flags, defining the\n               mapping parameters to apply to frames which are allocated\n               in the derived device.\n @return       Zero on success, negative AVERROR code on failure."]
    pub fn av_hwframe_ctx_create_derived(
        derived_frame_ctx: *mut *mut AVBufferRef,
        format: AVPixelFormat,
        derived_device_ctx: *mut AVBufferRef,
        source_frame_ctx: *mut AVBufferRef,
        flags: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
pub const AVCodecID_AV_CODEC_ID_NONE: AVCodecID = 0;
pub const AVCodecID_AV_CODEC_ID_MPEG1VIDEO: AVCodecID = 1;
#[doc = "< preferred ID for MPEG-1/2 video decoding"]
pub const AVCodecID_AV_CODEC_ID_MPEG2VIDEO: AVCodecID = 2;
pub const AVCodecID_AV_CODEC_ID_H261: AVCodecID = 3;
pub const AVCodecID_AV_CODEC_ID_H263: AVCodecID = 4;
pub const AVCodecID_AV_CODEC_ID_RV10: AVCodecID = 5;
pub const AVCodecID_AV_CODEC_ID_RV20: AVCodecID = 6;
pub const AVCodecID_AV_CODEC_ID_MJPEG: AVCodecID = 7;
pub const AVCodecID_AV_CODEC_ID_MJPEGB: AVCodecID = 8;
pub const AVCodecID_AV_CODEC_ID_LJPEG: AVCodecID = 9;
pub const AVCodecID_AV_CODEC_ID_SP5X: AVCodecID = 10;
pub const AVCodecID_AV_CODEC_ID_JPEGLS: AVCodecID = 11;
pub const AVCodecID_AV_CODEC_ID_MPEG4: AVCodecID = 12;
pub const AVCodecID_AV_CODEC_ID_RAWVIDEO: AVCodecID = 13;
pub const AVCodecID_AV_CODEC_ID_MSMPEG4V1: AVCodecID = 14;
pub const AVCodecID_AV_CODEC_ID_MSMPEG4V2: AVCodecID = 15;
pub const AVCodecID_AV_CODEC_ID_MSMPEG4V3: AVCodecID = 16;
pub const AVCodecID_AV_CODEC_ID_WMV1: AVCodecID = 17;
pub const AVCodecID_AV_CODEC_ID_WMV2: AVCodecID = 18;
pub const AVCodecID_AV_CODEC_ID_H263P: AVCodecID = 19;
pub const AVCodecID_AV_CODEC_ID_H263I: AVCodecID = 20;
pub const AVCodecID_AV_CODEC_ID_FLV1: AVCodecID = 21;
pub const AVCodecID_AV_CODEC_ID_SVQ1: AVCodecID = 22;
pub const AVCodecID_AV_CODEC_ID_SVQ3: AVCodecID = 23;
pub const AVCodecID_AV_CODEC_ID_DVVIDEO: AVCodecID = 24;
pub const AVCodecID_AV_CODEC_ID_HUFFYUV: AVCodecID = 25;
pub const AVCodecID_AV_CODEC_ID_CYUV: AVCodecID = 26;
pub const AVCodecID_AV_CODEC_ID_H264: AVCodecID = 27;
pub const AVCodecID_AV_CODEC_ID_INDEO3: AVCodecID = 28;
pub const AVCodecID_AV_CODEC_ID_VP3: AVCodecID = 29;
pub const AVCodecID_AV_CODEC_ID_THEORA: AVCodecID = 30;
pub const AVCodecID_AV_CODEC_ID_ASV1: AVCodecID = 31;
pub const AVCodecID_AV_CODEC_ID_ASV2: AVCodecID = 32;
pub const AVCodecID_AV_CODEC_ID_FFV1: AVCodecID = 33;
pub const AVCodecID_AV_CODEC_ID_4XM: AVCodecID = 34;
pub const AVCodecID_AV_CODEC_ID_VCR1: AVCodecID = 35;
pub const AVCodecID_AV_CODEC_ID_CLJR: AVCodecID = 36;
pub const AVCodecID_AV_CODEC_ID_MDEC: AVCodecID = 37;
pub const AVCodecID_AV_CODEC_ID_ROQ: AVCodecID = 38;
pub const AVCodecID_AV_CODEC_ID_INTERPLAY_VIDEO: AVCodecID = 39;
pub const AVCodecID_AV_CODEC_ID_XAN_WC3: AVCodecID = 40;
pub const AVCodecID_AV_CODEC_ID_XAN_WC4: AVCodecID = 41;
pub const AVCodecID_AV_CODEC_ID_RPZA: AVCodecID = 42;
pub const AVCodecID_AV_CODEC_ID_CINEPAK: AVCodecID = 43;
pub const AVCodecID_AV_CODEC_ID_WS_VQA: AVCodecID = 44;
pub const AVCodecID_AV_CODEC_ID_MSRLE: AVCodecID = 45;
pub const AVCodecID_AV_CODEC_ID_MSVIDEO1: AVCodecID = 46;
pub const AVCodecID_AV_CODEC_ID_IDCIN: AVCodecID = 47;
pub const AVCodecID_AV_CODEC_ID_8BPS: AVCodecID = 48;
pub const AVCodecID_AV_CODEC_ID_SMC: AVCodecID = 49;
pub const AVCodecID_AV_CODEC_ID_FLIC: AVCodecID = 50;
pub const AVCodecID_AV_CODEC_ID_TRUEMOTION1: AVCodecID = 51;
pub const AVCodecID_AV_CODEC_ID_VMDVIDEO: AVCodecID = 52;
pub const AVCodecID_AV_CODEC_ID_MSZH: AVCodecID = 53;
pub const AVCodecID_AV_CODEC_ID_ZLIB: AVCodecID = 54;
pub const AVCodecID_AV_CODEC_ID_QTRLE: AVCodecID = 55;
pub const AVCodecID_AV_CODEC_ID_TSCC: AVCodecID = 56;
pub const AVCodecID_AV_CODEC_ID_ULTI: AVCodecID = 57;
pub const AVCodecID_AV_CODEC_ID_QDRAW: AVCodecID = 58;
pub const AVCodecID_AV_CODEC_ID_VIXL: AVCodecID = 59;
pub const AVCodecID_AV_CODEC_ID_QPEG: AVCodecID = 60;
pub const AVCodecID_AV_CODEC_ID_PNG: AVCodecID = 61;
pub const AVCodecID_AV_CODEC_ID_PPM: AVCodecID = 62;
pub const AVCodecID_AV_CODEC_ID_PBM: AVCodecID = 63;
pub const AVCodecID_AV_CODEC_ID_PGM: AVCodecID = 64;
pub const AVCodecID_AV_CODEC_ID_PGMYUV: AVCodecID = 65;
pub const AVCodecID_AV_CODEC_ID_PAM: AVCodecID = 66;
pub const AVCodecID_AV_CODEC_ID_FFVHUFF: AVCodecID = 67;
pub const AVCodecID_AV_CODEC_ID_RV30: AVCodecID = 68;
pub const AVCodecID_AV_CODEC_ID_RV40: AVCodecID = 69;
pub const AVCodecID_AV_CODEC_ID_VC1: AVCodecID = 70;
pub const AVCodecID_AV_CODEC_ID_WMV3: AVCodecID = 71;
pub const AVCodecID_AV_CODEC_ID_LOCO: AVCodecID = 72;
pub const AVCodecID_AV_CODEC_ID_WNV1: AVCodecID = 73;
pub const AVCodecID_AV_CODEC_ID_AASC: AVCodecID = 74;
pub const AVCodecID_AV_CODEC_ID_INDEO2: AVCodecID = 75;
pub const AVCodecID_AV_CODEC_ID_FRAPS: AVCodecID = 76;
pub const AVCodecID_AV_CODEC_ID_TRUEMOTION2: AVCodecID = 77;
pub const AVCodecID_AV_CODEC_ID_BMP: AVCodecID = 78;
pub const AVCodecID_AV_CODEC_ID_CSCD: AVCodecID = 79;
pub const AVCodecID_AV_CODEC_ID_MMVIDEO: AVCodecID = 80;
pub const AVCodecID_AV_CODEC_ID_ZMBV: AVCodecID = 81;
pub const AVCodecID_AV_CODEC_ID_AVS: AVCodecID = 82;
pub const AVCodecID_AV_CODEC_ID_SMACKVIDEO: AVCodecID = 83;
pub const AVCodecID_AV_CODEC_ID_NUV: AVCodecID = 84;
pub const AVCodecID_AV_CODEC_ID_KMVC: AVCodecID = 85;
pub const AVCodecID_AV_CODEC_ID_FLASHSV: AVCodecID = 86;
pub const AVCodecID_AV_CODEC_ID_CAVS: AVCodecID = 87;
pub const AVCodecID_AV_CODEC_ID_JPEG2000: AVCodecID = 88;
pub const AVCodecID_AV_CODEC_ID_VMNC: AVCodecID = 89;
pub const AVCodecID_AV_CODEC_ID_VP5: AVCodecID = 90;
pub const AVCodecID_AV_CODEC_ID_VP6: AVCodecID = 91;
pub const AVCodecID_AV_CODEC_ID_VP6F: AVCodecID = 92;
pub const AVCodecID_AV_CODEC_ID_TARGA: AVCodecID = 93;
pub const AVCodecID_AV_CODEC_ID_DSICINVIDEO: AVCodecID = 94;
pub const AVCodecID_AV_CODEC_ID_TIERTEXSEQVIDEO: AVCodecID = 95;
pub const AVCodecID_AV_CODEC_ID_TIFF: AVCodecID = 96;
pub const AVCodecID_AV_CODEC_ID_GIF: AVCodecID = 97;
pub const AVCodecID_AV_CODEC_ID_DXA: AVCodecID = 98;
pub const AVCodecID_AV_CODEC_ID_DNXHD: AVCodecID = 99;
pub const AVCodecID_AV_CODEC_ID_THP: AVCodecID = 100;
pub const AVCodecID_AV_CODEC_ID_SGI: AVCodecID = 101;
pub const AVCodecID_AV_CODEC_ID_C93: AVCodecID = 102;
pub const AVCodecID_AV_CODEC_ID_BETHSOFTVID: AVCodecID = 103;
pub const AVCodecID_AV_CODEC_ID_PTX: AVCodecID = 104;
pub const AVCodecID_AV_CODEC_ID_TXD: AVCodecID = 105;
pub const AVCodecID_AV_CODEC_ID_VP6A: AVCodecID = 106;
pub const AVCodecID_AV_CODEC_ID_AMV: AVCodecID = 107;
pub const AVCodecID_AV_CODEC_ID_VB: AVCodecID = 108;
pub const AVCodecID_AV_CODEC_ID_PCX: AVCodecID = 109;
pub const AVCodecID_AV_CODEC_ID_SUNRAST: AVCodecID = 110;
pub const AVCodecID_AV_CODEC_ID_INDEO4: AVCodecID = 111;
pub const AVCodecID_AV_CODEC_ID_INDEO5: AVCodecID = 112;
pub const AVCodecID_AV_CODEC_ID_MIMIC: AVCodecID = 113;
pub const AVCodecID_AV_CODEC_ID_RL2: AVCodecID = 114;
pub const AVCodecID_AV_CODEC_ID_ESCAPE124: AVCodecID = 115;
pub const AVCodecID_AV_CODEC_ID_DIRAC: AVCodecID = 116;
pub const AVCodecID_AV_CODEC_ID_BFI: AVCodecID = 117;
pub const AVCodecID_AV_CODEC_ID_CMV: AVCodecID = 118;
pub const AVCodecID_AV_CODEC_ID_MOTIONPIXELS: AVCodecID = 119;
pub const AVCodecID_AV_CODEC_ID_TGV: AVCodecID = 120;
pub const AVCodecID_AV_CODEC_ID_TGQ: AVCodecID = 121;
pub const AVCodecID_AV_CODEC_ID_TQI: AVCodecID = 122;
pub const AVCodecID_AV_CODEC_ID_AURA: AVCodecID = 123;
pub const AVCodecID_AV_CODEC_ID_AURA2: AVCodecID = 124;
pub const AVCodecID_AV_CODEC_ID_V210X: AVCodecID = 125;
pub const AVCodecID_AV_CODEC_ID_TMV: AVCodecID = 126;
pub const AVCodecID_AV_CODEC_ID_V210: AVCodecID = 127;
pub const AVCodecID_AV_CODEC_ID_DPX: AVCodecID = 128;
pub const AVCodecID_AV_CODEC_ID_MAD: AVCodecID = 129;
pub const AVCodecID_AV_CODEC_ID_FRWU: AVCodecID = 130;
pub const AVCodecID_AV_CODEC_ID_FLASHSV2: AVCodecID = 131;
pub const AVCodecID_AV_CODEC_ID_CDGRAPHICS: AVCodecID = 132;
pub const AVCodecID_AV_CODEC_ID_R210: AVCodecID = 133;
pub const AVCodecID_AV_CODEC_ID_ANM: AVCodecID = 134;
pub const AVCodecID_AV_CODEC_ID_BINKVIDEO: AVCodecID = 135;
pub const AVCodecID_AV_CODEC_ID_IFF_ILBM: AVCodecID = 136;
pub const AVCodecID_AV_CODEC_ID_KGV1: AVCodecID = 137;
pub const AVCodecID_AV_CODEC_ID_YOP: AVCodecID = 138;
pub const AVCodecID_AV_CODEC_ID_VP8: AVCodecID = 139;
pub const AVCodecID_AV_CODEC_ID_PICTOR: AVCodecID = 140;
pub const AVCodecID_AV_CODEC_ID_ANSI: AVCodecID = 141;
pub const AVCodecID_AV_CODEC_ID_A64_MULTI: AVCodecID = 142;
pub const AVCodecID_AV_CODEC_ID_A64_MULTI5: AVCodecID = 143;
pub const AVCodecID_AV_CODEC_ID_R10K: AVCodecID = 144;
pub const AVCodecID_AV_CODEC_ID_MXPEG: AVCodecID = 145;
pub const AVCodecID_AV_CODEC_ID_LAGARITH: AVCodecID = 146;
pub const AVCodecID_AV_CODEC_ID_PRORES: AVCodecID = 147;
pub const AVCodecID_AV_CODEC_ID_JV: AVCodecID = 148;
pub const AVCodecID_AV_CODEC_ID_DFA: AVCodecID = 149;
pub const AVCodecID_AV_CODEC_ID_WMV3IMAGE: AVCodecID = 150;
pub const AVCodecID_AV_CODEC_ID_VC1IMAGE: AVCodecID = 151;
pub const AVCodecID_AV_CODEC_ID_UTVIDEO: AVCodecID = 152;
pub const AVCodecID_AV_CODEC_ID_BMV_VIDEO: AVCodecID = 153;
pub const AVCodecID_AV_CODEC_ID_VBLE: AVCodecID = 154;
pub const AVCodecID_AV_CODEC_ID_DXTORY: AVCodecID = 155;
pub const AVCodecID_AV_CODEC_ID_V410: AVCodecID = 156;
pub const AVCodecID_AV_CODEC_ID_XWD: AVCodecID = 157;
pub const AVCodecID_AV_CODEC_ID_CDXL: AVCodecID = 158;
pub const AVCodecID_AV_CODEC_ID_XBM: AVCodecID = 159;
pub const AVCodecID_AV_CODEC_ID_ZEROCODEC: AVCodecID = 160;
pub const AVCodecID_AV_CODEC_ID_MSS1: AVCodecID = 161;
pub const AVCodecID_AV_CODEC_ID_MSA1: AVCodecID = 162;
pub const AVCodecID_AV_CODEC_ID_TSCC2: AVCodecID = 163;
pub const AVCodecID_AV_CODEC_ID_MTS2: AVCodecID = 164;
pub const AVCodecID_AV_CODEC_ID_CLLC: AVCodecID = 165;
pub const AVCodecID_AV_CODEC_ID_MSS2: AVCodecID = 166;
pub const AVCodecID_AV_CODEC_ID_VP9: AVCodecID = 167;
pub const AVCodecID_AV_CODEC_ID_AIC: AVCodecID = 168;
pub const AVCodecID_AV_CODEC_ID_ESCAPE130: AVCodecID = 169;
pub const AVCodecID_AV_CODEC_ID_G2M: AVCodecID = 170;
pub const AVCodecID_AV_CODEC_ID_WEBP: AVCodecID = 171;
pub const AVCodecID_AV_CODEC_ID_HNM4_VIDEO: AVCodecID = 172;
pub const AVCodecID_AV_CODEC_ID_HEVC: AVCodecID = 173;
pub const AVCodecID_AV_CODEC_ID_FIC: AVCodecID = 174;
pub const AVCodecID_AV_CODEC_ID_ALIAS_PIX: AVCodecID = 175;
pub const AVCodecID_AV_CODEC_ID_BRENDER_PIX: AVCodecID = 176;
pub const AVCodecID_AV_CODEC_ID_PAF_VIDEO: AVCodecID = 177;
pub const AVCodecID_AV_CODEC_ID_EXR: AVCodecID = 178;
pub const AVCodecID_AV_CODEC_ID_VP7: AVCodecID = 179;
pub const AVCodecID_AV_CODEC_ID_SANM: AVCodecID = 180;
pub const AVCodecID_AV_CODEC_ID_SGIRLE: AVCodecID = 181;
pub const AVCodecID_AV_CODEC_ID_MVC1: AVCodecID = 182;
pub const AVCodecID_AV_CODEC_ID_MVC2: AVCodecID = 183;
pub const AVCodecID_AV_CODEC_ID_HQX: AVCodecID = 184;
pub const AVCodecID_AV_CODEC_ID_TDSC: AVCodecID = 185;
pub const AVCodecID_AV_CODEC_ID_HQ_HQA: AVCodecID = 186;
pub const AVCodecID_AV_CODEC_ID_HAP: AVCodecID = 187;
pub const AVCodecID_AV_CODEC_ID_DDS: AVCodecID = 188;
pub const AVCodecID_AV_CODEC_ID_DXV: AVCodecID = 189;
pub const AVCodecID_AV_CODEC_ID_SCREENPRESSO: AVCodecID = 190;
pub const AVCodecID_AV_CODEC_ID_RSCC: AVCodecID = 191;
pub const AVCodecID_AV_CODEC_ID_AVS2: AVCodecID = 192;
pub const AVCodecID_AV_CODEC_ID_PGX: AVCodecID = 193;
pub const AVCodecID_AV_CODEC_ID_AVS3: AVCodecID = 194;
pub const AVCodecID_AV_CODEC_ID_MSP2: AVCodecID = 195;
pub const AVCodecID_AV_CODEC_ID_VVC: AVCodecID = 196;
pub const AVCodecID_AV_CODEC_ID_Y41P: AVCodecID = 197;
pub const AVCodecID_AV_CODEC_ID_AVRP: AVCodecID = 198;
pub const AVCodecID_AV_CODEC_ID_012V: AVCodecID = 199;
pub const AVCodecID_AV_CODEC_ID_AVUI: AVCodecID = 200;
pub const AVCodecID_AV_CODEC_ID_TARGA_Y216: AVCodecID = 201;
pub const AVCodecID_AV_CODEC_ID_V308: AVCodecID = 202;
pub const AVCodecID_AV_CODEC_ID_V408: AVCodecID = 203;
pub const AVCodecID_AV_CODEC_ID_YUV4: AVCodecID = 204;
pub const AVCodecID_AV_CODEC_ID_AVRN: AVCodecID = 205;
pub const AVCodecID_AV_CODEC_ID_CPIA: AVCodecID = 206;
pub const AVCodecID_AV_CODEC_ID_XFACE: AVCodecID = 207;
pub const AVCodecID_AV_CODEC_ID_SNOW: AVCodecID = 208;
pub const AVCodecID_AV_CODEC_ID_SMVJPEG: AVCodecID = 209;
pub const AVCodecID_AV_CODEC_ID_APNG: AVCodecID = 210;
pub const AVCodecID_AV_CODEC_ID_DAALA: AVCodecID = 211;
pub const AVCodecID_AV_CODEC_ID_CFHD: AVCodecID = 212;
pub const AVCodecID_AV_CODEC_ID_TRUEMOTION2RT: AVCodecID = 213;
pub const AVCodecID_AV_CODEC_ID_M101: AVCodecID = 214;
pub const AVCodecID_AV_CODEC_ID_MAGICYUV: AVCodecID = 215;
pub const AVCodecID_AV_CODEC_ID_SHEERVIDEO: AVCodecID = 216;
pub const AVCodecID_AV_CODEC_ID_YLC: AVCodecID = 217;
pub const AVCodecID_AV_CODEC_ID_PSD: AVCodecID = 218;
pub const AVCodecID_AV_CODEC_ID_PIXLET: AVCodecID = 219;
pub const AVCodecID_AV_CODEC_ID_SPEEDHQ: AVCodecID = 220;
pub const AVCodecID_AV_CODEC_ID_FMVC: AVCodecID = 221;
pub const AVCodecID_AV_CODEC_ID_SCPR: AVCodecID = 222;
pub const AVCodecID_AV_CODEC_ID_CLEARVIDEO: AVCodecID = 223;
pub const AVCodecID_AV_CODEC_ID_XPM: AVCodecID = 224;
pub const AVCodecID_AV_CODEC_ID_AV1: AVCodecID = 225;
pub const AVCodecID_AV_CODEC_ID_BITPACKED: AVCodecID = 226;
pub const AVCodecID_AV_CODEC_ID_MSCC: AVCodecID = 227;
pub const AVCodecID_AV_CODEC_ID_SRGC: AVCodecID = 228;
pub const AVCodecID_AV_CODEC_ID_SVG: AVCodecID = 229;
pub const AVCodecID_AV_CODEC_ID_GDV: AVCodecID = 230;
pub const AVCodecID_AV_CODEC_ID_FITS: AVCodecID = 231;
pub const AVCodecID_AV_CODEC_ID_IMM4: AVCodecID = 232;
pub const AVCodecID_AV_CODEC_ID_PROSUMER: AVCodecID = 233;
pub const AVCodecID_AV_CODEC_ID_MWSC: AVCodecID = 234;
pub const AVCodecID_AV_CODEC_ID_WCMV: AVCodecID = 235;
pub const AVCodecID_AV_CODEC_ID_RASC: AVCodecID = 236;
pub const AVCodecID_AV_CODEC_ID_HYMT: AVCodecID = 237;
pub const AVCodecID_AV_CODEC_ID_ARBC: AVCodecID = 238;
pub const AVCodecID_AV_CODEC_ID_AGM: AVCodecID = 239;
pub const AVCodecID_AV_CODEC_ID_LSCR: AVCodecID = 240;
pub const AVCodecID_AV_CODEC_ID_VP4: AVCodecID = 241;
pub const AVCodecID_AV_CODEC_ID_IMM5: AVCodecID = 242;
pub const AVCodecID_AV_CODEC_ID_MVDV: AVCodecID = 243;
pub const AVCodecID_AV_CODEC_ID_MVHA: AVCodecID = 244;
pub const AVCodecID_AV_CODEC_ID_CDTOONS: AVCodecID = 245;
pub const AVCodecID_AV_CODEC_ID_MV30: AVCodecID = 246;
pub const AVCodecID_AV_CODEC_ID_NOTCHLC: AVCodecID = 247;
pub const AVCodecID_AV_CODEC_ID_PFM: AVCodecID = 248;
pub const AVCodecID_AV_CODEC_ID_MOBICLIP: AVCodecID = 249;
pub const AVCodecID_AV_CODEC_ID_PHOTOCD: AVCodecID = 250;
pub const AVCodecID_AV_CODEC_ID_IPU: AVCodecID = 251;
pub const AVCodecID_AV_CODEC_ID_ARGO: AVCodecID = 252;
pub const AVCodecID_AV_CODEC_ID_CRI: AVCodecID = 253;
pub const AVCodecID_AV_CODEC_ID_SIMBIOSIS_IMX: AVCodecID = 254;
pub const AVCodecID_AV_CODEC_ID_SGA_VIDEO: AVCodecID = 255;
pub const AVCodecID_AV_CODEC_ID_GEM: AVCodecID = 256;
pub const AVCodecID_AV_CODEC_ID_VBN: AVCodecID = 257;
pub const AVCodecID_AV_CODEC_ID_JPEGXL: AVCodecID = 258;
pub const AVCodecID_AV_CODEC_ID_QOI: AVCodecID = 259;
pub const AVCodecID_AV_CODEC_ID_PHM: AVCodecID = 260;
pub const AVCodecID_AV_CODEC_ID_RADIANCE_HDR: AVCodecID = 261;
pub const AVCodecID_AV_CODEC_ID_WBMP: AVCodecID = 262;
pub const AVCodecID_AV_CODEC_ID_MEDIA100: AVCodecID = 263;
pub const AVCodecID_AV_CODEC_ID_VQC: AVCodecID = 264;
pub const AVCodecID_AV_CODEC_ID_PDV: AVCodecID = 265;
pub const AVCodecID_AV_CODEC_ID_EVC: AVCodecID = 266;
pub const AVCodecID_AV_CODEC_ID_RTV1: AVCodecID = 267;
pub const AVCodecID_AV_CODEC_ID_VMIX: AVCodecID = 268;
pub const AVCodecID_AV_CODEC_ID_LEAD: AVCodecID = 269;
#[doc = "< A dummy id pointing at the start of audio codecs"]
pub const AVCodecID_AV_CODEC_ID_FIRST_AUDIO: AVCodecID = 65536;
pub const AVCodecID_AV_CODEC_ID_PCM_S16LE: AVCodecID = 65536;
pub const AVCodecID_AV_CODEC_ID_PCM_S16BE: AVCodecID = 65537;
pub const AVCodecID_AV_CODEC_ID_PCM_U16LE: AVCodecID = 65538;
pub const AVCodecID_AV_CODEC_ID_PCM_U16BE: AVCodecID = 65539;
pub const AVCodecID_AV_CODEC_ID_PCM_S8: AVCodecID = 65540;
pub const AVCodecID_AV_CODEC_ID_PCM_U8: AVCodecID = 65541;
pub const AVCodecID_AV_CODEC_ID_PCM_MULAW: AVCodecID = 65542;
pub const AVCodecID_AV_CODEC_ID_PCM_ALAW: AVCodecID = 65543;
pub const AVCodecID_AV_CODEC_ID_PCM_S32LE: AVCodecID = 65544;
pub const AVCodecID_AV_CODEC_ID_PCM_S32BE: AVCodecID = 65545;
pub const AVCodecID_AV_CODEC_ID_PCM_U32LE: AVCodecID = 65546;
pub const AVCodecID_AV_CODEC_ID_PCM_U32BE: AVCodecID = 65547;
pub const AVCodecID_AV_CODEC_ID_PCM_S24LE: AVCodecID = 65548;
pub const AVCodecID_AV_CODEC_ID_PCM_S24BE: AVCodecID = 65549;
pub const AVCodecID_AV_CODEC_ID_PCM_U24LE: AVCodecID = 65550;
pub const AVCodecID_AV_CODEC_ID_PCM_U24BE: AVCodecID = 65551;
pub const AVCodecID_AV_CODEC_ID_PCM_S24DAUD: AVCodecID = 65552;
pub const AVCodecID_AV_CODEC_ID_PCM_ZORK: AVCodecID = 65553;
pub const AVCodecID_AV_CODEC_ID_PCM_S16LE_PLANAR: AVCodecID = 65554;
pub const AVCodecID_AV_CODEC_ID_PCM_DVD: AVCodecID = 65555;
pub const AVCodecID_AV_CODEC_ID_PCM_F32BE: AVCodecID = 65556;
pub const AVCodecID_AV_CODEC_ID_PCM_F32LE: AVCodecID = 65557;
pub const AVCodecID_AV_CODEC_ID_PCM_F64BE: AVCodecID = 65558;
pub const AVCodecID_AV_CODEC_ID_PCM_F64LE: AVCodecID = 65559;
pub const AVCodecID_AV_CODEC_ID_PCM_BLURAY: AVCodecID = 65560;
pub const AVCodecID_AV_CODEC_ID_PCM_LXF: AVCodecID = 65561;
pub const AVCodecID_AV_CODEC_ID_S302M: AVCodecID = 65562;
pub const AVCodecID_AV_CODEC_ID_PCM_S8_PLANAR: AVCodecID = 65563;
pub const AVCodecID_AV_CODEC_ID_PCM_S24LE_PLANAR: AVCodecID = 65564;
pub const AVCodecID_AV_CODEC_ID_PCM_S32LE_PLANAR: AVCodecID = 65565;
pub const AVCodecID_AV_CODEC_ID_PCM_S16BE_PLANAR: AVCodecID = 65566;
pub const AVCodecID_AV_CODEC_ID_PCM_S64LE: AVCodecID = 65567;
pub const AVCodecID_AV_CODEC_ID_PCM_S64BE: AVCodecID = 65568;
pub const AVCodecID_AV_CODEC_ID_PCM_F16LE: AVCodecID = 65569;
pub const AVCodecID_AV_CODEC_ID_PCM_F24LE: AVCodecID = 65570;
pub const AVCodecID_AV_CODEC_ID_PCM_VIDC: AVCodecID = 65571;
pub const AVCodecID_AV_CODEC_ID_PCM_SGA: AVCodecID = 65572;
pub const AVCodecID_AV_CODEC_ID_ADPCM_IMA_QT: AVCodecID = 69632;
pub const AVCodecID_AV_CODEC_ID_ADPCM_IMA_WAV: AVCodecID = 69633;
pub const AVCodecID_AV_CODEC_ID_ADPCM_IMA_DK3: AVCodecID = 69634;
pub const AVCodecID_AV_CODEC_ID_ADPCM_IMA_DK4: AVCodecID = 69635;
pub const AVCodecID_AV_CODEC_ID_ADPCM_IMA_WS: AVCodecID = 69636;
pub const AVCodecID_AV_CODEC_ID_ADPCM_IMA_SMJPEG: AVCodecID = 69637;
pub const AVCodecID_AV_CODEC_ID_ADPCM_MS: AVCodecID = 69638;
pub const AVCodecID_AV_CODEC_ID_ADPCM_4XM: AVCodecID = 69639;
pub const AVCodecID_AV_CODEC_ID_ADPCM_XA: AVCodecID = 69640;
pub const AVCodecID_AV_CODEC_ID_ADPCM_ADX: AVCodecID = 69641;
pub const AVCodecID_AV_CODEC_ID_ADPCM_EA: AVCodecID = 69642;
pub const AVCodecID_AV_CODEC_ID_ADPCM_G726: AVCodecID = 69643;
pub const AVCodecID_AV_CODEC_ID_ADPCM_CT: AVCodecID = 69644;
pub const AVCodecID_AV_CODEC_ID_ADPCM_SWF: AVCodecID = 69645;
pub const AVCodecID_AV_CODEC_ID_ADPCM_YAMAHA: AVCodecID = 69646;
pub const AVCodecID_AV_CODEC_ID_ADPCM_SBPRO_4: AVCodecID = 69647;
pub const AVCodecID_AV_CODEC_ID_ADPCM_SBPRO_3: AVCodecID = 69648;
pub const AVCodecID_AV_CODEC_ID_ADPCM_SBPRO_2: AVCodecID = 69649;
pub const AVCodecID_AV_CODEC_ID_ADPCM_THP: AVCodecID = 69650;
pub const AVCodecID_AV_CODEC_ID_ADPCM_IMA_AMV: AVCodecID = 69651;
pub const AVCodecID_AV_CODEC_ID_ADPCM_EA_R1: AVCodecID = 69652;
pub const AVCodecID_AV_CODEC_ID_ADPCM_EA_R3: AVCodecID = 69653;
pub const AVCodecID_AV_CODEC_ID_ADPCM_EA_R2: AVCodecID = 69654;
pub const AVCodecID_AV_CODEC_ID_ADPCM_IMA_EA_SEAD: AVCodecID = 69655;
pub const AVCodecID_AV_CODEC_ID_ADPCM_IMA_EA_EACS: AVCodecID = 69656;
pub const AVCodecID_AV_CODEC_ID_ADPCM_EA_XAS: AVCodecID = 69657;
pub const AVCodecID_AV_CODEC_ID_ADPCM_EA_MAXIS_XA: AVCodecID = 69658;
pub const AVCodecID_AV_CODEC_ID_ADPCM_IMA_ISS: AVCodecID = 69659;
pub const AVCodecID_AV_CODEC_ID_ADPCM_G722: AVCodecID = 69660;
pub const AVCodecID_AV_CODEC_ID_ADPCM_IMA_APC: AVCodecID = 69661;
pub const AVCodecID_AV_CODEC_ID_ADPCM_VIMA: AVCodecID = 69662;
pub const AVCodecID_AV_CODEC_ID_ADPCM_AFC: AVCodecID = 69663;
pub const AVCodecID_AV_CODEC_ID_ADPCM_IMA_OKI: AVCodecID = 69664;
pub const AVCodecID_AV_CODEC_ID_ADPCM_DTK: AVCodecID = 69665;
pub const AVCodecID_AV_CODEC_ID_ADPCM_IMA_RAD: AVCodecID = 69666;
pub const AVCodecID_AV_CODEC_ID_ADPCM_G726LE: AVCodecID = 69667;
pub const AVCodecID_AV_CODEC_ID_ADPCM_THP_LE: AVCodecID = 69668;
pub const AVCodecID_AV_CODEC_ID_ADPCM_PSX: AVCodecID = 69669;
pub const AVCodecID_AV_CODEC_ID_ADPCM_AICA: AVCodecID = 69670;
pub const AVCodecID_AV_CODEC_ID_ADPCM_IMA_DAT4: AVCodecID = 69671;
pub const AVCodecID_AV_CODEC_ID_ADPCM_MTAF: AVCodecID = 69672;
pub const AVCodecID_AV_CODEC_ID_ADPCM_AGM: AVCodecID = 69673;
pub const AVCodecID_AV_CODEC_ID_ADPCM_ARGO: AVCodecID = 69674;
pub const AVCodecID_AV_CODEC_ID_ADPCM_IMA_SSI: AVCodecID = 69675;
pub const AVCodecID_AV_CODEC_ID_ADPCM_ZORK: AVCodecID = 69676;
pub const AVCodecID_AV_CODEC_ID_ADPCM_IMA_APM: AVCodecID = 69677;
pub const AVCodecID_AV_CODEC_ID_ADPCM_IMA_ALP: AVCodecID = 69678;
pub const AVCodecID_AV_CODEC_ID_ADPCM_IMA_MTF: AVCodecID = 69679;
pub const AVCodecID_AV_CODEC_ID_ADPCM_IMA_CUNNING: AVCodecID = 69680;
pub const AVCodecID_AV_CODEC_ID_ADPCM_IMA_MOFLEX: AVCodecID = 69681;
pub const AVCodecID_AV_CODEC_ID_ADPCM_IMA_ACORN: AVCodecID = 69682;
pub const AVCodecID_AV_CODEC_ID_ADPCM_XMD: AVCodecID = 69683;
pub const AVCodecID_AV_CODEC_ID_AMR_NB: AVCodecID = 73728;
pub const AVCodecID_AV_CODEC_ID_AMR_WB: AVCodecID = 73729;
pub const AVCodecID_AV_CODEC_ID_RA_144: AVCodecID = 77824;
pub const AVCodecID_AV_CODEC_ID_RA_288: AVCodecID = 77825;
pub const AVCodecID_AV_CODEC_ID_ROQ_DPCM: AVCodecID = 81920;
pub const AVCodecID_AV_CODEC_ID_INTERPLAY_DPCM: AVCodecID = 81921;
pub const AVCodecID_AV_CODEC_ID_XAN_DPCM: AVCodecID = 81922;
pub const AVCodecID_AV_CODEC_ID_SOL_DPCM: AVCodecID = 81923;
pub const AVCodecID_AV_CODEC_ID_SDX2_DPCM: AVCodecID = 81924;
pub const AVCodecID_AV_CODEC_ID_GREMLIN_DPCM: AVCodecID = 81925;
pub const AVCodecID_AV_CODEC_ID_DERF_DPCM: AVCodecID = 81926;
pub const AVCodecID_AV_CODEC_ID_WADY_DPCM: AVCodecID = 81927;
pub const AVCodecID_AV_CODEC_ID_CBD2_DPCM: AVCodecID = 81928;
pub const AVCodecID_AV_CODEC_ID_MP2: AVCodecID = 86016;
#[doc = "< preferred ID for decoding MPEG audio layer 1, 2 or 3"]
pub const AVCodecID_AV_CODEC_ID_MP3: AVCodecID = 86017;
pub const AVCodecID_AV_CODEC_ID_AAC: AVCodecID = 86018;
pub const AVCodecID_AV_CODEC_ID_AC3: AVCodecID = 86019;
pub const AVCodecID_AV_CODEC_ID_DTS: AVCodecID = 86020;
pub const AVCodecID_AV_CODEC_ID_VORBIS: AVCodecID = 86021;
pub const AVCodecID_AV_CODEC_ID_DVAUDIO: AVCodecID = 86022;
pub const AVCodecID_AV_CODEC_ID_WMAV1: AVCodecID = 86023;
pub const AVCodecID_AV_CODEC_ID_WMAV2: AVCodecID = 86024;
pub const AVCodecID_AV_CODEC_ID_MACE3: AVCodecID = 86025;
pub const AVCodecID_AV_CODEC_ID_MACE6: AVCodecID = 86026;
pub const AVCodecID_AV_CODEC_ID_VMDAUDIO: AVCodecID = 86027;
pub const AVCodecID_AV_CODEC_ID_FLAC: AVCodecID = 86028;
pub const AVCodecID_AV_CODEC_ID_MP3ADU: AVCodecID = 86029;
pub const AVCodecID_AV_CODEC_ID_MP3ON4: AVCodecID = 86030;
pub const AVCodecID_AV_CODEC_ID_SHORTEN: AVCodecID = 86031;
pub const AVCodecID_AV_CODEC_ID_ALAC: AVCodecID = 86032;
pub const AVCodecID_AV_CODEC_ID_WESTWOOD_SND1: AVCodecID = 86033;
#[doc = "< as in Berlin toast format"]
pub const AVCodecID_AV_CODEC_ID_GSM: AVCodecID = 86034;
pub const AVCodecID_AV_CODEC_ID_QDM2: AVCodecID = 86035;
pub const AVCodecID_AV_CODEC_ID_COOK: AVCodecID = 86036;
pub const AVCodecID_AV_CODEC_ID_TRUESPEECH: AVCodecID = 86037;
pub const AVCodecID_AV_CODEC_ID_TTA: AVCodecID = 86038;
pub const AVCodecID_AV_CODEC_ID_SMACKAUDIO: AVCodecID = 86039;
pub const AVCodecID_AV_CODEC_ID_QCELP: AVCodecID = 86040;
pub const AVCodecID_AV_CODEC_ID_WAVPACK: AVCodecID = 86041;
pub const AVCodecID_AV_CODEC_ID_DSICINAUDIO: AVCodecID = 86042;
pub const AVCodecID_AV_CODEC_ID_IMC: AVCodecID = 86043;
pub const AVCodecID_AV_CODEC_ID_MUSEPACK7: AVCodecID = 86044;
pub const AVCodecID_AV_CODEC_ID_MLP: AVCodecID = 86045;
pub const AVCodecID_AV_CODEC_ID_GSM_MS: AVCodecID = 86046;
pub const AVCodecID_AV_CODEC_ID_ATRAC3: AVCodecID = 86047;
pub const AVCodecID_AV_CODEC_ID_APE: AVCodecID = 86048;
pub const AVCodecID_AV_CODEC_ID_NELLYMOSER: AVCodecID = 86049;
pub const AVCodecID_AV_CODEC_ID_MUSEPACK8: AVCodecID = 86050;
pub const AVCodecID_AV_CODEC_ID_SPEEX: AVCodecID = 86051;
pub const AVCodecID_AV_CODEC_ID_WMAVOICE: AVCodecID = 86052;
pub const AVCodecID_AV_CODEC_ID_WMAPRO: AVCodecID = 86053;
pub const AVCodecID_AV_CODEC_ID_WMALOSSLESS: AVCodecID = 86054;
pub const AVCodecID_AV_CODEC_ID_ATRAC3P: AVCodecID = 86055;
pub const AVCodecID_AV_CODEC_ID_EAC3: AVCodecID = 86056;
pub const AVCodecID_AV_CODEC_ID_SIPR: AVCodecID = 86057;
pub const AVCodecID_AV_CODEC_ID_MP1: AVCodecID = 86058;
pub const AVCodecID_AV_CODEC_ID_TWINVQ: AVCodecID = 86059;
pub const AVCodecID_AV_CODEC_ID_TRUEHD: AVCodecID = 86060;
pub const AVCodecID_AV_CODEC_ID_MP4ALS: AVCodecID = 86061;
pub const AVCodecID_AV_CODEC_ID_ATRAC1: AVCodecID = 86062;
pub const AVCodecID_AV_CODEC_ID_BINKAUDIO_RDFT: AVCodecID = 86063;
pub const AVCodecID_AV_CODEC_ID_BINKAUDIO_DCT: AVCodecID = 86064;
pub const AVCodecID_AV_CODEC_ID_AAC_LATM: AVCodecID = 86065;
pub const AVCodecID_AV_CODEC_ID_QDMC: AVCodecID = 86066;
pub const AVCodecID_AV_CODEC_ID_CELT: AVCodecID = 86067;
pub const AVCodecID_AV_CODEC_ID_G723_1: AVCodecID = 86068;
pub const AVCodecID_AV_CODEC_ID_G729: AVCodecID = 86069;
pub const AVCodecID_AV_CODEC_ID_8SVX_EXP: AVCodecID = 86070;
pub const AVCodecID_AV_CODEC_ID_8SVX_FIB: AVCodecID = 86071;
pub const AVCodecID_AV_CODEC_ID_BMV_AUDIO: AVCodecID = 86072;
pub const AVCodecID_AV_CODEC_ID_RALF: AVCodecID = 86073;
pub const AVCodecID_AV_CODEC_ID_IAC: AVCodecID = 86074;
pub const AVCodecID_AV_CODEC_ID_ILBC: AVCodecID = 86075;
pub const AVCodecID_AV_CODEC_ID_OPUS: AVCodecID = 86076;
pub const AVCodecID_AV_CODEC_ID_COMFORT_NOISE: AVCodecID = 86077;
pub const AVCodecID_AV_CODEC_ID_TAK: AVCodecID = 86078;
pub const AVCodecID_AV_CODEC_ID_METASOUND: AVCodecID = 86079;
pub const AVCodecID_AV_CODEC_ID_PAF_AUDIO: AVCodecID = 86080;
pub const AVCodecID_AV_CODEC_ID_ON2AVC: AVCodecID = 86081;
pub const AVCodecID_AV_CODEC_ID_DSS_SP: AVCodecID = 86082;
pub const AVCodecID_AV_CODEC_ID_CODEC2: AVCodecID = 86083;
pub const AVCodecID_AV_CODEC_ID_FFWAVESYNTH: AVCodecID = 86084;
pub const AVCodecID_AV_CODEC_ID_SONIC: AVCodecID = 86085;
pub const AVCodecID_AV_CODEC_ID_SONIC_LS: AVCodecID = 86086;
pub const AVCodecID_AV_CODEC_ID_EVRC: AVCodecID = 86087;
pub const AVCodecID_AV_CODEC_ID_SMV: AVCodecID = 86088;
pub const AVCodecID_AV_CODEC_ID_DSD_LSBF: AVCodecID = 86089;
pub const AVCodecID_AV_CODEC_ID_DSD_MSBF: AVCodecID = 86090;
pub const AVCodecID_AV_CODEC_ID_DSD_LSBF_PLANAR: AVCodecID = 86091;
pub const AVCodecID_AV_CODEC_ID_DSD_MSBF_PLANAR: AVCodecID = 86092;
pub const AVCodecID_AV_CODEC_ID_4GV: AVCodecID = 86093;
pub const AVCodecID_AV_CODEC_ID_INTERPLAY_ACM: AVCodecID = 86094;
pub const AVCodecID_AV_CODEC_ID_XMA1: AVCodecID = 86095;
pub const AVCodecID_AV_CODEC_ID_XMA2: AVCodecID = 86096;
pub const AVCodecID_AV_CODEC_ID_DST: AVCodecID = 86097;
pub const AVCodecID_AV_CODEC_ID_ATRAC3AL: AVCodecID = 86098;
pub const AVCodecID_AV_CODEC_ID_ATRAC3PAL: AVCodecID = 86099;
pub const AVCodecID_AV_CODEC_ID_DOLBY_E: AVCodecID = 86100;
pub const AVCodecID_AV_CODEC_ID_APTX: AVCodecID = 86101;
pub const AVCodecID_AV_CODEC_ID_APTX_HD: AVCodecID = 86102;
pub const AVCodecID_AV_CODEC_ID_SBC: AVCodecID = 86103;
pub const AVCodecID_AV_CODEC_ID_ATRAC9: AVCodecID = 86104;
pub const AVCodecID_AV_CODEC_ID_HCOM: AVCodecID = 86105;
pub const AVCodecID_AV_CODEC_ID_ACELP_KELVIN: AVCodecID = 86106;
pub const AVCodecID_AV_CODEC_ID_MPEGH_3D_AUDIO: AVCodecID = 86107;
pub const AVCodecID_AV_CODEC_ID_SIREN: AVCodecID = 86108;
pub const AVCodecID_AV_CODEC_ID_HCA: AVCodecID = 86109;
pub const AVCodecID_AV_CODEC_ID_FASTAUDIO: AVCodecID = 86110;
pub const AVCodecID_AV_CODEC_ID_MSNSIREN: AVCodecID = 86111;
pub const AVCodecID_AV_CODEC_ID_DFPWM: AVCodecID = 86112;
pub const AVCodecID_AV_CODEC_ID_BONK: AVCodecID = 86113;
pub const AVCodecID_AV_CODEC_ID_MISC4: AVCodecID = 86114;
pub const AVCodecID_AV_CODEC_ID_APAC: AVCodecID = 86115;
pub const AVCodecID_AV_CODEC_ID_FTR: AVCodecID = 86116;
pub const AVCodecID_AV_CODEC_ID_WAVARC: AVCodecID = 86117;
pub const AVCodecID_AV_CODEC_ID_RKA: AVCodecID = 86118;
pub const AVCodecID_AV_CODEC_ID_AC4: AVCodecID = 86119;
pub const AVCodecID_AV_CODEC_ID_OSQ: AVCodecID = 86120;
pub const AVCodecID_AV_CODEC_ID_QOA: AVCodecID = 86121;
pub const AVCodecID_AV_CODEC_ID_LC3: AVCodecID = 86122;
#[doc = "< A dummy ID pointing at the start of subtitle codecs."]
pub const AVCodecID_AV_CODEC_ID_FIRST_SUBTITLE: AVCodecID = 94208;
pub const AVCodecID_AV_CODEC_ID_DVD_SUBTITLE: AVCodecID = 94208;
pub const AVCodecID_AV_CODEC_ID_DVB_SUBTITLE: AVCodecID = 94209;
#[doc = "< raw UTF-8 text"]
pub const AVCodecID_AV_CODEC_ID_TEXT: AVCodecID = 94210;
pub const AVCodecID_AV_CODEC_ID_XSUB: AVCodecID = 94211;
pub const AVCodecID_AV_CODEC_ID_SSA: AVCodecID = 94212;
pub const AVCodecID_AV_CODEC_ID_MOV_TEXT: AVCodecID = 94213;
pub const AVCodecID_AV_CODEC_ID_HDMV_PGS_SUBTITLE: AVCodecID = 94214;
pub const AVCodecID_AV_CODEC_ID_DVB_TELETEXT: AVCodecID = 94215;
pub const AVCodecID_AV_CODEC_ID_SRT: AVCodecID = 94216;
pub const AVCodecID_AV_CODEC_ID_MICRODVD: AVCodecID = 94217;
pub const AVCodecID_AV_CODEC_ID_EIA_608: AVCodecID = 94218;
pub const AVCodecID_AV_CODEC_ID_JACOSUB: AVCodecID = 94219;
pub const AVCodecID_AV_CODEC_ID_SAMI: AVCodecID = 94220;
pub const AVCodecID_AV_CODEC_ID_REALTEXT: AVCodecID = 94221;
pub const AVCodecID_AV_CODEC_ID_STL: AVCodecID = 94222;
pub const AVCodecID_AV_CODEC_ID_SUBVIEWER1: AVCodecID = 94223;
pub const AVCodecID_AV_CODEC_ID_SUBVIEWER: AVCodecID = 94224;
pub const AVCodecID_AV_CODEC_ID_SUBRIP: AVCodecID = 94225;
pub const AVCodecID_AV_CODEC_ID_WEBVTT: AVCodecID = 94226;
pub const AVCodecID_AV_CODEC_ID_MPL2: AVCodecID = 94227;
pub const AVCodecID_AV_CODEC_ID_VPLAYER: AVCodecID = 94228;
pub const AVCodecID_AV_CODEC_ID_PJS: AVCodecID = 94229;
pub const AVCodecID_AV_CODEC_ID_ASS: AVCodecID = 94230;
pub const AVCodecID_AV_CODEC_ID_HDMV_TEXT_SUBTITLE: AVCodecID = 94231;
pub const AVCodecID_AV_CODEC_ID_TTML: AVCodecID = 94232;
pub const AVCodecID_AV_CODEC_ID_ARIB_CAPTION: AVCodecID = 94233;
#[doc = "< A dummy ID pointing at the start of various fake codecs."]
pub const AVCodecID_AV_CODEC_ID_FIRST_UNKNOWN: AVCodecID = 98304;
pub const AVCodecID_AV_CODEC_ID_TTF: AVCodecID = 98304;
#[doc = "< Contain timestamp estimated through PCR of program stream."]
pub const AVCodecID_AV_CODEC_ID_SCTE_35: AVCodecID = 98305;
pub const AVCodecID_AV_CODEC_ID_EPG: AVCodecID = 98306;
pub const AVCodecID_AV_CODEC_ID_BINTEXT: AVCodecID = 98307;
pub const AVCodecID_AV_CODEC_ID_XBIN: AVCodecID = 98308;
pub const AVCodecID_AV_CODEC_ID_IDF: AVCodecID = 98309;
pub const AVCodecID_AV_CODEC_ID_OTF: AVCodecID = 98310;
pub const AVCodecID_AV_CODEC_ID_SMPTE_KLV: AVCodecID = 98311;
pub const AVCodecID_AV_CODEC_ID_DVD_NAV: AVCodecID = 98312;
pub const AVCodecID_AV_CODEC_ID_TIMED_ID3: AVCodecID = 98313;
pub const AVCodecID_AV_CODEC_ID_BIN_DATA: AVCodecID = 98314;
pub const AVCodecID_AV_CODEC_ID_SMPTE_2038: AVCodecID = 98315;
#[doc = "< codec_id is not known (like AV_CODEC_ID_NONE) but lavf should attempt to identify it"]
pub const AVCodecID_AV_CODEC_ID_PROBE: AVCodecID = 102400;
#[doc = "< _FAKE_ codec to indicate a raw MPEG-2 TS\n stream (only used by libavformat)"]
pub const AVCodecID_AV_CODEC_ID_MPEG2TS: AVCodecID = 131072;
#[doc = "< _FAKE_ codec to indicate a MPEG-4 Systems\n stream (only used by libavformat)"]
pub const AVCodecID_AV_CODEC_ID_MPEG4SYSTEMS: AVCodecID = 131073;
#[doc = "< Dummy codec for streams containing only metadata information."]
pub const AVCodecID_AV_CODEC_ID_FFMETADATA: AVCodecID = 135168;
#[doc = "< Passthrough codec, AVFrames wrapped in AVPacket"]
pub const AVCodecID_AV_CODEC_ID_WRAPPED_AVFRAME: AVCodecID = 135169;
#[doc = " Dummy null video codec, useful mainly for development and debugging.\n Null encoder/decoder discard all input and never return any output."]
pub const AVCodecID_AV_CODEC_ID_VNULL: AVCodecID = 135170;
#[doc = " Dummy null audio codec, useful mainly for development and debugging.\n Null encoder/decoder discard all input and never return any output."]
pub const AVCodecID_AV_CODEC_ID_ANULL: AVCodecID = 135171;
#[doc = " Identify the syntax and semantics of the bitstream.\n The principle is roughly:\n Two decoders with the same ID can decode the same streams.\n Two encoders with the same ID can encode compatible streams.\n There may be slight deviations from the principle due to implementation\n details.\n\n If you add a codec ID to this list, add it so that\n 1. no value of an existing codec ID changes (that would break ABI),\n 2. it is as close as possible to similar codecs\n\n After adding new codec IDs, do not forget to add an entry to the codec\n descriptor list and bump libavcodec minor version."]
pub type AVCodecID = ::std::os::raw::c_uint;
extern "C" {
    #[doc = " Get the type of the given codec."]
    pub fn avcodec_get_type(codec_id: AVCodecID) -> AVMediaType;
}
extern "C" {
    #[doc = " Get the name of a codec.\n @return  a static string identifying the codec; never NULL"]
    pub fn avcodec_get_name(id: AVCodecID) -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Return codec bits per sample.\n\n @param[in] codec_id the codec\n @return Number of bits per sample or zero if unknown for the given codec."]
    pub fn av_get_bits_per_sample(codec_id: AVCodecID) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Return codec bits per sample.\n Only return non-zero if the bits per sample is exactly correct, not an\n approximation.\n\n @param[in] codec_id the codec\n @return Number of bits per sample or zero if unknown for the given codec."]
    pub fn av_get_exact_bits_per_sample(codec_id: AVCodecID) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Return a name for the specified profile, if available.\n\n @param codec_id the ID of the codec to which the requested profile belongs\n @param profile the profile value for which a name is requested\n @return A name for the profile if found, NULL otherwise.\n\n @note unlike av_get_profile_name(), which searches a list of profiles\n       supported by a specific decoder or encoder implementation, this\n       function searches the list of profiles from the AVCodecDescriptor"]
    pub fn avcodec_profile_name(
        codec_id: AVCodecID,
        profile: ::std::os::raw::c_int,
    ) -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Return the PCM codec associated with a sample format.\n @param be  endianness, 0 for little, 1 for big,\n            -1 (or anything else) for native\n @return  AV_CODEC_ID_PCM_* or AV_CODEC_ID_NONE"]
    pub fn av_get_pcm_codec(fmt: AVSampleFormat, be: ::std::os::raw::c_int) -> AVCodecID;
}
#[doc = " AVProfile."]
#[repr(C)]
#[derive(Debug, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVProfile {
    pub profile: ::std::os::raw::c_int,
    #[doc = "< short name for the profile"]
    pub name: *const ::std::os::raw::c_char,
}
impl Default for AVProfile {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = " AVCodec."]
#[repr(C)]
#[derive(Debug, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVCodec {
    #[doc = " Name of the codec implementation.\n The name is globally unique among encoders and among decoders (but an\n encoder and a decoder can share the same name).\n This is the primary way to find a codec from the user perspective."]
    pub name: *const ::std::os::raw::c_char,
    #[doc = " Descriptive name for the codec, meant to be more human readable than name.\n You should use the NULL_IF_CONFIG_SMALL() macro to define it."]
    pub long_name: *const ::std::os::raw::c_char,
    pub type_: AVMediaType,
    pub id: AVCodecID,
    #[doc = " Codec capabilities.\n see AV_CODEC_CAP_*"]
    pub capabilities: ::std::os::raw::c_int,
    #[doc = "< maximum value for lowres supported by the decoder"]
    pub max_lowres: u8,
    #[doc = "< array of supported framerates, or NULL if any, array is terminated by {0,0}"]
    pub supported_framerates: *const AVRational,
    #[doc = "< array of supported pixel formats, or NULL if unknown, array is terminated by -1"]
    pub pix_fmts: *const AVPixelFormat,
    #[doc = "< array of supported audio samplerates, or NULL if unknown, array is terminated by 0"]
    pub supported_samplerates: *const ::std::os::raw::c_int,
    #[doc = "< array of supported sample formats, or NULL if unknown, array is terminated by -1"]
    pub sample_fmts: *const AVSampleFormat,
    #[doc = "< AVClass for the private context"]
    pub priv_class: *const AVClass,
    #[doc = "< array of recognized profiles, or NULL if unknown, array is terminated by {AV_PROFILE_UNKNOWN}"]
    pub profiles: *const AVProfile,
    #[doc = " Group name of the codec implementation.\n This is a short symbolic name of the wrapper backing this codec. A\n wrapper uses some kind of external implementation for the codec, such\n as an external library, or a codec implementation provided by the OS or\n the hardware.\n If this field is NULL, this is a builtin, libavcodec native codec.\n If non-NULL, this will be the suffix in AVCodec.name in most cases\n (usually AVCodec.name will be of the form \"<codec_name>_<wrapper_name>\")."]
    pub wrapper_name: *const ::std::os::raw::c_char,
    #[doc = " Array of supported channel layouts, terminated with a zeroed layout."]
    pub ch_layouts: *const AVChannelLayout,
}
impl Default for AVCodec {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
extern "C" {
    #[doc = " Iterate over all registered codecs.\n\n @param opaque a pointer where libavcodec will store the iteration state. Must\n               point to NULL to start the iteration.\n\n @return the next registered codec or NULL when the iteration is\n         finished"]
    pub fn av_codec_iterate(opaque: *mut *mut ::std::os::raw::c_void) -> *const AVCodec;
}
extern "C" {
    #[doc = " Find a registered decoder with a matching codec ID.\n\n @param id AVCodecID of the requested decoder\n @return A decoder if one was found, NULL otherwise."]
    pub fn avcodec_find_decoder(id: AVCodecID) -> *const AVCodec;
}
extern "C" {
    #[doc = " Find a registered decoder with the specified name.\n\n @param name name of the requested decoder\n @return A decoder if one was found, NULL otherwise."]
    pub fn avcodec_find_decoder_by_name(name: *const ::std::os::raw::c_char) -> *const AVCodec;
}
extern "C" {
    #[doc = " Find a registered encoder with a matching codec ID.\n\n @param id AVCodecID of the requested encoder\n @return An encoder if one was found, NULL otherwise."]
    pub fn avcodec_find_encoder(id: AVCodecID) -> *const AVCodec;
}
extern "C" {
    #[doc = " Find a registered encoder with the specified name.\n\n @param name name of the requested encoder\n @return An encoder if one was found, NULL otherwise."]
    pub fn avcodec_find_encoder_by_name(name: *const ::std::os::raw::c_char) -> *const AVCodec;
}
extern "C" {
    #[doc = " @return a non-zero number if codec is an encoder, zero otherwise"]
    pub fn av_codec_is_encoder(codec: *const AVCodec) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " @return a non-zero number if codec is a decoder, zero otherwise"]
    pub fn av_codec_is_decoder(codec: *const AVCodec) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Return a name for the specified profile, if available.\n\n @param codec the codec that is searched for the given profile\n @param profile the profile value for which a name is requested\n @return A name for the profile if found, NULL otherwise."]
    pub fn av_get_profile_name(
        codec: *const AVCodec,
        profile: ::std::os::raw::c_int,
    ) -> *const ::std::os::raw::c_char;
}
#[doc = " The codec supports this format via the hw_device_ctx interface.\n\n When selecting this format, AVCodecContext.hw_device_ctx should\n have been set to a device of the specified type before calling\n avcodec_open2()."]
pub const AV_CODEC_HW_CONFIG_METHOD_HW_DEVICE_CTX: _bindgen_ty_3 = 1;
#[doc = " The codec supports this format via the hw_frames_ctx interface.\n\n When selecting this format for a decoder,\n AVCodecContext.hw_frames_ctx should be set to a suitable frames\n context inside the get_format() callback.  The frames context\n must have been created on a device of the specified type.\n\n When selecting this format for an encoder,\n AVCodecContext.hw_frames_ctx should be set to the context which\n will be used for the input frames before calling avcodec_open2()."]
pub const AV_CODEC_HW_CONFIG_METHOD_HW_FRAMES_CTX: _bindgen_ty_3 = 2;
#[doc = " The codec supports this format by some internal method.\n\n This format can be selected without any additional configuration -\n no device or frames context is required."]
pub const AV_CODEC_HW_CONFIG_METHOD_INTERNAL: _bindgen_ty_3 = 4;
#[doc = " The codec supports this format by some ad-hoc method.\n\n Additional settings and/or function calls are required.  See the\n codec-specific documentation for details.  (Methods requiring\n this sort of configuration are deprecated and others should be\n used in preference.)"]
pub const AV_CODEC_HW_CONFIG_METHOD_AD_HOC: _bindgen_ty_3 = 8;
pub type _bindgen_ty_3 = ::std::os::raw::c_uint;
#[repr(C)]
#[derive(Debug, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVCodecHWConfig {
    #[doc = " For decoders, a hardware pixel format which that decoder may be\n able to decode to if suitable hardware is available.\n\n For encoders, a pixel format which the encoder may be able to\n accept.  If set to AV_PIX_FMT_NONE, this applies to all pixel\n formats supported by the codec."]
    pub pix_fmt: AVPixelFormat,
    #[doc = " Bit set of AV_CODEC_HW_CONFIG_METHOD_* flags, describing the possible\n setup methods which can be used with this configuration."]
    pub methods: ::std::os::raw::c_int,
    #[doc = " The device type associated with the configuration.\n\n Must be set for AV_CODEC_HW_CONFIG_METHOD_HW_DEVICE_CTX and\n AV_CODEC_HW_CONFIG_METHOD_HW_FRAMES_CTX, otherwise unused."]
    pub device_type: AVHWDeviceType,
}
impl Default for AVCodecHWConfig {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
extern "C" {
    #[doc = " Retrieve supported hardware configurations for a codec.\n\n Values of index from zero to some maximum return the indexed configuration\n descriptor; all other values return NULL.  If the codec does not support\n any hardware configurations then it will always return NULL."]
    pub fn avcodec_get_hw_config(
        codec: *const AVCodec,
        index: ::std::os::raw::c_int,
    ) -> *const AVCodecHWConfig;
}
pub const AVFieldOrder_AV_FIELD_UNKNOWN: AVFieldOrder = 0;
pub const AVFieldOrder_AV_FIELD_PROGRESSIVE: AVFieldOrder = 1;
#[doc = "< Top coded_first, top displayed first"]
pub const AVFieldOrder_AV_FIELD_TT: AVFieldOrder = 2;
#[doc = "< Bottom coded first, bottom displayed first"]
pub const AVFieldOrder_AV_FIELD_BB: AVFieldOrder = 3;
#[doc = "< Top coded first, bottom displayed first"]
pub const AVFieldOrder_AV_FIELD_TB: AVFieldOrder = 4;
#[doc = "< Bottom coded first, top displayed first"]
pub const AVFieldOrder_AV_FIELD_BT: AVFieldOrder = 5;
pub type AVFieldOrder = ::std::os::raw::c_uint;
#[doc = "< discard nothing"]
pub const AVDiscard_AVDISCARD_NONE: AVDiscard = -16;
#[doc = "< discard useless packets like 0 size packets in avi"]
pub const AVDiscard_AVDISCARD_DEFAULT: AVDiscard = 0;
#[doc = "< discard all non reference"]
pub const AVDiscard_AVDISCARD_NONREF: AVDiscard = 8;
#[doc = "< discard all bidirectional frames"]
pub const AVDiscard_AVDISCARD_BIDIR: AVDiscard = 16;
#[doc = "< discard all non intra frames"]
pub const AVDiscard_AVDISCARD_NONINTRA: AVDiscard = 24;
#[doc = "< discard all frames except keyframes"]
pub const AVDiscard_AVDISCARD_NONKEY: AVDiscard = 32;
#[doc = "< discard all"]
pub const AVDiscard_AVDISCARD_ALL: AVDiscard = 48;
#[doc = " @ingroup lavc_decoding"]
pub type AVDiscard = ::std::os::raw::c_int;
pub const AVAudioServiceType_AV_AUDIO_SERVICE_TYPE_MAIN: AVAudioServiceType = 0;
pub const AVAudioServiceType_AV_AUDIO_SERVICE_TYPE_EFFECTS: AVAudioServiceType = 1;
pub const AVAudioServiceType_AV_AUDIO_SERVICE_TYPE_VISUALLY_IMPAIRED: AVAudioServiceType = 2;
pub const AVAudioServiceType_AV_AUDIO_SERVICE_TYPE_HEARING_IMPAIRED: AVAudioServiceType = 3;
pub const AVAudioServiceType_AV_AUDIO_SERVICE_TYPE_DIALOGUE: AVAudioServiceType = 4;
pub const AVAudioServiceType_AV_AUDIO_SERVICE_TYPE_COMMENTARY: AVAudioServiceType = 5;
pub const AVAudioServiceType_AV_AUDIO_SERVICE_TYPE_EMERGENCY: AVAudioServiceType = 6;
pub const AVAudioServiceType_AV_AUDIO_SERVICE_TYPE_VOICE_OVER: AVAudioServiceType = 7;
pub const AVAudioServiceType_AV_AUDIO_SERVICE_TYPE_KARAOKE: AVAudioServiceType = 8;
#[doc = "< Not part of ABI"]
pub const AVAudioServiceType_AV_AUDIO_SERVICE_TYPE_NB: AVAudioServiceType = 9;
pub type AVAudioServiceType = ::std::os::raw::c_uint;
#[doc = " Pan Scan area.\n This specifies the area which should be displayed.\n Note there may be multiple such areas for one frame."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVPanScan {
    #[doc = " id\n - encoding: Set by user.\n - decoding: Set by libavcodec."]
    pub id: ::std::os::raw::c_int,
    #[doc = " width and height in 1/16 pel\n - encoding: Set by user.\n - decoding: Set by libavcodec."]
    pub width: ::std::os::raw::c_int,
    pub height: ::std::os::raw::c_int,
    #[doc = " position of the top left corner in 1/16 pel for up to 3 fields/frames\n - encoding: Set by user.\n - decoding: Set by libavcodec."]
    pub position: [[i16; 2usize]; 3usize],
}
#[doc = " This structure describes the bitrate properties of an encoded bitstream. It\n roughly corresponds to a subset the VBV parameters for MPEG-2 or HRD\n parameters for H.264/HEVC."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVCPBProperties {
    #[doc = " Maximum bitrate of the stream, in bits per second.\n Zero if unknown or unspecified."]
    pub max_bitrate: i64,
    #[doc = " Minimum bitrate of the stream, in bits per second.\n Zero if unknown or unspecified."]
    pub min_bitrate: i64,
    #[doc = " Average bitrate of the stream, in bits per second.\n Zero if unknown or unspecified."]
    pub avg_bitrate: i64,
    #[doc = " The size of the buffer to which the ratecontrol is applied, in bits.\n Zero if unknown or unspecified."]
    pub buffer_size: i64,
    #[doc = " The delay between the time the packet this structure is associated with\n is received and the time when it should be decoded, in periods of a 27MHz\n clock.\n\n UINT64_MAX when unknown or unspecified."]
    pub vbv_delay: u64,
}
extern "C" {
    #[doc = " Allocate a CPB properties structure and initialize its fields to default\n values.\n\n @param size if non-NULL, the size of the allocated struct will be written\n             here. This is useful for embedding it in side data.\n\n @return the newly allocated struct or NULL on failure"]
    pub fn av_cpb_properties_alloc(size: *mut usize) -> *mut AVCPBProperties;
}
#[doc = " This structure supplies correlation between a packet timestamp and a wall clock\n production time. The definition follows the Producer Reference Time ('prft')\n as defined in ISO/IEC 14496-12"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVProducerReferenceTime {
    #[doc = " A UTC timestamp, in microseconds, since Unix epoch (e.g, av_gettime())."]
    pub wallclock: i64,
    pub flags: ::std::os::raw::c_int,
}
extern "C" {
    #[doc = " Encode extradata length to a buffer. Used by xiph codecs.\n\n @param s buffer to write to; must be at least (v/255+1) bytes long\n @param v size of extradata in bytes\n @return number of bytes written to the buffer."]
    pub fn av_xiphlacing(
        s: *mut ::std::os::raw::c_uchar,
        v: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
#[doc = " An AV_PKT_DATA_PALETTE side data packet contains exactly AVPALETTE_SIZE\n bytes worth of palette. This side data signals that a new palette is\n present."]
pub const AVPacketSideDataType_AV_PKT_DATA_PALETTE: AVPacketSideDataType = 0;
#[doc = " The AV_PKT_DATA_NEW_EXTRADATA is used to notify the codec or the format\n that the extradata buffer was changed and the receiving side should\n act upon it appropriately. The new extradata is embedded in the side\n data buffer and should be immediately used for processing the current\n frame or packet."]
pub const AVPacketSideDataType_AV_PKT_DATA_NEW_EXTRADATA: AVPacketSideDataType = 1;
#[doc = " An AV_PKT_DATA_PARAM_CHANGE side data packet is laid out as follows:\n @code\n u32le param_flags\n if (param_flags & AV_SIDE_DATA_PARAM_CHANGE_CHANNEL_COUNT)\n     s32le channel_count\n if (param_flags & AV_SIDE_DATA_PARAM_CHANGE_CHANNEL_LAYOUT)\n     u64le channel_layout\n if (param_flags & AV_SIDE_DATA_PARAM_CHANGE_SAMPLE_RATE)\n     s32le sample_rate\n if (param_flags & AV_SIDE_DATA_PARAM_CHANGE_DIMENSIONS)\n     s32le width\n     s32le height\n @endcode"]
pub const AVPacketSideDataType_AV_PKT_DATA_PARAM_CHANGE: AVPacketSideDataType = 2;
#[doc = " An AV_PKT_DATA_H263_MB_INFO side data packet contains a number of\n structures with info about macroblocks relevant to splitting the\n packet into smaller packets on macroblock edges (e.g. as for RFC 2190).\n That is, it does not necessarily contain info about all macroblocks,\n as long as the distance between macroblocks in the info is smaller\n than the target payload size.\n Each MB info structure is 12 bytes, and is laid out as follows:\n @code\n u32le bit offset from the start of the packet\n u8    current quantizer at the start of the macroblock\n u8    GOB number\n u16le macroblock address within the GOB\n u8    horizontal MV predictor\n u8    vertical MV predictor\n u8    horizontal MV predictor for block number 3\n u8    vertical MV predictor for block number 3\n @endcode"]
pub const AVPacketSideDataType_AV_PKT_DATA_H263_MB_INFO: AVPacketSideDataType = 3;
#[doc = " This side data should be associated with an audio stream and contains\n ReplayGain information in form of the AVReplayGain struct."]
pub const AVPacketSideDataType_AV_PKT_DATA_REPLAYGAIN: AVPacketSideDataType = 4;
#[doc = " This side data contains a 3x3 transformation matrix describing an affine\n transformation that needs to be applied to the decoded video frames for\n correct presentation.\n\n See libavutil/display.h for a detailed description of the data."]
pub const AVPacketSideDataType_AV_PKT_DATA_DISPLAYMATRIX: AVPacketSideDataType = 5;
#[doc = " This side data should be associated with a video stream and contains\n Stereoscopic 3D information in form of the AVStereo3D struct."]
pub const AVPacketSideDataType_AV_PKT_DATA_STEREO3D: AVPacketSideDataType = 6;
#[doc = " This side data should be associated with an audio stream and corresponds\n to enum AVAudioServiceType."]
pub const AVPacketSideDataType_AV_PKT_DATA_AUDIO_SERVICE_TYPE: AVPacketSideDataType = 7;
#[doc = " This side data contains quality related information from the encoder.\n @code\n u32le quality factor of the compressed frame. Allowed range is between 1 (good) and FF_LAMBDA_MAX (bad).\n u8    picture type\n u8    error count\n u16   reserved\n u64le[error count] sum of squared differences between encoder in and output\n @endcode"]
pub const AVPacketSideDataType_AV_PKT_DATA_QUALITY_STATS: AVPacketSideDataType = 8;
#[doc = " This side data contains an integer value representing the stream index\n of a \"fallback\" track.  A fallback track indicates an alternate\n track to use when the current track can not be decoded for some reason.\n e.g. no decoder available for codec."]
pub const AVPacketSideDataType_AV_PKT_DATA_FALLBACK_TRACK: AVPacketSideDataType = 9;
#[doc = " This side data corresponds to the AVCPBProperties struct."]
pub const AVPacketSideDataType_AV_PKT_DATA_CPB_PROPERTIES: AVPacketSideDataType = 10;
#[doc = " Recommmends skipping the specified number of samples\n @code\n u32le number of samples to skip from start of this packet\n u32le number of samples to skip from end of this packet\n u8    reason for start skip\n u8    reason for end   skip (0=padding silence, 1=convergence)\n @endcode"]
pub const AVPacketSideDataType_AV_PKT_DATA_SKIP_SAMPLES: AVPacketSideDataType = 11;
#[doc = " An AV_PKT_DATA_JP_DUALMONO side data packet indicates that\n the packet may contain \"dual mono\" audio specific to Japanese DTV\n and if it is true, recommends only the selected channel to be used.\n @code\n u8    selected channels (0=main/left, 1=sub/right, 2=both)\n @endcode"]
pub const AVPacketSideDataType_AV_PKT_DATA_JP_DUALMONO: AVPacketSideDataType = 12;
#[doc = " A list of zero terminated key/value strings. There is no end marker for\n the list, so it is required to rely on the side data size to stop."]
pub const AVPacketSideDataType_AV_PKT_DATA_STRINGS_METADATA: AVPacketSideDataType = 13;
#[doc = " Subtitle event position\n @code\n u32le x1\n u32le y1\n u32le x2\n u32le y2\n @endcode"]
pub const AVPacketSideDataType_AV_PKT_DATA_SUBTITLE_POSITION: AVPacketSideDataType = 14;
#[doc = " Data found in BlockAdditional element of matroska container. There is\n no end marker for the data, so it is required to rely on the side data\n size to recognize the end. 8 byte id (as found in BlockAddId) followed\n by data."]
pub const AVPacketSideDataType_AV_PKT_DATA_MATROSKA_BLOCKADDITIONAL: AVPacketSideDataType = 15;
#[doc = " The optional first identifier line of a WebVTT cue."]
pub const AVPacketSideDataType_AV_PKT_DATA_WEBVTT_IDENTIFIER: AVPacketSideDataType = 16;
#[doc = " The optional settings (rendering instructions) that immediately\n follow the timestamp specifier of a WebVTT cue."]
pub const AVPacketSideDataType_AV_PKT_DATA_WEBVTT_SETTINGS: AVPacketSideDataType = 17;
#[doc = " A list of zero terminated key/value strings. There is no end marker for\n the list, so it is required to rely on the side data size to stop. This\n side data includes updated metadata which appeared in the stream."]
pub const AVPacketSideDataType_AV_PKT_DATA_METADATA_UPDATE: AVPacketSideDataType = 18;
#[doc = " MPEGTS stream ID as uint8_t, this is required to pass the stream ID\n information from the demuxer to the corresponding muxer."]
pub const AVPacketSideDataType_AV_PKT_DATA_MPEGTS_STREAM_ID: AVPacketSideDataType = 19;
#[doc = " Mastering display metadata (based on SMPTE-2086:2014). This metadata\n should be associated with a video stream and contains data in the form\n of the AVMasteringDisplayMetadata struct."]
pub const AVPacketSideDataType_AV_PKT_DATA_MASTERING_DISPLAY_METADATA: AVPacketSideDataType = 20;
#[doc = " This side data should be associated with a video stream and corresponds\n to the AVSphericalMapping structure."]
pub const AVPacketSideDataType_AV_PKT_DATA_SPHERICAL: AVPacketSideDataType = 21;
#[doc = " Content light level (based on CTA-861.3). This metadata should be\n associated with a video stream and contains data in the form of the\n AVContentLightMetadata struct."]
pub const AVPacketSideDataType_AV_PKT_DATA_CONTENT_LIGHT_LEVEL: AVPacketSideDataType = 22;
#[doc = " ATSC A53 Part 4 Closed Captions. This metadata should be associated with\n a video stream. A53 CC bitstream is stored as uint8_t in AVPacketSideData.data.\n The number of bytes of CC data is AVPacketSideData.size."]
pub const AVPacketSideDataType_AV_PKT_DATA_A53_CC: AVPacketSideDataType = 23;
#[doc = " This side data is encryption initialization data.\n The format is not part of ABI, use av_encryption_init_info_* methods to\n access."]
pub const AVPacketSideDataType_AV_PKT_DATA_ENCRYPTION_INIT_INFO: AVPacketSideDataType = 24;
#[doc = " This side data contains encryption info for how to decrypt the packet.\n The format is not part of ABI, use av_encryption_info_* methods to access."]
pub const AVPacketSideDataType_AV_PKT_DATA_ENCRYPTION_INFO: AVPacketSideDataType = 25;
#[doc = " Active Format Description data consisting of a single byte as specified\n in ETSI TS 101 154 using AVActiveFormatDescription enum."]
pub const AVPacketSideDataType_AV_PKT_DATA_AFD: AVPacketSideDataType = 26;
#[doc = " Producer Reference Time data corresponding to the AVProducerReferenceTime struct,\n usually exported by some encoders (on demand through the prft flag set in the\n AVCodecContext export_side_data field)."]
pub const AVPacketSideDataType_AV_PKT_DATA_PRFT: AVPacketSideDataType = 27;
#[doc = " ICC profile data consisting of an opaque octet buffer following the\n format described by ISO 15076-1."]
pub const AVPacketSideDataType_AV_PKT_DATA_ICC_PROFILE: AVPacketSideDataType = 28;
#[doc = " DOVI configuration\n ref:\n dolby-vision-bitstreams-within-the-iso-base-media-file-format-v2.1.2, section 2.2\n dolby-vision-bitstreams-in-mpeg-2-transport-stream-multiplex-v1.2, section 3.3\n Tags are stored in struct AVDOVIDecoderConfigurationRecord."]
pub const AVPacketSideDataType_AV_PKT_DATA_DOVI_CONF: AVPacketSideDataType = 29;
#[doc = " Timecode which conforms to SMPTE ST 12-1:2014. The data is an array of 4 uint32_t\n where the first uint32_t describes how many (1-3) of the other timecodes are used.\n The timecode format is described in the documentation of av_timecode_get_smpte_from_framenum()\n function in libavutil/timecode.h."]
pub const AVPacketSideDataType_AV_PKT_DATA_S12M_TIMECODE: AVPacketSideDataType = 30;
#[doc = " HDR10+ dynamic metadata associated with a video frame. The metadata is in\n the form of the AVDynamicHDRPlus struct and contains\n information for color volume transform - application 4 of\n SMPTE 2094-40:2016 standard."]
pub const AVPacketSideDataType_AV_PKT_DATA_DYNAMIC_HDR10_PLUS: AVPacketSideDataType = 31;
#[doc = " IAMF Mix Gain Parameter Data associated with the audio frame. This metadata\n is in the form of the AVIAMFParamDefinition struct and contains information\n defined in sections 3.6.1 and 3.8.1 of the Immersive Audio Model and\n Formats standard."]
pub const AVPacketSideDataType_AV_PKT_DATA_IAMF_MIX_GAIN_PARAM: AVPacketSideDataType = 32;
#[doc = " IAMF Demixing Info Parameter Data associated with the audio frame. This\n metadata is in the form of the AVIAMFParamDefinition struct and contains\n information defined in sections 3.6.1 and 3.8.2 of the Immersive Audio Model\n and Formats standard."]
pub const AVPacketSideDataType_AV_PKT_DATA_IAMF_DEMIXING_INFO_PARAM: AVPacketSideDataType = 33;
#[doc = " IAMF Recon Gain Info Parameter Data associated with the audio frame. This\n metadata is in the form of the AVIAMFParamDefinition struct and contains\n information defined in sections 3.6.1 and 3.8.3 of the Immersive Audio Model\n and Formats standard."]
pub const AVPacketSideDataType_AV_PKT_DATA_IAMF_RECON_GAIN_INFO_PARAM: AVPacketSideDataType = 34;
#[doc = " Ambient viewing environment metadata, as defined by H.274. This metadata\n should be associated with a video stream and contains data in the form\n of the AVAmbientViewingEnvironment struct."]
pub const AVPacketSideDataType_AV_PKT_DATA_AMBIENT_VIEWING_ENVIRONMENT: AVPacketSideDataType = 35;
#[doc = " The number of side data types.\n This is not part of the public API/ABI in the sense that it may\n change when new side data types are added.\n This must stay the last enum value.\n If its value becomes huge, some code using it\n needs to be updated as it assumes it to be smaller than other limits."]
pub const AVPacketSideDataType_AV_PKT_DATA_NB: AVPacketSideDataType = 36;
#[doc = " @defgroup lavc_packet_side_data AVPacketSideData\n\n Types and functions for working with AVPacketSideData.\n @{"]
pub type AVPacketSideDataType = ::std::os::raw::c_uint;
#[doc = " This structure stores auxiliary information for decoding, presenting, or\n otherwise processing the coded stream. It is typically exported by demuxers\n and encoders and can be fed to decoders and muxers either in a per packet\n basis, or as global side data (applying to the entire coded stream).\n\n Global side data is handled as follows:\n - During demuxing, it may be exported through\n   @ref AVStream.codecpar.side_data \"AVStream's codec parameters\", which can\n   then be passed as input to decoders through the\n   @ref AVCodecContext.coded_side_data \"decoder context's side data\", for\n   initialization.\n - For muxing, it can be fed through @ref AVStream.codecpar.side_data\n   \"AVStream's codec parameters\", typically  the output of encoders through\n   the @ref AVCodecContext.coded_side_data \"encoder context's side data\", for\n   initialization.\n\n Packet specific side data is handled as follows:\n - During demuxing, it may be exported through @ref AVPacket.side_data\n   \"AVPacket's side data\", which can then be passed as input to decoders.\n - For muxing, it can be fed through @ref AVPacket.side_data \"AVPacket's\n   side data\", typically the output of encoders.\n\n Different modules may accept or export different types of side data\n depending on media type and codec. Refer to @ref AVPacketSideDataType for a\n list of defined types and where they may be found or used."]
#[repr(C)]
#[derive(Debug, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVPacketSideData {
    pub data: *mut u8,
    pub size: usize,
    pub type_: AVPacketSideDataType,
}
impl Default for AVPacketSideData {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
extern "C" {
    #[doc = " Allocate a new packet side data.\n\n @param sd    pointer to an array of side data to which the side data should\n              be added. *sd may be NULL, in which case the array will be\n              initialized.\n @param nb_sd pointer to an integer containing the number of entries in\n              the array. The integer value will be increased by 1 on success.\n @param type  side data type\n @param size  desired side data size\n @param flags currently unused. Must be zero\n\n @return pointer to freshly allocated side data on success, or NULL otherwise."]
    pub fn av_packet_side_data_new(
        psd: *mut *mut AVPacketSideData,
        pnb_sd: *mut ::std::os::raw::c_int,
        type_: AVPacketSideDataType,
        size: usize,
        flags: ::std::os::raw::c_int,
    ) -> *mut AVPacketSideData;
}
extern "C" {
    #[doc = " Wrap existing data as packet side data.\n\n @param sd    pointer to an array of side data to which the side data should\n              be added. *sd may be NULL, in which case the array will be\n              initialized\n @param nb_sd pointer to an integer containing the number of entries in\n              the array. The integer value will be increased by 1 on success.\n @param type  side data type\n @param data  a data array. It must be allocated with the av_malloc() family\n              of functions. The ownership of the data is transferred to the\n              side data array on success\n @param size  size of the data array\n @param flags currently unused. Must be zero\n\n @return pointer to freshly allocated side data on success, or NULL otherwise\n         On failure, the side data array is unchanged and the data remains\n         owned by the caller."]
    pub fn av_packet_side_data_add(
        sd: *mut *mut AVPacketSideData,
        nb_sd: *mut ::std::os::raw::c_int,
        type_: AVPacketSideDataType,
        data: *mut ::std::os::raw::c_void,
        size: usize,
        flags: ::std::os::raw::c_int,
    ) -> *mut AVPacketSideData;
}
extern "C" {
    #[doc = " Get side information from a side data array.\n\n @param sd    the array from which the side data should be fetched\n @param nb_sd value containing the number of entries in the array.\n @param type  desired side information type\n\n @return pointer to side data if present or NULL otherwise"]
    pub fn av_packet_side_data_get(
        sd: *const AVPacketSideData,
        nb_sd: ::std::os::raw::c_int,
        type_: AVPacketSideDataType,
    ) -> *const AVPacketSideData;
}
extern "C" {
    #[doc = " Remove side data of the given type from a side data array.\n\n @param sd    the array from which the side data should be removed\n @param nb_sd pointer to an integer containing the number of entries in\n              the array. Will be reduced by the amount of entries removed\n              upon return\n @param type  side information type"]
    pub fn av_packet_side_data_remove(
        sd: *mut AVPacketSideData,
        nb_sd: *mut ::std::os::raw::c_int,
        type_: AVPacketSideDataType,
    );
}
extern "C" {
    #[doc = " Convenience function to free all the side data stored in an array, and\n the array itself.\n\n @param sd    pointer to array of side data to free. Will be set to NULL\n              upon return.\n @param nb_sd pointer to an integer containing the number of entries in\n              the array. Will be set to 0 upon return."]
    pub fn av_packet_side_data_free(
        sd: *mut *mut AVPacketSideData,
        nb_sd: *mut ::std::os::raw::c_int,
    );
}
extern "C" {
    pub fn av_packet_side_data_name(type_: AVPacketSideDataType) -> *const ::std::os::raw::c_char;
}
#[doc = " This structure stores compressed data. It is typically exported by demuxers\n and then passed as input to decoders, or received as output from encoders and\n then passed to muxers.\n\n For video, it should typically contain one compressed frame. For audio it may\n contain several compressed frames. Encoders are allowed to output empty\n packets, with no compressed data, containing only side data\n (e.g. to update some stream parameters at the end of encoding).\n\n The semantics of data ownership depends on the buf field.\n If it is set, the packet data is dynamically allocated and is\n valid indefinitely until a call to av_packet_unref() reduces the\n reference count to 0.\n\n If the buf field is not set av_packet_ref() would make a copy instead\n of increasing the reference count.\n\n The side data is always allocated with av_malloc(), copied by\n av_packet_ref() and freed by av_packet_unref().\n\n sizeof(AVPacket) being a part of the public ABI is deprecated. once\n av_init_packet() is removed, new packets will only be able to be allocated\n with av_packet_alloc(), and new fields may be added to the end of the struct\n with a minor bump.\n\n @see av_packet_alloc\n @see av_packet_ref\n @see av_packet_unref"]
#[repr(C)]
#[derive(Debug, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVPacket {
    #[doc = " A reference to the reference-counted buffer where the packet data is\n stored.\n May be NULL, then the packet data is not reference-counted."]
    pub buf: *mut AVBufferRef,
    #[doc = " Presentation timestamp in AVStream->time_base units; the time at which\n the decompressed packet will be presented to the user.\n Can be AV_NOPTS_VALUE if it is not stored in the file.\n pts MUST be larger or equal to dts as presentation cannot happen before\n decompression, unless one wants to view hex dumps. Some formats misuse\n the terms dts and pts/cts to mean something different. Such timestamps\n must be converted to true pts/dts before they are stored in AVPacket."]
    pub pts: i64,
    #[doc = " Decompression timestamp in AVStream->time_base units; the time at which\n the packet is decompressed.\n Can be AV_NOPTS_VALUE if it is not stored in the file."]
    pub dts: i64,
    pub data: *mut u8,
    pub size: ::std::os::raw::c_int,
    pub stream_index: ::std::os::raw::c_int,
    #[doc = " A combination of AV_PKT_FLAG values"]
    pub flags: ::std::os::raw::c_int,
    #[doc = " Additional packet data that can be provided by the container.\n Packet can contain several types of side information."]
    pub side_data: *mut AVPacketSideData,
    pub side_data_elems: ::std::os::raw::c_int,
    #[doc = " Duration of this packet in AVStream->time_base units, 0 if unknown.\n Equals next_pts - this_pts in presentation order."]
    pub duration: i64,
    #[doc = "< byte position in stream, -1 if unknown"]
    pub pos: i64,
    #[doc = " for some private data of the user"]
    pub opaque: *mut ::std::os::raw::c_void,
    #[doc = " AVBufferRef for free use by the API user. FFmpeg will never check the\n contents of the buffer ref. FFmpeg calls av_buffer_unref() on it when\n the packet is unreferenced. av_packet_copy_props() calls create a new\n reference with av_buffer_ref() for the target packet's opaque_ref field.\n\n This is unrelated to the opaque field, although it serves a similar\n purpose."]
    pub opaque_ref: *mut AVBufferRef,
    #[doc = " Time base of the packet's timestamps.\n In the future, this field may be set on packets output by encoders or\n demuxers, but its value will be by default ignored on input to decoders\n or muxers."]
    pub time_base: AVRational,
}
impl Default for AVPacket {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Debug, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVPacketList {
    pub pkt: AVPacket,
    pub next: *mut AVPacketList,
}
impl Default for AVPacketList {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub const AVSideDataParamChangeFlags_AV_SIDE_DATA_PARAM_CHANGE_SAMPLE_RATE:
    AVSideDataParamChangeFlags = 4;
pub const AVSideDataParamChangeFlags_AV_SIDE_DATA_PARAM_CHANGE_DIMENSIONS:
    AVSideDataParamChangeFlags = 8;
pub type AVSideDataParamChangeFlags = ::std::os::raw::c_uint;
extern "C" {
    #[doc = " Allocate an AVPacket and set its fields to default values.  The resulting\n struct must be freed using av_packet_free().\n\n @return An AVPacket filled with default values or NULL on failure.\n\n @note this only allocates the AVPacket itself, not the data buffers. Those\n must be allocated through other means such as av_new_packet.\n\n @see av_new_packet"]
    pub fn av_packet_alloc() -> *mut AVPacket;
}
extern "C" {
    #[doc = " Create a new packet that references the same data as src.\n\n This is a shortcut for av_packet_alloc()+av_packet_ref().\n\n @return newly created AVPacket on success, NULL on error.\n\n @see av_packet_alloc\n @see av_packet_ref"]
    pub fn av_packet_clone(src: *const AVPacket) -> *mut AVPacket;
}
extern "C" {
    #[doc = " Free the packet, if the packet is reference counted, it will be\n unreferenced first.\n\n @param pkt packet to be freed. The pointer will be set to NULL.\n @note passing NULL is a no-op."]
    pub fn av_packet_free(pkt: *mut *mut AVPacket);
}
extern "C" {
    #[doc = " Initialize optional fields of a packet with default values.\n\n Note, this does not touch the data and size members, which have to be\n initialized separately.\n\n @param pkt packet\n\n @see av_packet_alloc\n @see av_packet_unref\n\n @deprecated This function is deprecated. Once it's removed,\nsizeof(AVPacket) will not be a part of the ABI anymore."]
    pub fn av_init_packet(pkt: *mut AVPacket);
}
extern "C" {
    #[doc = " Allocate the payload of a packet and initialize its fields with\n default values.\n\n @param pkt packet\n @param size wanted payload size\n @return 0 if OK, AVERROR_xxx otherwise"]
    pub fn av_new_packet(pkt: *mut AVPacket, size: ::std::os::raw::c_int) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Reduce packet size, correctly zeroing padding\n\n @param pkt packet\n @param size new size"]
    pub fn av_shrink_packet(pkt: *mut AVPacket, size: ::std::os::raw::c_int);
}
extern "C" {
    #[doc = " Increase packet size, correctly zeroing padding\n\n @param pkt packet\n @param grow_by number of bytes by which to increase the size of the packet"]
    pub fn av_grow_packet(
        pkt: *mut AVPacket,
        grow_by: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Initialize a reference-counted packet from av_malloc()ed data.\n\n @param pkt packet to be initialized. This function will set the data, size,\n        and buf fields, all others are left untouched.\n @param data Data allocated by av_malloc() to be used as packet data. If this\n        function returns successfully, the data is owned by the underlying AVBuffer.\n        The caller may not access the data through other means.\n @param size size of data in bytes, without the padding. I.e. the full buffer\n        size is assumed to be size + AV_INPUT_BUFFER_PADDING_SIZE.\n\n @return 0 on success, a negative AVERROR on error"]
    pub fn av_packet_from_data(
        pkt: *mut AVPacket,
        data: *mut u8,
        size: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Allocate new information of a packet.\n\n @param pkt packet\n @param type side information type\n @param size side information size\n @return pointer to fresh allocated data or NULL otherwise"]
    pub fn av_packet_new_side_data(
        pkt: *mut AVPacket,
        type_: AVPacketSideDataType,
        size: usize,
    ) -> *mut u8;
}
extern "C" {
    #[doc = " Wrap an existing array as a packet side data.\n\n @param pkt packet\n @param type side information type\n @param data the side data array. It must be allocated with the av_malloc()\n             family of functions. The ownership of the data is transferred to\n             pkt.\n @param size side information size\n @return a non-negative number on success, a negative AVERROR code on\n         failure. On failure, the packet is unchanged and the data remains\n         owned by the caller."]
    pub fn av_packet_add_side_data(
        pkt: *mut AVPacket,
        type_: AVPacketSideDataType,
        data: *mut u8,
        size: usize,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Shrink the already allocated side data buffer\n\n @param pkt packet\n @param type side information type\n @param size new side information size\n @return 0 on success, < 0 on failure"]
    pub fn av_packet_shrink_side_data(
        pkt: *mut AVPacket,
        type_: AVPacketSideDataType,
        size: usize,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get side information from packet.\n\n @param pkt packet\n @param type desired side information type\n @param size If supplied, *size will be set to the size of the side data\n             or to zero if the desired side data is not present.\n @return pointer to data if present or NULL otherwise"]
    pub fn av_packet_get_side_data(
        pkt: *const AVPacket,
        type_: AVPacketSideDataType,
        size: *mut usize,
    ) -> *mut u8;
}
extern "C" {
    #[doc = " Pack a dictionary for use in side_data.\n\n @param dict The dictionary to pack.\n @param size pointer to store the size of the returned data\n @return pointer to data if successful, NULL otherwise"]
    pub fn av_packet_pack_dictionary(dict: *mut AVDictionary, size: *mut usize) -> *mut u8;
}
extern "C" {
    #[doc = " Unpack a dictionary from side_data.\n\n @param data data from side_data\n @param size size of the data\n @param dict the metadata storage dictionary\n @return 0 on success, < 0 on failure"]
    pub fn av_packet_unpack_dictionary(
        data: *const u8,
        size: usize,
        dict: *mut *mut AVDictionary,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Convenience function to free all the side data stored.\n All the other fields stay untouched.\n\n @param pkt packet"]
    pub fn av_packet_free_side_data(pkt: *mut AVPacket);
}
extern "C" {
    #[doc = " Setup a new reference to the data described by a given packet\n\n If src is reference-counted, setup dst as a new reference to the\n buffer in src. Otherwise allocate a new buffer in dst and copy the\n data from src into it.\n\n All the other fields are copied from src.\n\n @see av_packet_unref\n\n @param dst Destination packet. Will be completely overwritten.\n @param src Source packet\n\n @return 0 on success, a negative AVERROR on error. On error, dst\n         will be blank (as if returned by av_packet_alloc())."]
    pub fn av_packet_ref(dst: *mut AVPacket, src: *const AVPacket) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Wipe the packet.\n\n Unreference the buffer referenced by the packet and reset the\n remaining packet fields to their default values.\n\n @param pkt The packet to be unreferenced."]
    pub fn av_packet_unref(pkt: *mut AVPacket);
}
extern "C" {
    #[doc = " Move every field in src to dst and reset src.\n\n @see av_packet_unref\n\n @param src Source packet, will be reset\n @param dst Destination packet"]
    pub fn av_packet_move_ref(dst: *mut AVPacket, src: *mut AVPacket);
}
extern "C" {
    #[doc = " Copy only \"properties\" fields from src to dst.\n\n Properties for the purpose of this function are all the fields\n beside those related to the packet data (buf, data, size)\n\n @param dst Destination packet\n @param src Source packet\n\n @return 0 on success AVERROR on failure."]
    pub fn av_packet_copy_props(dst: *mut AVPacket, src: *const AVPacket) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Ensure the data described by a given packet is reference counted.\n\n @note This function does not ensure that the reference will be writable.\n       Use av_packet_make_writable instead for that purpose.\n\n @see av_packet_ref\n @see av_packet_make_writable\n\n @param pkt packet whose data should be made reference counted.\n\n @return 0 on success, a negative AVERROR on error. On failure, the\n         packet is unchanged."]
    pub fn av_packet_make_refcounted(pkt: *mut AVPacket) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Create a writable reference for the data described by a given packet,\n avoiding data copy if possible.\n\n @param pkt Packet whose data should be made writable.\n\n @return 0 on success, a negative AVERROR on failure. On failure, the\n         packet is unchanged."]
    pub fn av_packet_make_writable(pkt: *mut AVPacket) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Convert valid timing fields (timestamps / durations) in a packet from one\n timebase to another. Timestamps with unknown values (AV_NOPTS_VALUE) will be\n ignored.\n\n @param pkt packet on which the conversion will be performed\n @param tb_src source timebase, in which the timing fields in pkt are\n               expressed\n @param tb_dst destination timebase, to which the timing fields will be\n               converted"]
    pub fn av_packet_rescale_ts(pkt: *mut AVPacket, tb_src: AVRational, tb_dst: AVRational);
}
#[doc = " This struct describes the properties of a single codec described by an\n AVCodecID.\n @see avcodec_descriptor_get()"]
#[repr(C)]
#[derive(Debug, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVCodecDescriptor {
    pub id: AVCodecID,
    pub type_: AVMediaType,
    #[doc = " Name of the codec described by this descriptor. It is non-empty and\n unique for each codec descriptor. It should contain alphanumeric\n characters and '_' only."]
    pub name: *const ::std::os::raw::c_char,
    #[doc = " A more descriptive name for this codec. May be NULL."]
    pub long_name: *const ::std::os::raw::c_char,
    #[doc = " Codec properties, a combination of AV_CODEC_PROP_* flags."]
    pub props: ::std::os::raw::c_int,
    #[doc = " MIME type(s) associated with the codec.\n May be NULL; if not, a NULL-terminated array of MIME types.\n The first item is always non-NULL and is the preferred MIME type."]
    pub mime_types: *const *const ::std::os::raw::c_char,
    #[doc = " If non-NULL, an array of profiles recognized for this codec.\n Terminated with AV_PROFILE_UNKNOWN."]
    pub profiles: *const AVProfile,
}
impl Default for AVCodecDescriptor {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
extern "C" {
    #[doc = " @return descriptor for given codec ID or NULL if no descriptor exists."]
    pub fn avcodec_descriptor_get(id: AVCodecID) -> *const AVCodecDescriptor;
}
extern "C" {
    #[doc = " Iterate over all codec descriptors known to libavcodec.\n\n @param prev previous descriptor. NULL to get the first descriptor.\n\n @return next descriptor or NULL after the last descriptor"]
    pub fn avcodec_descriptor_next(prev: *const AVCodecDescriptor) -> *const AVCodecDescriptor;
}
extern "C" {
    #[doc = " @return codec descriptor with the given name or NULL if no such descriptor\n         exists."]
    pub fn avcodec_descriptor_get_by_name(
        name: *const ::std::os::raw::c_char,
    ) -> *const AVCodecDescriptor;
}
#[doc = " This struct describes the properties of an encoded stream.\n\n sizeof(AVCodecParameters) is not a part of the public ABI, this struct must\n be allocated with avcodec_parameters_alloc() and freed with\n avcodec_parameters_free()."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct AVCodecParameters {
    #[doc = " General type of the encoded data."]
    pub codec_type: AVMediaType,
    #[doc = " Specific type of the encoded data (the codec used)."]
    pub codec_id: AVCodecID,
    #[doc = " Additional information about the codec (corresponds to the AVI FOURCC)."]
    pub codec_tag: u32,
    #[doc = " Extra binary data needed for initializing the decoder, codec-dependent.\n\n Must be allocated with av_malloc() and will be freed by\n avcodec_parameters_free(). The allocated size of extradata must be at\n least extradata_size + AV_INPUT_BUFFER_PADDING_SIZE, with the padding\n bytes zeroed."]
    pub extradata: *mut u8,
    #[doc = " Size of the extradata content in bytes."]
    pub extradata_size: ::std::os::raw::c_int,
    #[doc = " Additional data associated with the entire stream.\n\n Should be allocated with av_packet_side_data_new() or\n av_packet_side_data_add(), and will be freed by avcodec_parameters_free()."]
    pub coded_side_data: *mut AVPacketSideData,
    #[doc = " Amount of entries in @ref coded_side_data."]
    pub nb_coded_side_data: ::std::os::raw::c_int,
    #[doc = " - video: the pixel format, the value corresponds to enum AVPixelFormat.\n - audio: the sample format, the value corresponds to enum AVSampleFormat."]
    pub format: ::std::os::raw::c_int,
    #[doc = " The average bitrate of the encoded data (in bits per second)."]
    pub bit_rate: i64,
    #[doc = " The number of bits per sample in the codedwords.\n\n This is basically the bitrate per sample. It is mandatory for a bunch of\n formats to actually decode them. It's the number of bits for one sample in\n the actual coded bitstream.\n\n This could be for example 4 for ADPCM\n For PCM formats this matches bits_per_raw_sample\n Can be 0"]
    pub bits_per_coded_sample: ::std::os::raw::c_int,
    #[doc = " This is the number of valid bits in each output sample. If the\n sample format has more bits, the least significant bits are additional\n padding bits, which are always 0. Use right shifts to reduce the sample\n to its actual size. For example, audio formats with 24 bit samples will\n have bits_per_raw_sample set to 24, and format set to AV_SAMPLE_FMT_S32.\n To get the original sample use \"(int32_t)sample >> 8\".\"\n\n For ADPCM this might be 12 or 16 or similar\n Can be 0"]
    pub bits_per_raw_sample: ::std::os::raw::c_int,
    #[doc = " Codec-specific bitstream restrictions that the stream conforms to."]
    pub profile: ::std::os::raw::c_int,
    pub level: ::std::os::raw::c_int,
    #[doc = " Video only. The dimensions of the video frame in pixels."]
    pub width: ::std::os::raw::c_int,
    pub height: ::std::os::raw::c_int,
    #[doc = " Video only. The aspect ratio (width / height) which a single pixel\n should have when displayed.\n\n When the aspect ratio is unknown / undefined, the numerator should be\n set to 0 (the denominator may have any value)."]
    pub sample_aspect_ratio: AVRational,
    #[doc = " Video only. Number of frames per second, for streams with constant frame\n durations. Should be set to { 0, 1 } when some frames have differing\n durations or if the value is not known.\n\n @note This field correponds to values that are stored in codec-level\n headers and is typically overridden by container/transport-layer\n timestamps, when available. It should thus be used only as a last resort,\n when no higher-level timing information is available."]
    pub framerate: AVRational,
    #[doc = " Video only. The order of the fields in interlaced video."]
    pub field_order: AVFieldOrder,
    #[doc = " Video only. Additional colorspace characteristics."]
    pub color_range: AVColorRange,
    pub color_primaries: AVColorPrimaries,
    pub color_trc: AVColorTransferCharacteristic,
    pub color_space: AVColorSpace,
    pub chroma_location: AVChromaLocation,
    #[doc = " Video only. Number of delayed frames."]
    pub video_delay: ::std::os::raw::c_int,
    #[doc = " Audio only. The channel layout and number of channels."]
    pub ch_layout: AVChannelLayout,
    #[doc = " Audio only. The number of audio samples per second."]
    pub sample_rate: ::std::os::raw::c_int,
    #[doc = " Audio only. The number of bytes per coded audio frame, required by some\n formats.\n\n Corresponds to nBlockAlign in WAVEFORMATEX."]
    pub block_align: ::std::os::raw::c_int,
    #[doc = " Audio only. Audio frame size, if known. Required by some formats to be static."]
    pub frame_size: ::std::os::raw::c_int,
    #[doc = " Audio only. The amount of padding (in samples) inserted by the encoder at\n the beginning of the audio. I.e. this number of leading decoded samples\n must be discarded by the caller to get the original audio without leading\n padding."]
    pub initial_padding: ::std::os::raw::c_int,
    #[doc = " Audio only. The amount of padding (in samples) appended by the encoder to\n the end of the audio. I.e. this number of decoded samples must be\n discarded by the caller from the end of the stream to get the original\n audio without any trailing padding."]
    pub trailing_padding: ::std::os::raw::c_int,
    #[doc = " Audio only. Number of samples to skip after a discontinuity."]
    pub seek_preroll: ::std::os::raw::c_int,
}
impl Default for AVCodecParameters {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
extern "C" {
    #[doc = " Allocate a new AVCodecParameters and set its fields to default values\n (unknown/invalid/0). The returned struct must be freed with\n avcodec_parameters_free()."]
    pub fn avcodec_parameters_alloc() -> *mut AVCodecParameters;
}
extern "C" {
    #[doc = " Free an AVCodecParameters instance and everything associated with it and\n write NULL to the supplied pointer."]
    pub fn avcodec_parameters_free(par: *mut *mut AVCodecParameters);
}
extern "C" {
    #[doc = " Copy the contents of src to dst. Any allocated fields in dst are freed and\n replaced with newly allocated duplicates of the corresponding fields in src.\n\n @return >= 0 on success, a negative AVERROR code on failure."]
    pub fn avcodec_parameters_copy(
        dst: *mut AVCodecParameters,
        src: *const AVCodecParameters,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " This function is the same as av_get_audio_frame_duration(), except it works\n with AVCodecParameters instead of an AVCodecContext."]
    pub fn av_get_audio_frame_duration2(
        par: *mut AVCodecParameters,
        frame_bytes: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
#[doc = " @ingroup lavc_encoding"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone, PartialOrd, PartialEq)]
pub struct RcOverride {
    pub start_frame: ::std::os::raw::c_int,
    pub end_frame: ::std::os::raw::c_int,
    pub qscale: ::std::os::raw::c_int,
    pub quality_factor: f32,
}
#[doc = " main external API structure.\n New fields can be added to the end with minor version bumps.\n Removal, reordering and changes to existing fields require a major\n version bump.\n You can use AVOptions (av_opt* / av_set/get*()) to access these fields from user\n applications.\n The name string for AVOptions options matches the associated command line\n parameter name and can be found in libavcodec/options_table.h\n The AVOption/command line parameter names differ in some cases from the C\n structure field names for historic reasons or brevity.\n sizeof(AVCodecContext) must not be used outside libav*."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct AVCodecContext {
    #[doc = " information on struct for av_log\n - set by avcodec_alloc_context3"]
    pub av_class: *const AVClass,
    pub log_level_offset: ::std::os::raw::c_int,
    pub codec_type: AVMediaType,
    pub codec: *const AVCodec,
    pub codec_id: AVCodecID,
    #[doc = " fourcc (LSB first, so \"ABCD\" -> ('D'<<24) + ('C'<<16) + ('B'<<8) + 'A').\n This is used to work around some encoder bugs.\n A demuxer should set this to what is stored in the field used to identify the codec.\n If there are multiple such fields in a container then the demuxer should choose the one\n which maximizes the information about the used codec.\n If the codec tag field in a container is larger than 32 bits then the demuxer should\n remap the longer ID to 32 bits with a table or other structure. Alternatively a new\n extra_codec_tag + size could be added but for this a clear advantage must be demonstrated\n first.\n - encoding: Set by user, if not then the default based on codec_id will be used.\n - decoding: Set by user, will be converted to uppercase by libavcodec during init."]
    pub codec_tag: ::std::os::raw::c_uint,
    pub priv_data: *mut ::std::os::raw::c_void,
    #[doc = " Private context used for internal data.\n\n Unlike priv_data, this is not codec-specific. It is used in general\n libavcodec functions."]
    pub internal: *mut AVCodecInternal,
    #[doc = " Private data of the user, can be used to carry app specific stuff.\n - encoding: Set by user.\n - decoding: Set by user."]
    pub opaque: *mut ::std::os::raw::c_void,
    #[doc = " the average bitrate\n - encoding: Set by user; unused for constant quantizer encoding.\n - decoding: Set by user, may be overwritten by libavcodec\n             if this info is available in the stream"]
    pub bit_rate: i64,
    #[doc = " AV_CODEC_FLAG_*.\n - encoding: Set by user.\n - decoding: Set by user."]
    pub flags: ::std::os::raw::c_int,
    #[doc = " AV_CODEC_FLAG2_*\n - encoding: Set by user.\n - decoding: Set by user."]
    pub flags2: ::std::os::raw::c_int,
    #[doc = " some codecs need / can use extradata like Huffman tables.\n MJPEG: Huffman tables\n rv10: additional flags\n MPEG-4: global headers (they can be in the bitstream or here)\n The allocated memory should be AV_INPUT_BUFFER_PADDING_SIZE bytes larger\n than extradata_size to avoid problems if it is read with the bitstream reader.\n The bytewise contents of extradata must not depend on the architecture or CPU endianness.\n Must be allocated with the av_malloc() family of functions.\n - encoding: Set/allocated/freed by libavcodec.\n - decoding: Set/allocated/freed by user."]
    pub extradata: *mut u8,
    pub extradata_size: ::std::os::raw::c_int,
    #[doc = " This is the fundamental unit of time (in seconds) in terms\n of which frame timestamps are represented. For fixed-fps content,\n timebase should be 1/framerate and timestamp increments should be\n identically 1.\n This often, but not always is the inverse of the frame rate or field rate\n for video. 1/time_base is not the average frame rate if the frame rate is not\n constant.\n\n Like containers, elementary streams also can store timestamps, 1/time_base\n is the unit in which these timestamps are specified.\n As example of such codec time base see ISO/IEC 14496-2:2001(E)\n vop_time_increment_resolution and fixed_vop_rate\n (fixed_vop_rate == 0 implies that it is different from the framerate)\n\n - encoding: MUST be set by user.\n - decoding: unused."]
    pub time_base: AVRational,
    #[doc = " Timebase in which pkt_dts/pts and AVPacket.dts/pts are expressed.\n - encoding: unused.\n - decoding: set by user."]
    pub pkt_timebase: AVRational,
    #[doc = " - decoding: For codecs that store a framerate value in the compressed\n             bitstream, the decoder may export it here. { 0, 1} when\n             unknown.\n - encoding: May be used to signal the framerate of CFR content to an\n             encoder."]
    pub framerate: AVRational,
    #[doc = " For some codecs, the time base is closer to the field rate than the frame rate.\n Most notably, H.264 and MPEG-2 specify time_base as half of frame duration\n if no telecine is used ...\n\n Set to time_base ticks per frame. Default 1, e.g., H.264/MPEG-2 set it to 2.\n\n @deprecated\n - decoding: Use AVCodecDescriptor.props & AV_CODEC_PROP_FIELDS\n - encoding: Set AVCodecContext.framerate instead\n"]
    pub ticks_per_frame: ::std::os::raw::c_int,
    #[doc = " Codec delay.\n\n Encoding: Number of frames delay there will be from the encoder input to\n           the decoder output. (we assume the decoder matches the spec)\n Decoding: Number of frames delay in addition to what a standard decoder\n           as specified in the spec would produce.\n\n Video:\n   Number of frames the decoded output will be delayed relative to the\n   encoded input.\n\n Audio:\n   For encoding, this field is unused (see initial_padding).\n\n   For decoding, this is the number of samples the decoder needs to\n   output before the decoder's output is valid. When seeking, you should\n   start decoding this many samples prior to your desired seek point.\n\n - encoding: Set by libavcodec.\n - decoding: Set by libavcodec."]
    pub delay: ::std::os::raw::c_int,
    #[doc = " picture width / height.\n\n @note Those fields may not match the values of the last\n AVFrame output by avcodec_receive_frame() due frame\n reordering.\n\n - encoding: MUST be set by user.\n - decoding: May be set by the user before opening the decoder if known e.g.\n             from the container. Some decoders will require the dimensions\n             to be set by the caller. During decoding, the decoder may\n             overwrite those values as required while parsing the data."]
    pub width: ::std::os::raw::c_int,
    #[doc = " picture width / height.\n\n @note Those fields may not match the values of the last\n AVFrame output by avcodec_receive_frame() due frame\n reordering.\n\n - encoding: MUST be set by user.\n - decoding: May be set by the user before opening the decoder if known e.g.\n             from the container. Some decoders will require the dimensions\n             to be set by the caller. During decoding, the decoder may\n             overwrite those values as required while parsing the data."]
    pub height: ::std::os::raw::c_int,
    #[doc = " Bitstream width / height, may be different from width/height e.g. when\n the decoded frame is cropped before being output or lowres is enabled.\n\n @note Those field may not match the value of the last\n AVFrame output by avcodec_receive_frame() due frame\n reordering.\n\n - encoding: unused\n - decoding: May be set by the user before opening the decoder if known\n             e.g. from the container. During decoding, the decoder may\n             overwrite those values as required while parsing the data."]
    pub coded_width: ::std::os::raw::c_int,
    #[doc = " Bitstream width / height, may be different from width/height e.g. when\n the decoded frame is cropped before being output or lowres is enabled.\n\n @note Those field may not match the value of the last\n AVFrame output by avcodec_receive_frame() due frame\n reordering.\n\n - encoding: unused\n - decoding: May be set by the user before opening the decoder if known\n             e.g. from the container. During decoding, the decoder may\n             overwrite those values as required while parsing the data."]
    pub coded_height: ::std::os::raw::c_int,
    #[doc = " sample aspect ratio (0 if unknown)\n That is the width of a pixel divided by the height of the pixel.\n Numerator and denominator must be relatively prime and smaller than 256 for some video standards.\n - encoding: Set by user.\n - decoding: Set by libavcodec."]
    pub sample_aspect_ratio: AVRational,
    #[doc = " Pixel format, see AV_PIX_FMT_xxx.\n May be set by the demuxer if known from headers.\n May be overridden by the decoder if it knows better.\n\n @note This field may not match the value of the last\n AVFrame output by avcodec_receive_frame() due frame\n reordering.\n\n - encoding: Set by user.\n - decoding: Set by user if known, overridden by libavcodec while\n             parsing the data."]
    pub pix_fmt: AVPixelFormat,
    #[doc = " Nominal unaccelerated pixel format, see AV_PIX_FMT_xxx.\n - encoding: unused.\n - decoding: Set by libavcodec before calling get_format()"]
    pub sw_pix_fmt: AVPixelFormat,
    #[doc = " Chromaticity coordinates of the source primaries.\n - encoding: Set by user\n - decoding: Set by libavcodec"]
    pub color_primaries: AVColorPrimaries,
    #[doc = " Color Transfer Characteristic.\n - encoding: Set by user\n - decoding: Set by libavcodec"]
    pub color_trc: AVColorTransferCharacteristic,
    #[doc = " YUV colorspace type.\n - encoding: Set by user\n - decoding: Set by libavcodec"]
    pub colorspace: AVColorSpace,
    #[doc = " MPEG vs JPEG YUV range.\n - encoding: Set by user to override the default output color range value,\n   If not specified, libavcodec sets the color range depending on the\n   output format.\n - decoding: Set by libavcodec, can be set by the user to propagate the\n   color range to components reading from the decoder context."]
    pub color_range: AVColorRange,
    #[doc = " This defines the location of chroma samples.\n - encoding: Set by user\n - decoding: Set by libavcodec"]
    pub chroma_sample_location: AVChromaLocation,
    #[doc = " Field order\n - encoding: set by libavcodec\n - decoding: Set by user."]
    pub field_order: AVFieldOrder,
    #[doc = " number of reference frames\n - encoding: Set by user.\n - decoding: Set by lavc."]
    pub refs: ::std::os::raw::c_int,
    #[doc = " Size of the frame reordering buffer in the decoder.\n For MPEG-2 it is 1 IPB or 0 low delay IP.\n - encoding: Set by libavcodec.\n - decoding: Set by libavcodec."]
    pub has_b_frames: ::std::os::raw::c_int,
    #[doc = " slice flags\n - encoding: unused\n - decoding: Set by user."]
    pub slice_flags: ::std::os::raw::c_int,
    #[doc = " If non NULL, 'draw_horiz_band' is called by the libavcodec\n decoder to draw a horizontal band. It improves cache usage. Not\n all codecs can do that. You must check the codec capabilities\n beforehand.\n When multithreading is used, it may be called from multiple threads\n at the same time; threads might draw different parts of the same AVFrame,\n or multiple AVFrames, and there is no guarantee that slices will be drawn\n in order.\n The function is also used by hardware acceleration APIs.\n It is called at least once during frame decoding to pass\n the data needed for hardware render.\n In that mode instead of pixel data, AVFrame points to\n a structure specific to the acceleration API. The application\n reads the structure and can change some fields to indicate progress\n or mark state.\n - encoding: unused\n - decoding: Set by user.\n @param height the height of the slice\n @param y the y position of the slice\n @param type 1->top field, 2->bottom field, 3->frame\n @param offset offset into the AVFrame.data from which the slice should be read"]
    pub draw_horiz_band: ::std::option::Option<
        unsafe extern "C" fn(
            s: *mut AVCodecContext,
            src: *const AVFrame,
            offset: *mut ::std::os::raw::c_int,
            y: ::std::os::raw::c_int,
            type_: ::std::os::raw::c_int,
            height: ::std::os::raw::c_int,
        ),
    >,
    #[doc = " Callback to negotiate the pixel format. Decoding only, may be set by the\n caller before avcodec_open2().\n\n Called by some decoders to select the pixel format that will be used for\n the output frames. This is mainly used to set up hardware acceleration,\n then the provided format list contains the corresponding hwaccel pixel\n formats alongside the \"software\" one. The software pixel format may also\n be retrieved from \\ref sw_pix_fmt.\n\n This callback will be called when the coded frame properties (such as\n resolution, pixel format, etc.) change and more than one output format is\n supported for those new properties. If a hardware pixel format is chosen\n and initialization for it fails, the callback may be called again\n immediately.\n\n This callback may be called from different threads if the decoder is\n multi-threaded, but not from more than one thread simultaneously.\n\n @param fmt list of formats which may be used in the current\n            configuration, terminated by AV_PIX_FMT_NONE.\n @warning Behavior is undefined if the callback returns a value other\n          than one of the formats in fmt or AV_PIX_FMT_NONE.\n @return the chosen format or AV_PIX_FMT_NONE"]
    pub get_format: ::std::option::Option<
        unsafe extern "C" fn(s: *mut AVCodecContext, fmt: *const AVPixelFormat) -> AVPixelFormat,
    >,
    #[doc = " maximum number of B-frames between non-B-frames\n Note: The output will be delayed by max_b_frames+1 relative to the input.\n - encoding: Set by user.\n - decoding: unused"]
    pub max_b_frames: ::std::os::raw::c_int,
    #[doc = " qscale factor between IP and B-frames\n If > 0 then the last P-frame quantizer will be used (q= lastp_q*factor+offset).\n If < 0 then normal ratecontrol will be done (q= -normal_q*factor+offset).\n - encoding: Set by user.\n - decoding: unused"]
    pub b_quant_factor: f32,
    #[doc = " qscale offset between IP and B-frames\n - encoding: Set by user.\n - decoding: unused"]
    pub b_quant_offset: f32,
    #[doc = " qscale factor between P- and I-frames\n If > 0 then the last P-frame quantizer will be used (q = lastp_q * factor + offset).\n If < 0 then normal ratecontrol will be done (q= -normal_q*factor+offset).\n - encoding: Set by user.\n - decoding: unused"]
    pub i_quant_factor: f32,
    #[doc = " qscale offset between P and I-frames\n - encoding: Set by user.\n - decoding: unused"]
    pub i_quant_offset: f32,
    #[doc = " luminance masking (0-> disabled)\n - encoding: Set by user.\n - decoding: unused"]
    pub lumi_masking: f32,
    #[doc = " temporary complexity masking (0-> disabled)\n - encoding: Set by user.\n - decoding: unused"]
    pub temporal_cplx_masking: f32,
    #[doc = " spatial complexity masking (0-> disabled)\n - encoding: Set by user.\n - decoding: unused"]
    pub spatial_cplx_masking: f32,
    #[doc = " p block masking (0-> disabled)\n - encoding: Set by user.\n - decoding: unused"]
    pub p_masking: f32,
    #[doc = " darkness masking (0-> disabled)\n - encoding: Set by user.\n - decoding: unused"]
    pub dark_masking: f32,
    #[doc = " noise vs. sse weight for the nsse comparison function\n - encoding: Set by user.\n - decoding: unused"]
    pub nsse_weight: ::std::os::raw::c_int,
    #[doc = " motion estimation comparison function\n - encoding: Set by user.\n - decoding: unused"]
    pub me_cmp: ::std::os::raw::c_int,
    #[doc = " subpixel motion estimation comparison function\n - encoding: Set by user.\n - decoding: unused"]
    pub me_sub_cmp: ::std::os::raw::c_int,
    #[doc = " macroblock comparison function (not supported yet)\n - encoding: Set by user.\n - decoding: unused"]
    pub mb_cmp: ::std::os::raw::c_int,
    #[doc = " interlaced DCT comparison function\n - encoding: Set by user.\n - decoding: unused"]
    pub ildct_cmp: ::std::os::raw::c_int,
    #[doc = " ME diamond size & shape\n - encoding: Set by user.\n - decoding: unused"]
    pub dia_size: ::std::os::raw::c_int,
    #[doc = " amount of previous MV predictors (2a+1 x 2a+1 square)\n - encoding: Set by user.\n - decoding: unused"]
    pub last_predictor_count: ::std::os::raw::c_int,
    #[doc = " motion estimation prepass comparison function\n - encoding: Set by user.\n - decoding: unused"]
    pub me_pre_cmp: ::std::os::raw::c_int,
    #[doc = " ME prepass diamond size & shape\n - encoding: Set by user.\n - decoding: unused"]
    pub pre_dia_size: ::std::os::raw::c_int,
    #[doc = " subpel ME quality\n - encoding: Set by user.\n - decoding: unused"]
    pub me_subpel_quality: ::std::os::raw::c_int,
    #[doc = " maximum motion estimation search range in subpel units\n If 0 then no limit.\n\n - encoding: Set by user.\n - decoding: unused"]
    pub me_range: ::std::os::raw::c_int,
    #[doc = " macroblock decision mode\n - encoding: Set by user.\n - decoding: unused"]
    pub mb_decision: ::std::os::raw::c_int,
    #[doc = " custom intra quantization matrix\n Must be allocated with the av_malloc() family of functions, and will be freed in\n avcodec_free_context().\n - encoding: Set/allocated by user, freed by libavcodec. Can be NULL.\n - decoding: Set/allocated/freed by libavcodec."]
    pub intra_matrix: *mut u16,
    #[doc = " custom inter quantization matrix\n Must be allocated with the av_malloc() family of functions, and will be freed in\n avcodec_free_context().\n - encoding: Set/allocated by user, freed by libavcodec. Can be NULL.\n - decoding: Set/allocated/freed by libavcodec."]
    pub inter_matrix: *mut u16,
    #[doc = " custom intra quantization matrix\n - encoding: Set by user, can be NULL.\n - decoding: unused."]
    pub chroma_intra_matrix: *mut u16,
    #[doc = " precision of the intra DC coefficient - 8\n - encoding: Set by user.\n - decoding: Set by libavcodec"]
    pub intra_dc_precision: ::std::os::raw::c_int,
    #[doc = " minimum MB Lagrange multiplier\n - encoding: Set by user.\n - decoding: unused"]
    pub mb_lmin: ::std::os::raw::c_int,
    #[doc = " maximum MB Lagrange multiplier\n - encoding: Set by user.\n - decoding: unused"]
    pub mb_lmax: ::std::os::raw::c_int,
    #[doc = " - encoding: Set by user.\n - decoding: unused"]
    pub bidir_refine: ::std::os::raw::c_int,
    #[doc = " minimum GOP size\n - encoding: Set by user.\n - decoding: unused"]
    pub keyint_min: ::std::os::raw::c_int,
    #[doc = " the number of pictures in a group of pictures, or 0 for intra_only\n - encoding: Set by user.\n - decoding: unused"]
    pub gop_size: ::std::os::raw::c_int,
    #[doc = " Note: Value depends upon the compare function used for fullpel ME.\n - encoding: Set by user.\n - decoding: unused"]
    pub mv0_threshold: ::std::os::raw::c_int,
    #[doc = " Number of slices.\n Indicates number of picture subdivisions. Used for parallelized\n decoding.\n - encoding: Set by user\n - decoding: unused"]
    pub slices: ::std::os::raw::c_int,
    #[doc = "< samples per second"]
    pub sample_rate: ::std::os::raw::c_int,
    #[doc = "< sample format"]
    pub sample_fmt: AVSampleFormat,
    #[doc = " Audio channel layout.\n - encoding: must be set by the caller, to one of AVCodec.ch_layouts.\n - decoding: may be set by the caller if known e.g. from the container.\n             The decoder can then override during decoding as needed."]
    pub ch_layout: AVChannelLayout,
    #[doc = " Number of samples per channel in an audio frame.\n\n - encoding: set by libavcodec in avcodec_open2(). Each submitted frame\n   except the last must contain exactly frame_size samples per channel.\n   May be 0 when the codec has AV_CODEC_CAP_VARIABLE_FRAME_SIZE set, then the\n   frame size is not restricted.\n - decoding: may be set by some decoders to indicate constant frame size"]
    pub frame_size: ::std::os::raw::c_int,
    #[doc = " number of bytes per packet if constant and known or 0\n Used by some WAV based audio codecs."]
    pub block_align: ::std::os::raw::c_int,
    #[doc = " Audio cutoff bandwidth (0 means \"automatic\")\n - encoding: Set by user.\n - decoding: unused"]
    pub cutoff: ::std::os::raw::c_int,
    #[doc = " Type of service that the audio stream conveys.\n - encoding: Set by user.\n - decoding: Set by libavcodec."]
    pub audio_service_type: AVAudioServiceType,
    #[doc = " desired sample format\n - encoding: Not used.\n - decoding: Set by user.\n Decoder will decode to this format if it can."]
    pub request_sample_fmt: AVSampleFormat,
    #[doc = " Audio only. The number of \"priming\" samples (padding) inserted by the\n encoder at the beginning of the audio. I.e. this number of leading\n decoded samples must be discarded by the caller to get the original audio\n without leading padding.\n\n - decoding: unused\n - encoding: Set by libavcodec. The timestamps on the output packets are\n             adjusted by the encoder so that they always refer to the\n             first sample of the data actually contained in the packet,\n             including any added padding.  E.g. if the timebase is\n             1/samplerate and the timestamp of the first input sample is\n             0, the timestamp of the first output packet will be\n             -initial_padding."]
    pub initial_padding: ::std::os::raw::c_int,
    #[doc = " Audio only. The amount of padding (in samples) appended by the encoder to\n the end of the audio. I.e. this number of decoded samples must be\n discarded by the caller from the end of the stream to get the original\n audio without any trailing padding.\n\n - decoding: unused\n - encoding: unused"]
    pub trailing_padding: ::std::os::raw::c_int,
    #[doc = " Number of samples to skip after a discontinuity\n - decoding: unused\n - encoding: set by libavcodec"]
    pub seek_preroll: ::std::os::raw::c_int,
    #[doc = " This callback is called at the beginning of each frame to get data\n buffer(s) for it. There may be one contiguous buffer for all the data or\n there may be a buffer per each data plane or anything in between. What\n this means is, you may set however many entries in buf[] you feel necessary.\n Each buffer must be reference-counted using the AVBuffer API (see description\n of buf[] below).\n\n The following fields will be set in the frame before this callback is\n called:\n - format\n - width, height (video only)\n - sample_rate, channel_layout, nb_samples (audio only)\n Their values may differ from the corresponding values in\n AVCodecContext. This callback must use the frame values, not the codec\n context values, to calculate the required buffer size.\n\n This callback must fill the following fields in the frame:\n - data[]\n - linesize[]\n - extended_data:\n   * if the data is planar audio with more than 8 channels, then this\n     callback must allocate and fill extended_data to contain all pointers\n     to all data planes. data[] must hold as many pointers as it can.\n     extended_data must be allocated with av_malloc() and will be freed in\n     av_frame_unref().\n   * otherwise extended_data must point to data\n - buf[] must contain one or more pointers to AVBufferRef structures. Each of\n   the frame's data and extended_data pointers must be contained in these. That\n   is, one AVBufferRef for each allocated chunk of memory, not necessarily one\n   AVBufferRef per data[] entry. See: av_buffer_create(), av_buffer_alloc(),\n   and av_buffer_ref().\n - extended_buf and nb_extended_buf must be allocated with av_malloc() by\n   this callback and filled with the extra buffers if there are more\n   buffers than buf[] can hold. extended_buf will be freed in\n   av_frame_unref().\n\n If AV_CODEC_CAP_DR1 is not set then get_buffer2() must call\n avcodec_default_get_buffer2() instead of providing buffers allocated by\n some other means.\n\n Each data plane must be aligned to the maximum required by the target\n CPU.\n\n @see avcodec_default_get_buffer2()\n\n Video:\n\n If AV_GET_BUFFER_FLAG_REF is set in flags then the frame may be reused\n (read and/or written to if it is writable) later by libavcodec.\n\n avcodec_align_dimensions2() should be used to find the required width and\n height, as they normally need to be rounded up to the next multiple of 16.\n\n Some decoders do not support linesizes changing between frames.\n\n If frame multithreading is used, this callback may be called from a\n different thread, but not from more than one at once. Does not need to be\n reentrant.\n\n @see avcodec_align_dimensions2()\n\n Audio:\n\n Decoders request a buffer of a particular size by setting\n AVFrame.nb_samples prior to calling get_buffer2(). The decoder may,\n however, utilize only part of the buffer by setting AVFrame.nb_samples\n to a smaller value in the output frame.\n\n As a convenience, av_samples_get_buffer_size() and\n av_samples_fill_arrays() in libavutil may be used by custom get_buffer2()\n functions to find the required data size and to fill data pointers and\n linesize. In AVFrame.linesize, only linesize[0] may be set for audio\n since all planes must be the same size.\n\n @see av_samples_get_buffer_size(), av_samples_fill_arrays()\n\n - encoding: unused\n - decoding: Set by libavcodec, user can override."]
    pub get_buffer2: ::std::option::Option<
        unsafe extern "C" fn(
            s: *mut AVCodecContext,
            frame: *mut AVFrame,
            flags: ::std::os::raw::c_int,
        ) -> ::std::os::raw::c_int,
    >,
    #[doc = " number of bits the bitstream is allowed to diverge from the reference.\n           the reference can be CBR (for CBR pass1) or VBR (for pass2)\n - encoding: Set by user; unused for constant quantizer encoding.\n - decoding: unused"]
    pub bit_rate_tolerance: ::std::os::raw::c_int,
    #[doc = " Global quality for codecs which cannot change it per frame.\n This should be proportional to MPEG-1/2/4 qscale.\n - encoding: Set by user.\n - decoding: unused"]
    pub global_quality: ::std::os::raw::c_int,
    #[doc = " - encoding: Set by user.\n - decoding: unused"]
    pub compression_level: ::std::os::raw::c_int,
    #[doc = "< amount of qscale change between easy & hard scenes (0.0-1.0)"]
    pub qcompress: f32,
    #[doc = "< amount of qscale smoothing over time (0.0-1.0)"]
    pub qblur: f32,
    #[doc = " minimum quantizer\n - encoding: Set by user.\n - decoding: unused"]
    pub qmin: ::std::os::raw::c_int,
    #[doc = " maximum quantizer\n - encoding: Set by user.\n - decoding: unused"]
    pub qmax: ::std::os::raw::c_int,
    #[doc = " maximum quantizer difference between frames\n - encoding: Set by user.\n - decoding: unused"]
    pub max_qdiff: ::std::os::raw::c_int,
    #[doc = " decoder bitstream buffer size\n - encoding: Set by user.\n - decoding: May be set by libavcodec."]
    pub rc_buffer_size: ::std::os::raw::c_int,
    #[doc = " ratecontrol override, see RcOverride\n - encoding: Allocated/set/freed by user.\n - decoding: unused"]
    pub rc_override_count: ::std::os::raw::c_int,
    pub rc_override: *mut RcOverride,
    #[doc = " maximum bitrate\n - encoding: Set by user.\n - decoding: Set by user, may be overwritten by libavcodec."]
    pub rc_max_rate: i64,
    #[doc = " minimum bitrate\n - encoding: Set by user.\n - decoding: unused"]
    pub rc_min_rate: i64,
    #[doc = " Ratecontrol attempt to use, at maximum, <value> of what can be used without an underflow.\n - encoding: Set by user.\n - decoding: unused."]
    pub rc_max_available_vbv_use: f32,
    #[doc = " Ratecontrol attempt to use, at least, <value> times the amount needed to prevent a vbv overflow.\n - encoding: Set by user.\n - decoding: unused."]
    pub rc_min_vbv_overflow_use: f32,
    #[doc = " Number of bits which should be loaded into the rc buffer before decoding starts.\n - encoding: Set by user.\n - decoding: unused"]
    pub rc_initial_buffer_occupancy: ::std::os::raw::c_int,
    #[doc = " trellis RD quantization\n - encoding: Set by user.\n - decoding: unused"]
    pub trellis: ::std::os::raw::c_int,
    #[doc = " pass1 encoding statistics output buffer\n - encoding: Set by libavcodec.\n - decoding: unused"]
    pub stats_out: *mut ::std::os::raw::c_char,
    #[doc = " pass2 encoding statistics input buffer\n Concatenated stuff from stats_out of pass1 should be placed here.\n - encoding: Allocated/set/freed by user.\n - decoding: unused"]
    pub stats_in: *mut ::std::os::raw::c_char,
    #[doc = " Work around bugs in encoders which sometimes cannot be detected automatically.\n - encoding: Set by user\n - decoding: Set by user"]
    pub workaround_bugs: ::std::os::raw::c_int,
    #[doc = " strictly follow the standard (MPEG-4, ...).\n - encoding: Set by user.\n - decoding: Set by user.\n Setting this to STRICT or higher means the encoder and decoder will\n generally do stupid things, whereas setting it to unofficial or lower\n will mean the encoder might produce output that is not supported by all\n spec-compliant decoders. Decoders don't differentiate between normal,\n unofficial and experimental (that is, they always try to decode things\n when they can) unless they are explicitly asked to behave stupidly\n (=strictly conform to the specs)\n This may only be set to one of the FF_COMPLIANCE_* values in defs.h."]
    pub strict_std_compliance: ::std::os::raw::c_int,
    #[doc = " error concealment flags\n - encoding: unused\n - decoding: Set by user."]
    pub error_concealment: ::std::os::raw::c_int,
    #[doc = " debug\n - encoding: Set by user.\n - decoding: Set by user."]
    pub debug: ::std::os::raw::c_int,
    #[doc = " Error recognition; may misdetect some more or less valid parts as errors.\n This is a bitfield of the AV_EF_* values defined in defs.h.\n\n - encoding: Set by user.\n - decoding: Set by user."]
    pub err_recognition: ::std::os::raw::c_int,
    #[doc = " Hardware accelerator in use\n - encoding: unused.\n - decoding: Set by libavcodec"]
    pub hwaccel: *const AVHWAccel,
    #[doc = " Legacy hardware accelerator context.\n\n For some hardware acceleration methods, the caller may use this field to\n signal hwaccel-specific data to the codec. The struct pointed to by this\n pointer is hwaccel-dependent and defined in the respective header. Please\n refer to the FFmpeg HW accelerator documentation to know how to fill\n this.\n\n In most cases this field is optional - the necessary information may also\n be provided to libavcodec through @ref hw_frames_ctx or @ref\n hw_device_ctx (see avcodec_get_hw_config()). However, in some cases it\n may be the only method of signalling some (optional) information.\n\n The struct and its contents are owned by the caller.\n\n - encoding: May be set by the caller before avcodec_open2(). Must remain\n             valid until avcodec_free_context().\n - decoding: May be set by the caller in the get_format() callback.\n             Must remain valid until the next get_format() call,\n             or avcodec_free_context() (whichever comes first)."]
    pub hwaccel_context: *mut ::std::os::raw::c_void,
    #[doc = " A reference to the AVHWFramesContext describing the input (for encoding)\n or output (decoding) frames. The reference is set by the caller and\n afterwards owned (and freed) by libavcodec - it should never be read by\n the caller after being set.\n\n - decoding: This field should be set by the caller from the get_format()\n             callback. The previous reference (if any) will always be\n             unreffed by libavcodec before the get_format() call.\n\n             If the default get_buffer2() is used with a hwaccel pixel\n             format, then this AVHWFramesContext will be used for\n             allocating the frame buffers.\n\n - encoding: For hardware encoders configured to use a hwaccel pixel\n             format, this field should be set by the caller to a reference\n             to the AVHWFramesContext describing input frames.\n             AVHWFramesContext.format must be equal to\n             AVCodecContext.pix_fmt.\n\n             This field should be set before avcodec_open2() is called."]
    pub hw_frames_ctx: *mut AVBufferRef,
    #[doc = " A reference to the AVHWDeviceContext describing the device which will\n be used by a hardware encoder/decoder.  The reference is set by the\n caller and afterwards owned (and freed) by libavcodec.\n\n This should be used if either the codec device does not require\n hardware frames or any that are used are to be allocated internally by\n libavcodec.  If the user wishes to supply any of the frames used as\n encoder input or decoder output then hw_frames_ctx should be used\n instead.  When hw_frames_ctx is set in get_format() for a decoder, this\n field will be ignored while decoding the associated stream segment, but\n may again be used on a following one after another get_format() call.\n\n For both encoders and decoders this field should be set before\n avcodec_open2() is called and must not be written to thereafter.\n\n Note that some decoders may require this field to be set initially in\n order to support hw_frames_ctx at all - in that case, all frames\n contexts used must be created on the same device."]
    pub hw_device_ctx: *mut AVBufferRef,
    #[doc = " Bit set of AV_HWACCEL_FLAG_* flags, which affect hardware accelerated\n decoding (if active).\n - encoding: unused\n - decoding: Set by user (either before avcodec_open2(), or in the\n             AVCodecContext.get_format callback)"]
    pub hwaccel_flags: ::std::os::raw::c_int,
    #[doc = " Video decoding only.  Sets the number of extra hardware frames which\n the decoder will allocate for use by the caller.  This must be set\n before avcodec_open2() is called.\n\n Some hardware decoders require all frames that they will use for\n output to be defined in advance before decoding starts.  For such\n decoders, the hardware frame pool must therefore be of a fixed size.\n The extra frames set here are on top of any number that the decoder\n needs internally in order to operate normally (for example, frames\n used as reference pictures)."]
    pub extra_hw_frames: ::std::os::raw::c_int,
    #[doc = " error\n - encoding: Set by libavcodec if flags & AV_CODEC_FLAG_PSNR.\n - decoding: unused"]
    pub error: [u64; 8usize],
    #[doc = " DCT algorithm, see FF_DCT_* below\n - encoding: Set by user.\n - decoding: unused"]
    pub dct_algo: ::std::os::raw::c_int,
    #[doc = " IDCT algorithm, see FF_IDCT_* below.\n - encoding: Set by user.\n - decoding: Set by user."]
    pub idct_algo: ::std::os::raw::c_int,
    #[doc = " bits per sample/pixel from the demuxer (needed for huffyuv).\n - encoding: Set by libavcodec.\n - decoding: Set by user."]
    pub bits_per_coded_sample: ::std::os::raw::c_int,
    #[doc = " Bits per sample/pixel of internal libavcodec pixel/sample format.\n - encoding: set by user.\n - decoding: set by libavcodec."]
    pub bits_per_raw_sample: ::std::os::raw::c_int,
    #[doc = " thread count\n is used to decide how many independent tasks should be passed to execute()\n - encoding: Set by user.\n - decoding: Set by user."]
    pub thread_count: ::std::os::raw::c_int,
    #[doc = " Which multithreading methods to use.\n Use of FF_THREAD_FRAME will increase decoding delay by one frame per thread,\n so clients which cannot provide future frames should not use it.\n\n - encoding: Set by user, otherwise the default is used.\n - decoding: Set by user, otherwise the default is used."]
    pub thread_type: ::std::os::raw::c_int,
    #[doc = " Which multithreading methods are in use by the codec.\n - encoding: Set by libavcodec.\n - decoding: Set by libavcodec."]
    pub active_thread_type: ::std::os::raw::c_int,
    #[doc = " The codec may call this to execute several independent things.\n It will return only after finishing all tasks.\n The user may replace this with some multithreaded implementation,\n the default implementation will execute the parts serially.\n @param count the number of things to execute\n - encoding: Set by libavcodec, user can override.\n - decoding: Set by libavcodec, user can override."]
    pub execute: ::std::option::Option<
        unsafe extern "C" fn(
            c: *mut AVCodecContext,
            func: ::std::option::Option<
                unsafe extern "C" fn(
                    c2: *mut AVCodecContext,
                    arg: *mut ::std::os::raw::c_void,
                ) -> ::std::os::raw::c_int,
            >,
            arg2: *mut ::std::os::raw::c_void,
            ret: *mut ::std::os::raw::c_int,
            count: ::std::os::raw::c_int,
            size: ::std::os::raw::c_int,
        ) -> ::std::os::raw::c_int,
    >,
    #[doc = " The codec may call this to execute several independent things.\n It will return only after finishing all tasks.\n The user may replace this with some multithreaded implementation,\n the default implementation will execute the parts serially.\n @param c context passed also to func\n @param count the number of things to execute\n @param arg2 argument passed unchanged to func\n @param ret return values of executed functions, must have space for \"count\" values. May be NULL.\n @param func function that will be called count times, with jobnr from 0 to count-1.\n             threadnr will be in the range 0 to c->thread_count-1 < MAX_THREADS and so that no\n             two instances of func executing at the same time will have the same threadnr.\n @return always 0 currently, but code should handle a future improvement where when any call to func\n         returns < 0 no further calls to func may be done and < 0 is returned.\n - encoding: Set by libavcodec, user can override.\n - decoding: Set by libavcodec, user can override."]
    pub execute2: ::std::option::Option<
        unsafe extern "C" fn(
            c: *mut AVCodecContext,
            func: ::std::option::Option<
                unsafe extern "C" fn(
                    c2: *mut AVCodecContext,
                    arg: *mut ::std::os::raw::c_void,
                    jobnr: ::std::os::raw::c_int,
                    threadnr: ::std::os::raw::c_int,
                ) -> ::std::os::raw::c_int,
            >,
            arg2: *mut ::std::os::raw::c_void,
            ret: *mut ::std::os::raw::c_int,
            count: ::std::os::raw::c_int,
        ) -> ::std::os::raw::c_int,
    >,
    #[doc = " profile\n - encoding: Set by user.\n - decoding: Set by libavcodec.\n See the AV_PROFILE_* defines in defs.h."]
    pub profile: ::std::os::raw::c_int,
    #[doc = " Encoding level descriptor.\n - encoding: Set by user, corresponds to a specific level defined by the\n   codec, usually corresponding to the profile level, if not specified it\n   is set to FF_LEVEL_UNKNOWN.\n - decoding: Set by libavcodec.\n See AV_LEVEL_* in defs.h."]
    pub level: ::std::os::raw::c_int,
    #[doc = " Properties of the stream that gets decoded\n - encoding: unused\n - decoding: set by libavcodec"]
    pub properties: ::std::os::raw::c_uint,
    #[doc = " Skip loop filtering for selected frames.\n - encoding: unused\n - decoding: Set by user."]
    pub skip_loop_filter: AVDiscard,
    #[doc = " Skip IDCT/dequantization for selected frames.\n - encoding: unused\n - decoding: Set by user."]
    pub skip_idct: AVDiscard,
    #[doc = " Skip decoding for selected frames.\n - encoding: unused\n - decoding: Set by user."]
    pub skip_frame: AVDiscard,
    #[doc = " Skip processing alpha if supported by codec.\n Note that if the format uses pre-multiplied alpha (common with VP6,\n and recommended due to better video quality/compression)\n the image will look as if alpha-blended onto a black background.\n However for formats that do not use pre-multiplied alpha\n there might be serious artefacts (though e.g. libswscale currently\n assumes pre-multiplied alpha anyway).\n\n - decoding: set by user\n - encoding: unused"]
    pub skip_alpha: ::std::os::raw::c_int,
    #[doc = " Number of macroblock rows at the top which are skipped.\n - encoding: unused\n - decoding: Set by user."]
    pub skip_top: ::std::os::raw::c_int,
    #[doc = " Number of macroblock rows at the bottom which are skipped.\n - encoding: unused\n - decoding: Set by user."]
    pub skip_bottom: ::std::os::raw::c_int,
    #[doc = " low resolution decoding, 1-> 1/2 size, 2->1/4 size\n - encoding: unused\n - decoding: Set by user."]
    pub lowres: ::std::os::raw::c_int,
    #[doc = " AVCodecDescriptor\n - encoding: unused.\n - decoding: set by libavcodec."]
    pub codec_descriptor: *const AVCodecDescriptor,
    #[doc = " Character encoding of the input subtitles file.\n - decoding: set by user\n - encoding: unused"]
    pub sub_charenc: *mut ::std::os::raw::c_char,
    #[doc = " Subtitles character encoding mode. Formats or codecs might be adjusting\n this setting (if they are doing the conversion themselves for instance).\n - decoding: set by libavcodec\n - encoding: unused"]
    pub sub_charenc_mode: ::std::os::raw::c_int,
    #[doc = " Header containing style information for text subtitles.\n For SUBTITLE_ASS subtitle type, it should contain the whole ASS\n [Script Info] and [V4+ Styles] section, plus the [Events] line and\n the Format line following. It shouldn't include any Dialogue line.\n - encoding: Set/allocated/freed by user (before avcodec_open2())\n - decoding: Set/allocated/freed by libavcodec (by avcodec_open2())"]
    pub subtitle_header_size: ::std::os::raw::c_int,
    pub subtitle_header: *mut u8,
    #[doc = " dump format separator.\n can be \", \" or \"\\n      \" or anything else\n - encoding: Set by user.\n - decoding: Set by user."]
    pub dump_separator: *mut u8,
    #[doc = " ',' separated list of allowed decoders.\n If NULL then all are allowed\n - encoding: unused\n - decoding: set by user"]
    pub codec_whitelist: *mut ::std::os::raw::c_char,
    #[doc = " Additional data associated with the entire coded stream.\n\n - decoding: may be set by user before calling avcodec_open2().\n - encoding: may be set by libavcodec after avcodec_open2()."]
    pub coded_side_data: *mut AVPacketSideData,
    pub nb_coded_side_data: ::std::os::raw::c_int,
    #[doc = " Bit set of AV_CODEC_EXPORT_DATA_* flags, which affects the kind of\n metadata exported in frame, packet, or coded stream side data by\n decoders and encoders.\n\n - decoding: set by user\n - encoding: set by user"]
    pub export_side_data: ::std::os::raw::c_int,
    #[doc = " The number of pixels per image to maximally accept.\n\n - decoding: set by user\n - encoding: set by user"]
    pub max_pixels: i64,
    #[doc = " Video decoding only. Certain video codecs support cropping, meaning that\n only a sub-rectangle of the decoded frame is intended for display.  This\n option controls how cropping is handled by libavcodec.\n\n When set to 1 (the default), libavcodec will apply cropping internally.\n I.e. it will modify the output frame width/height fields and offset the\n data pointers (only by as much as possible while preserving alignment, or\n by the full amount if the AV_CODEC_FLAG_UNALIGNED flag is set) so that\n the frames output by the decoder refer only to the cropped area. The\n crop_* fields of the output frames will be zero.\n\n When set to 0, the width/height fields of the output frames will be set\n to the coded dimensions and the crop_* fields will describe the cropping\n rectangle. Applying the cropping is left to the caller.\n\n @warning When hardware acceleration with opaque output frames is used,\n libavcodec is unable to apply cropping from the top/left border.\n\n @note when this option is set to zero, the width/height fields of the\n AVCodecContext and output AVFrames have different meanings. The codec\n context fields store display dimensions (with the coded dimensions in\n coded_width/height), while the frame fields store the coded dimensions\n (with the display dimensions being determined by the crop_* fields)."]
    pub apply_cropping: ::std::os::raw::c_int,
    #[doc = " The percentage of damaged samples to discard a frame.\n\n - decoding: set by user\n - encoding: unused"]
    pub discard_damaged_percentage: ::std::os::raw::c_int,
    #[doc = " The number of samples per frame to maximally accept.\n\n - decoding: set by user\n - encoding: set by user"]
    pub max_samples: i64,
    #[doc = " This callback is called at the beginning of each packet to get a data\n buffer for it.\n\n The following field will be set in the packet before this callback is\n called:\n - size\n This callback must use the above value to calculate the required buffer size,\n which must padded by at least AV_INPUT_BUFFER_PADDING_SIZE bytes.\n\n In some specific cases, the encoder may not use the entire buffer allocated by this\n callback. This will be reflected in the size value in the packet once returned by\n avcodec_receive_packet().\n\n This callback must fill the following fields in the packet:\n - data: alignment requirements for AVPacket apply, if any. Some architectures and\n   encoders may benefit from having aligned data.\n - buf: must contain a pointer to an AVBufferRef structure. The packet's\n   data pointer must be contained in it. See: av_buffer_create(), av_buffer_alloc(),\n   and av_buffer_ref().\n\n If AV_CODEC_CAP_DR1 is not set then get_encode_buffer() must call\n avcodec_default_get_encode_buffer() instead of providing a buffer allocated by\n some other means.\n\n The flags field may contain a combination of AV_GET_ENCODE_BUFFER_FLAG_ flags.\n They may be used for example to hint what use the buffer may get after being\n created.\n Implementations of this callback may ignore flags they don't understand.\n If AV_GET_ENCODE_BUFFER_FLAG_REF is set in flags then the packet may be reused\n (read and/or written to if it is writable) later by libavcodec.\n\n This callback must be thread-safe, as when frame threading is used, it may\n be called from multiple threads simultaneously.\n\n @see avcodec_default_get_encode_buffer()\n\n - encoding: Set by libavcodec, user can override.\n - decoding: unused"]
    pub get_encode_buffer: ::std::option::Option<
        unsafe extern "C" fn(
            s: *mut AVCodecContext,
            pkt: *mut AVPacket,
            flags: ::std::os::raw::c_int,
        ) -> ::std::os::raw::c_int,
    >,
    #[doc = " Frame counter, set by libavcodec.\n\n - decoding: total number of frames returned from the decoder so far.\n - encoding: total number of frames passed to the encoder so far.\n\n   @note the counter is not incremented if encoding/decoding resulted in\n   an error."]
    pub frame_num: i64,
    #[doc = " Decoding only. May be set by the caller before avcodec_open2() to an\n av_malloc()'ed array (or via AVOptions). Owned and freed by the decoder\n afterwards.\n\n Side data attached to decoded frames may come from several sources:\n 1. coded_side_data, which the decoder will for certain types translate\n    from packet-type to frame-type and attach to frames;\n 2. side data attached to an AVPacket sent for decoding (same\n    considerations as above);\n 3. extracted from the coded bytestream.\n The first two cases are supplied by the caller and typically come from a\n container.\n\n This array configures decoder behaviour in cases when side data of the\n same type is present both in the coded bytestream and in the\n user-supplied side data (items 1. and 2. above). In all cases, at most\n one instance of each side data type will be attached to output frames. By\n default it will be the bytestream side data. Adding an\n AVPacketSideDataType value to this array will flip the preference for\n this type, thus making the decoder prefer user-supplied side data over\n bytestream. In case side data of the same type is present both in\n coded_data and attacked to a packet, the packet instance always has\n priority.\n\n The array may also contain a single -1, in which case the preference is\n switched for all side data types."]
    pub side_data_prefer_packet: *mut ::std::os::raw::c_int,
    #[doc = " Number of entries in side_data_prefer_packet."]
    pub nb_side_data_prefer_packet: ::std::os::raw::c_uint,
    #[doc = " Array containing static side data, such as HDR10 CLL / MDCV structures.\n Side data entries should be allocated by usage of helpers defined in\n libavutil/frame.h.\n\n - encoding: may be set by user before calling avcodec_open2() for\n             encoder configuration. Afterwards owned and freed by the\n             encoder.\n - decoding: may be set by libavcodec in avcodec_open2()."]
    pub decoded_side_data: *mut *mut AVFrameSideData,
    pub nb_decoded_side_data: ::std::os::raw::c_int,
}
impl Default for AVCodecContext {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = " @defgroup lavc_hwaccel AVHWAccel\n\n @note  Nothing in this structure should be accessed by the user.  At some\n        point in future it will not be externally visible at all.\n\n @{"]
#[repr(C)]
#[derive(Debug, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVHWAccel {
    #[doc = " Name of the hardware accelerated codec.\n The name is globally unique among encoders and among decoders (but an\n encoder and a decoder can share the same name)."]
    pub name: *const ::std::os::raw::c_char,
    #[doc = " Type of codec implemented by the hardware accelerator.\n\n See AVMEDIA_TYPE_xxx"]
    pub type_: AVMediaType,
    #[doc = " Codec implemented by the hardware accelerator.\n\n See AV_CODEC_ID_xxx"]
    pub id: AVCodecID,
    #[doc = " Supported pixel format.\n\n Only hardware accelerated formats are supported here."]
    pub pix_fmt: AVPixelFormat,
    #[doc = " Hardware accelerated codec capabilities.\n see AV_HWACCEL_CODEC_CAP_*"]
    pub capabilities: ::std::os::raw::c_int,
}
impl Default for AVHWAccel {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub const AVSubtitleType_SUBTITLE_NONE: AVSubtitleType = 0;
#[doc = "< A bitmap, pict will be set"]
pub const AVSubtitleType_SUBTITLE_BITMAP: AVSubtitleType = 1;
#[doc = " Plain text, the text field must be set by the decoder and is\n authoritative. ass and pict fields may contain approximations."]
pub const AVSubtitleType_SUBTITLE_TEXT: AVSubtitleType = 2;
#[doc = " Formatted text, the ass field must be set by the decoder and is\n authoritative. pict and text fields may contain approximations."]
pub const AVSubtitleType_SUBTITLE_ASS: AVSubtitleType = 3;
#[doc = " @}"]
pub type AVSubtitleType = ::std::os::raw::c_uint;
#[repr(C)]
#[derive(Debug, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVSubtitleRect {
    #[doc = "< top left corner  of pict, undefined when pict is not set"]
    pub x: ::std::os::raw::c_int,
    #[doc = "< top left corner  of pict, undefined when pict is not set"]
    pub y: ::std::os::raw::c_int,
    #[doc = "< width            of pict, undefined when pict is not set"]
    pub w: ::std::os::raw::c_int,
    #[doc = "< height           of pict, undefined when pict is not set"]
    pub h: ::std::os::raw::c_int,
    #[doc = "< number of colors in pict, undefined when pict is not set"]
    pub nb_colors: ::std::os::raw::c_int,
    #[doc = " data+linesize for the bitmap of this subtitle.\n Can be set for text/ass as well once they are rendered."]
    pub data: [*mut u8; 4usize],
    pub linesize: [::std::os::raw::c_int; 4usize],
    pub flags: ::std::os::raw::c_int,
    pub type_: AVSubtitleType,
    #[doc = "< 0 terminated plain UTF-8 text"]
    pub text: *mut ::std::os::raw::c_char,
    #[doc = " 0 terminated ASS/SSA compatible event line.\n The presentation of this is unaffected by the other values in this\n struct."]
    pub ass: *mut ::std::os::raw::c_char,
}
impl Default for AVSubtitleRect {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Debug, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVSubtitle {
    pub format: u16,
    pub start_display_time: u32,
    pub end_display_time: u32,
    pub num_rects: ::std::os::raw::c_uint,
    pub rects: *mut *mut AVSubtitleRect,
    #[doc = "< Same as packet pts, in AV_TIME_BASE"]
    pub pts: i64,
}
impl Default for AVSubtitle {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
extern "C" {
    #[doc = " Return the LIBAVCODEC_VERSION_INT constant."]
    pub fn avcodec_version() -> ::std::os::raw::c_uint;
}
extern "C" {
    #[doc = " Return the libavcodec build-time configuration."]
    pub fn avcodec_configuration() -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Return the libavcodec license."]
    pub fn avcodec_license() -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Allocate an AVCodecContext and set its fields to default values. The\n resulting struct should be freed with avcodec_free_context().\n\n @param codec if non-NULL, allocate private data and initialize defaults\n              for the given codec. It is illegal to then call avcodec_open2()\n              with a different codec.\n              If NULL, then the codec-specific defaults won't be initialized,\n              which may result in suboptimal default settings (this is\n              important mainly for encoders, e.g. libx264).\n\n @return An AVCodecContext filled with default values or NULL on failure."]
    pub fn avcodec_alloc_context3(codec: *const AVCodec) -> *mut AVCodecContext;
}
extern "C" {
    #[doc = " Free the codec context and everything associated with it and write NULL to\n the provided pointer."]
    pub fn avcodec_free_context(avctx: *mut *mut AVCodecContext);
}
extern "C" {
    #[doc = " Get the AVClass for AVCodecContext. It can be used in combination with\n AV_OPT_SEARCH_FAKE_OBJ for examining options.\n\n @see av_opt_find()."]
    pub fn avcodec_get_class() -> *const AVClass;
}
extern "C" {
    #[doc = " Get the AVClass for AVSubtitleRect. It can be used in combination with\n AV_OPT_SEARCH_FAKE_OBJ for examining options.\n\n @see av_opt_find()."]
    pub fn avcodec_get_subtitle_rect_class() -> *const AVClass;
}
extern "C" {
    #[doc = " Fill the parameters struct based on the values from the supplied codec\n context. Any allocated fields in par are freed and replaced with duplicates\n of the corresponding fields in codec.\n\n @return >= 0 on success, a negative AVERROR code on failure"]
    pub fn avcodec_parameters_from_context(
        par: *mut AVCodecParameters,
        codec: *const AVCodecContext,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Fill the codec context based on the values from the supplied codec\n parameters. Any allocated fields in codec that have a corresponding field in\n par are freed and replaced with duplicates of the corresponding field in par.\n Fields in codec that do not have a counterpart in par are not touched.\n\n @return >= 0 on success, a negative AVERROR code on failure."]
    pub fn avcodec_parameters_to_context(
        codec: *mut AVCodecContext,
        par: *const AVCodecParameters,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Initialize the AVCodecContext to use the given AVCodec. Prior to using this\n function the context has to be allocated with avcodec_alloc_context3().\n\n The functions avcodec_find_decoder_by_name(), avcodec_find_encoder_by_name(),\n avcodec_find_decoder() and avcodec_find_encoder() provide an easy way for\n retrieving a codec.\n\n Depending on the codec, you might need to set options in the codec context\n also for decoding (e.g. width, height, or the pixel or audio sample format in\n the case the information is not available in the bitstream, as when decoding\n raw audio or video).\n\n Options in the codec context can be set either by setting them in the options\n AVDictionary, or by setting the values in the context itself, directly or by\n using the av_opt_set() API before calling this function.\n\n Example:\n @code\n av_dict_set(&opts, \"b\", \"2.5M\", 0);\n codec = avcodec_find_decoder(AV_CODEC_ID_H264);\n if (!codec)\n     exit(1);\n\n context = avcodec_alloc_context3(codec);\n\n if (avcodec_open2(context, codec, opts) < 0)\n     exit(1);\n @endcode\n\n In the case AVCodecParameters are available (e.g. when demuxing a stream\n using libavformat, and accessing the AVStream contained in the demuxer), the\n codec parameters can be copied to the codec context using\n avcodec_parameters_to_context(), as in the following example:\n\n @code\n AVStream *stream = ...;\n context = avcodec_alloc_context3(codec);\n if (avcodec_parameters_to_context(context, stream->codecpar) < 0)\n     exit(1);\n if (avcodec_open2(context, codec, NULL) < 0)\n     exit(1);\n @endcode\n\n @note Always call this function before using decoding routines (such as\n @ref avcodec_receive_frame()).\n\n @param avctx The context to initialize.\n @param codec The codec to open this context for. If a non-NULL codec has been\n              previously passed to avcodec_alloc_context3() or\n              for this context, then this parameter MUST be either NULL or\n              equal to the previously passed codec.\n @param options A dictionary filled with AVCodecContext and codec-private\n                options, which are set on top of the options already set in\n                avctx, can be NULL. On return this object will be filled with\n                options that were not found in the avctx codec context.\n\n @return zero on success, a negative value on error\n @see avcodec_alloc_context3(), avcodec_find_decoder(), avcodec_find_encoder(),\n      av_dict_set(), av_opt_set(), av_opt_find(), avcodec_parameters_to_context()"]
    pub fn avcodec_open2(
        avctx: *mut AVCodecContext,
        codec: *const AVCodec,
        options: *mut *mut AVDictionary,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Close a given AVCodecContext and free all the data associated with it\n (but not the AVCodecContext itself).\n\n Calling this function on an AVCodecContext that hasn't been opened will free\n the codec-specific data allocated in avcodec_alloc_context3() with a non-NULL\n codec. Subsequent calls will do nothing.\n\n @deprecated Do not use this function. Use avcodec_free_context() to destroy a\n codec context (either open or closed). Opening and closing a codec context\n multiple times is not supported anymore -- use multiple codec contexts\n instead."]
    pub fn avcodec_close(avctx: *mut AVCodecContext) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Free all allocated data in the given subtitle struct.\n\n @param sub AVSubtitle to free."]
    pub fn avsubtitle_free(sub: *mut AVSubtitle);
}
extern "C" {
    #[doc = " The default callback for AVCodecContext.get_buffer2(). It is made public so\n it can be called by custom get_buffer2() implementations for decoders without\n AV_CODEC_CAP_DR1 set."]
    pub fn avcodec_default_get_buffer2(
        s: *mut AVCodecContext,
        frame: *mut AVFrame,
        flags: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " The default callback for AVCodecContext.get_encode_buffer(). It is made public so\n it can be called by custom get_encode_buffer() implementations for encoders without\n AV_CODEC_CAP_DR1 set."]
    pub fn avcodec_default_get_encode_buffer(
        s: *mut AVCodecContext,
        pkt: *mut AVPacket,
        flags: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Modify width and height values so that they will result in a memory\n buffer that is acceptable for the codec if you do not use any horizontal\n padding.\n\n May only be used if a codec with AV_CODEC_CAP_DR1 has been opened."]
    pub fn avcodec_align_dimensions(
        s: *mut AVCodecContext,
        width: *mut ::std::os::raw::c_int,
        height: *mut ::std::os::raw::c_int,
    );
}
extern "C" {
    #[doc = " Modify width and height values so that they will result in a memory\n buffer that is acceptable for the codec if you also ensure that all\n line sizes are a multiple of the respective linesize_align[i].\n\n May only be used if a codec with AV_CODEC_CAP_DR1 has been opened."]
    pub fn avcodec_align_dimensions2(
        s: *mut AVCodecContext,
        width: *mut ::std::os::raw::c_int,
        height: *mut ::std::os::raw::c_int,
        linesize_align: *mut ::std::os::raw::c_int,
    );
}
extern "C" {
    #[doc = " Decode a subtitle message.\n Return a negative value on error, otherwise return the number of bytes used.\n If no subtitle could be decompressed, got_sub_ptr is zero.\n Otherwise, the subtitle is stored in *sub.\n Note that AV_CODEC_CAP_DR1 is not available for subtitle codecs. This is for\n simplicity, because the performance difference is expected to be negligible\n and reusing a get_buffer written for video codecs would probably perform badly\n due to a potentially very different allocation pattern.\n\n Some decoders (those marked with AV_CODEC_CAP_DELAY) have a delay between input\n and output. This means that for some packets they will not immediately\n produce decoded output and need to be flushed at the end of decoding to get\n all the decoded data. Flushing is done by calling this function with packets\n with avpkt->data set to NULL and avpkt->size set to 0 until it stops\n returning subtitles. It is safe to flush even those decoders that are not\n marked with AV_CODEC_CAP_DELAY, then no subtitles will be returned.\n\n @note The AVCodecContext MUST have been opened with @ref avcodec_open2()\n before packets may be fed to the decoder.\n\n @param avctx the codec context\n @param[out] sub The preallocated AVSubtitle in which the decoded subtitle will be stored,\n                 must be freed with avsubtitle_free if *got_sub_ptr is set.\n @param[in,out] got_sub_ptr Zero if no subtitle could be decompressed, otherwise, it is nonzero.\n @param[in] avpkt The input AVPacket containing the input buffer."]
    pub fn avcodec_decode_subtitle2(
        avctx: *mut AVCodecContext,
        sub: *mut AVSubtitle,
        got_sub_ptr: *mut ::std::os::raw::c_int,
        avpkt: *const AVPacket,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Supply raw packet data as input to a decoder.\n\n Internally, this call will copy relevant AVCodecContext fields, which can\n influence decoding per-packet, and apply them when the packet is actually\n decoded. (For example AVCodecContext.skip_frame, which might direct the\n decoder to drop the frame contained by the packet sent with this function.)\n\n @warning The input buffer, avpkt->data must be AV_INPUT_BUFFER_PADDING_SIZE\n          larger than the actual read bytes because some optimized bitstream\n          readers read 32 or 64 bits at once and could read over the end.\n\n @note The AVCodecContext MUST have been opened with @ref avcodec_open2()\n       before packets may be fed to the decoder.\n\n @param avctx codec context\n @param[in] avpkt The input AVPacket. Usually, this will be a single video\n                  frame, or several complete audio frames.\n                  Ownership of the packet remains with the caller, and the\n                  decoder will not write to the packet. The decoder may create\n                  a reference to the packet data (or copy it if the packet is\n                  not reference-counted).\n                  Unlike with older APIs, the packet is always fully consumed,\n                  and if it contains multiple frames (e.g. some audio codecs),\n                  will require you to call avcodec_receive_frame() multiple\n                  times afterwards before you can send a new packet.\n                  It can be NULL (or an AVPacket with data set to NULL and\n                  size set to 0); in this case, it is considered a flush\n                  packet, which signals the end of the stream. Sending the\n                  first flush packet will return success. Subsequent ones are\n                  unnecessary and will return AVERROR_EOF. If the decoder\n                  still has frames buffered, it will return them after sending\n                  a flush packet.\n\n @retval 0                 success\n @retval AVERROR(EAGAIN)   input is not accepted in the current state - user\n                           must read output with avcodec_receive_frame() (once\n                           all output is read, the packet should be resent,\n                           and the call will not fail with EAGAIN).\n @retval AVERROR_EOF       the decoder has been flushed, and no new packets can be\n                           sent to it (also returned if more than 1 flush\n                           packet is sent)\n @retval AVERROR(EINVAL)   codec not opened, it is an encoder, or requires flush\n @retval AVERROR(ENOMEM)   failed to add packet to internal queue, or similar\n @retval \"another negative error code\" legitimate decoding errors"]
    pub fn avcodec_send_packet(
        avctx: *mut AVCodecContext,
        avpkt: *const AVPacket,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Return decoded output data from a decoder or encoder (when the\n @ref AV_CODEC_FLAG_RECON_FRAME flag is used).\n\n @param avctx codec context\n @param frame This will be set to a reference-counted video or audio\n              frame (depending on the decoder type) allocated by the\n              codec. Note that the function will always call\n              av_frame_unref(frame) before doing anything else.\n\n @retval 0                success, a frame was returned\n @retval AVERROR(EAGAIN)  output is not available in this state - user must\n                          try to send new input\n @retval AVERROR_EOF      the codec has been fully flushed, and there will be\n                          no more output frames\n @retval AVERROR(EINVAL)  codec not opened, or it is an encoder without the\n                          @ref AV_CODEC_FLAG_RECON_FRAME flag enabled\n @retval \"other negative error code\" legitimate decoding errors"]
    pub fn avcodec_receive_frame(
        avctx: *mut AVCodecContext,
        frame: *mut AVFrame,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Supply a raw video or audio frame to the encoder. Use avcodec_receive_packet()\n to retrieve buffered output packets.\n\n @param avctx     codec context\n @param[in] frame AVFrame containing the raw audio or video frame to be encoded.\n                  Ownership of the frame remains with the caller, and the\n                  encoder will not write to the frame. The encoder may create\n                  a reference to the frame data (or copy it if the frame is\n                  not reference-counted).\n                  It can be NULL, in which case it is considered a flush\n                  packet.  This signals the end of the stream. If the encoder\n                  still has packets buffered, it will return them after this\n                  call. Once flushing mode has been entered, additional flush\n                  packets are ignored, and sending frames will return\n                  AVERROR_EOF.\n\n                  For audio:\n                  If AV_CODEC_CAP_VARIABLE_FRAME_SIZE is set, then each frame\n                  can have any number of samples.\n                  If it is not set, frame->nb_samples must be equal to\n                  avctx->frame_size for all frames except the last.\n                  The final frame may be smaller than avctx->frame_size.\n @retval 0                 success\n @retval AVERROR(EAGAIN)   input is not accepted in the current state - user must\n                           read output with avcodec_receive_packet() (once all\n                           output is read, the packet should be resent, and the\n                           call will not fail with EAGAIN).\n @retval AVERROR_EOF       the encoder has been flushed, and no new frames can\n                           be sent to it\n @retval AVERROR(EINVAL)   codec not opened, it is a decoder, or requires flush\n @retval AVERROR(ENOMEM)   failed to add packet to internal queue, or similar\n @retval \"another negative error code\" legitimate encoding errors"]
    pub fn avcodec_send_frame(
        avctx: *mut AVCodecContext,
        frame: *const AVFrame,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Read encoded data from the encoder.\n\n @param avctx codec context\n @param avpkt This will be set to a reference-counted packet allocated by the\n              encoder. Note that the function will always call\n              av_packet_unref(avpkt) before doing anything else.\n @retval 0               success\n @retval AVERROR(EAGAIN) output is not available in the current state - user must\n                         try to send input\n @retval AVERROR_EOF     the encoder has been fully flushed, and there will be no\n                         more output packets\n @retval AVERROR(EINVAL) codec not opened, or it is a decoder\n @retval \"another negative error code\" legitimate encoding errors"]
    pub fn avcodec_receive_packet(
        avctx: *mut AVCodecContext,
        avpkt: *mut AVPacket,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Create and return a AVHWFramesContext with values adequate for hardware\n decoding. This is meant to get called from the get_format callback, and is\n a helper for preparing a AVHWFramesContext for AVCodecContext.hw_frames_ctx.\n This API is for decoding with certain hardware acceleration modes/APIs only.\n\n The returned AVHWFramesContext is not initialized. The caller must do this\n with av_hwframe_ctx_init().\n\n Calling this function is not a requirement, but makes it simpler to avoid\n codec or hardware API specific details when manually allocating frames.\n\n Alternatively to this, an API user can set AVCodecContext.hw_device_ctx,\n which sets up AVCodecContext.hw_frames_ctx fully automatically, and makes\n it unnecessary to call this function or having to care about\n AVHWFramesContext initialization at all.\n\n There are a number of requirements for calling this function:\n\n - It must be called from get_format with the same avctx parameter that was\n   passed to get_format. Calling it outside of get_format is not allowed, and\n   can trigger undefined behavior.\n - The function is not always supported (see description of return values).\n   Even if this function returns successfully, hwaccel initialization could\n   fail later. (The degree to which implementations check whether the stream\n   is actually supported varies. Some do this check only after the user's\n   get_format callback returns.)\n - The hw_pix_fmt must be one of the choices suggested by get_format. If the\n   user decides to use a AVHWFramesContext prepared with this API function,\n   the user must return the same hw_pix_fmt from get_format.\n - The device_ref passed to this function must support the given hw_pix_fmt.\n - After calling this API function, it is the user's responsibility to\n   initialize the AVHWFramesContext (returned by the out_frames_ref parameter),\n   and to set AVCodecContext.hw_frames_ctx to it. If done, this must be done\n   before returning from get_format (this is implied by the normal\n   AVCodecContext.hw_frames_ctx API rules).\n - The AVHWFramesContext parameters may change every time time get_format is\n   called. Also, AVCodecContext.hw_frames_ctx is reset before get_format. So\n   you are inherently required to go through this process again on every\n   get_format call.\n - It is perfectly possible to call this function without actually using\n   the resulting AVHWFramesContext. One use-case might be trying to reuse a\n   previously initialized AVHWFramesContext, and calling this API function\n   only to test whether the required frame parameters have changed.\n - Fields that use dynamically allocated values of any kind must not be set\n   by the user unless setting them is explicitly allowed by the documentation.\n   If the user sets AVHWFramesContext.free and AVHWFramesContext.user_opaque,\n   the new free callback must call the potentially set previous free callback.\n   This API call may set any dynamically allocated fields, including the free\n   callback.\n\n The function will set at least the following fields on AVHWFramesContext\n (potentially more, depending on hwaccel API):\n\n - All fields set by av_hwframe_ctx_alloc().\n - Set the format field to hw_pix_fmt.\n - Set the sw_format field to the most suited and most versatile format. (An\n   implication is that this will prefer generic formats over opaque formats\n   with arbitrary restrictions, if possible.)\n - Set the width/height fields to the coded frame size, rounded up to the\n   API-specific minimum alignment.\n - Only _if_ the hwaccel requires a pre-allocated pool: set the initial_pool_size\n   field to the number of maximum reference surfaces possible with the codec,\n   plus 1 surface for the user to work (meaning the user can safely reference\n   at most 1 decoded surface at a time), plus additional buffering introduced\n   by frame threading. If the hwaccel does not require pre-allocation, the\n   field is left to 0, and the decoder will allocate new surfaces on demand\n   during decoding.\n - Possibly AVHWFramesContext.hwctx fields, depending on the underlying\n   hardware API.\n\n Essentially, out_frames_ref returns the same as av_hwframe_ctx_alloc(), but\n with basic frame parameters set.\n\n The function is stateless, and does not change the AVCodecContext or the\n device_ref AVHWDeviceContext.\n\n @param avctx The context which is currently calling get_format, and which\n              implicitly contains all state needed for filling the returned\n              AVHWFramesContext properly.\n @param device_ref A reference to the AVHWDeviceContext describing the device\n                   which will be used by the hardware decoder.\n @param hw_pix_fmt The hwaccel format you are going to return from get_format.\n @param out_frames_ref On success, set to a reference to an _uninitialized_\n                       AVHWFramesContext, created from the given device_ref.\n                       Fields will be set to values required for decoding.\n                       Not changed if an error is returned.\n @return zero on success, a negative value on error. The following error codes\n         have special semantics:\n      AVERROR(ENOENT): the decoder does not support this functionality. Setup\n                       is always manual, or it is a decoder which does not\n                       support setting AVCodecContext.hw_frames_ctx at all,\n                       or it is a software format.\n      AVERROR(EINVAL): it is known that hardware decoding is not supported for\n                       this configuration, or the device_ref is not supported\n                       for the hwaccel referenced by hw_pix_fmt."]
    pub fn avcodec_get_hw_frames_parameters(
        avctx: *mut AVCodecContext,
        device_ref: *mut AVBufferRef,
        hw_pix_fmt: AVPixelFormat,
        out_frames_ref: *mut *mut AVBufferRef,
    ) -> ::std::os::raw::c_int;
}
#[doc = "< unknown"]
pub const AVPictureStructure_AV_PICTURE_STRUCTURE_UNKNOWN: AVPictureStructure = 0;
#[doc = "< coded as top field"]
pub const AVPictureStructure_AV_PICTURE_STRUCTURE_TOP_FIELD: AVPictureStructure = 1;
#[doc = "< coded as bottom field"]
pub const AVPictureStructure_AV_PICTURE_STRUCTURE_BOTTOM_FIELD: AVPictureStructure = 2;
#[doc = "< coded as frame"]
pub const AVPictureStructure_AV_PICTURE_STRUCTURE_FRAME: AVPictureStructure = 3;
#[doc = " @defgroup lavc_parsing Frame parsing\n @{"]
pub type AVPictureStructure = ::std::os::raw::c_uint;
#[repr(C)]
#[derive(Debug, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVCodecParserContext {
    pub priv_data: *mut ::std::os::raw::c_void,
    pub parser: *const AVCodecParser,
    pub frame_offset: i64,
    pub cur_offset: i64,
    pub next_frame_offset: i64,
    pub pict_type: ::std::os::raw::c_int,
    #[doc = " This field is used for proper frame duration computation in lavf.\n It signals, how much longer the frame duration of the current frame\n is compared to normal frame duration.\n\n frame_duration = (1 + repeat_pict) * time_base\n\n It is used by codecs like H.264 to display telecined material."]
    pub repeat_pict: ::std::os::raw::c_int,
    pub pts: i64,
    pub dts: i64,
    pub last_pts: i64,
    pub last_dts: i64,
    pub fetch_timestamp: ::std::os::raw::c_int,
    pub cur_frame_start_index: ::std::os::raw::c_int,
    pub cur_frame_offset: [i64; 4usize],
    pub cur_frame_pts: [i64; 4usize],
    pub cur_frame_dts: [i64; 4usize],
    pub flags: ::std::os::raw::c_int,
    #[doc = "< byte offset from starting packet start"]
    pub offset: i64,
    pub cur_frame_end: [i64; 4usize],
    #[doc = " Set by parser to 1 for key frames and 0 for non-key frames.\n It is initialized to -1, so if the parser doesn't set this flag,\n old-style fallback using AV_PICTURE_TYPE_I picture type as key frames\n will be used."]
    pub key_frame: ::std::os::raw::c_int,
    #[doc = " Synchronization point for start of timestamp generation.\n\n Set to >0 for sync point, 0 for no sync point and <0 for undefined\n (default).\n\n For example, this corresponds to presence of H.264 buffering period\n SEI message."]
    pub dts_sync_point: ::std::os::raw::c_int,
    #[doc = " Offset of the current timestamp against last timestamp sync point in\n units of AVCodecContext.time_base.\n\n Set to INT_MIN when dts_sync_point unused. Otherwise, it must\n contain a valid timestamp offset.\n\n Note that the timestamp of sync point has usually a nonzero\n dts_ref_dts_delta, which refers to the previous sync point. Offset of\n the next frame after timestamp sync point will be usually 1.\n\n For example, this corresponds to H.264 cpb_removal_delay."]
    pub dts_ref_dts_delta: ::std::os::raw::c_int,
    #[doc = " Presentation delay of current frame in units of AVCodecContext.time_base.\n\n Set to INT_MIN when dts_sync_point unused. Otherwise, it must\n contain valid non-negative timestamp delta (presentation time of a frame\n must not lie in the past).\n\n This delay represents the difference between decoding and presentation\n time of the frame.\n\n For example, this corresponds to H.264 dpb_output_delay."]
    pub pts_dts_delta: ::std::os::raw::c_int,
    #[doc = " Position of the packet in file.\n\n Analogous to cur_frame_pts/dts"]
    pub cur_frame_pos: [i64; 4usize],
    #[doc = " Byte position of currently parsed frame in stream."]
    pub pos: i64,
    #[doc = " Previous frame byte position."]
    pub last_pos: i64,
    #[doc = " Duration of the current frame.\n For audio, this is in units of 1 / AVCodecContext.sample_rate.\n For all other types, this is in units of AVCodecContext.time_base."]
    pub duration: ::std::os::raw::c_int,
    pub field_order: AVFieldOrder,
    #[doc = " Indicate whether a picture is coded as a frame, top field or bottom field.\n\n For example, H.264 field_pic_flag equal to 0 corresponds to\n AV_PICTURE_STRUCTURE_FRAME. An H.264 picture with field_pic_flag\n equal to 1 and bottom_field_flag equal to 0 corresponds to\n AV_PICTURE_STRUCTURE_TOP_FIELD."]
    pub picture_structure: AVPictureStructure,
    #[doc = " Picture number incremented in presentation or output order.\n This field may be reinitialized at the first picture of a new sequence.\n\n For example, this corresponds to H.264 PicOrderCnt."]
    pub output_picture_number: ::std::os::raw::c_int,
    #[doc = " Dimensions of the decoded video intended for presentation."]
    pub width: ::std::os::raw::c_int,
    pub height: ::std::os::raw::c_int,
    #[doc = " Dimensions of the coded video."]
    pub coded_width: ::std::os::raw::c_int,
    pub coded_height: ::std::os::raw::c_int,
    #[doc = " The format of the coded data, corresponds to enum AVPixelFormat for video\n and for enum AVSampleFormat for audio.\n\n Note that a decoder can have considerable freedom in how exactly it\n decodes the data, so the format reported here might be different from the\n one returned by a decoder."]
    pub format: ::std::os::raw::c_int,
}
impl Default for AVCodecParserContext {
    fn default() -> Self {
        let mut s = ::std::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::std::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVCodecParser {
    pub codec_ids: [::std::os::raw::c_int; 7usize],
    pub priv_data_size: ::std::os::raw::c_int,
    pub parser_init: ::std::option::Option<
        unsafe extern "C" fn(s: *mut AVCodecParserContext) -> ::std::os::raw::c_int,
    >,
    pub parser_parse: ::std::option::Option<
        unsafe extern "C" fn(
            s: *mut AVCodecParserContext,
            avctx: *mut AVCodecContext,
            poutbuf: *mut *const u8,
            poutbuf_size: *mut ::std::os::raw::c_int,
            buf: *const u8,
            buf_size: ::std::os::raw::c_int,
        ) -> ::std::os::raw::c_int,
    >,
    pub parser_close: ::std::option::Option<unsafe extern "C" fn(s: *mut AVCodecParserContext)>,
    pub split: ::std::option::Option<
        unsafe extern "C" fn(
            avctx: *mut AVCodecContext,
            buf: *const u8,
            buf_size: ::std::os::raw::c_int,
        ) -> ::std::os::raw::c_int,
    >,
}
extern "C" {
    #[doc = " Iterate over all registered codec parsers.\n\n @param opaque a pointer where libavcodec will store the iteration state. Must\n               point to NULL to start the iteration.\n\n @return the next registered codec parser or NULL when the iteration is\n         finished"]
    pub fn av_parser_iterate(opaque: *mut *mut ::std::os::raw::c_void) -> *const AVCodecParser;
}
extern "C" {
    pub fn av_parser_init(codec_id: ::std::os::raw::c_int) -> *mut AVCodecParserContext;
}
extern "C" {
    #[doc = " Parse a packet.\n\n @param s             parser context.\n @param avctx         codec context.\n @param poutbuf       set to pointer to parsed buffer or NULL if not yet finished.\n @param poutbuf_size  set to size of parsed buffer or zero if not yet finished.\n @param buf           input buffer.\n @param buf_size      buffer size in bytes without the padding. I.e. the full buffer\nsize is assumed to be buf_size + AV_INPUT_BUFFER_PADDING_SIZE.\nTo signal EOF, this should be 0 (so that the last frame\ncan be output).\n @param pts           input presentation timestamp.\n @param dts           input decoding timestamp.\n @param pos           input byte position in stream.\n @return the number of bytes of the input bitstream used.\n\n Example:\n @code\n   while(in_len){\n       len = av_parser_parse2(myparser, AVCodecContext, &data, &size,\n                                        in_data, in_len,\n                                        pts, dts, pos);\n       in_data += len;\n       in_len  -= len;\n\n       if(size)\n          decode_frame(data, size);\n   }\n @endcode"]
    pub fn av_parser_parse2(
        s: *mut AVCodecParserContext,
        avctx: *mut AVCodecContext,
        poutbuf: *mut *mut u8,
        poutbuf_size: *mut ::std::os::raw::c_int,
        buf: *const u8,
        buf_size: ::std::os::raw::c_int,
        pts: i64,
        dts: i64,
        pos: i64,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn av_parser_close(s: *mut AVCodecParserContext);
}
extern "C" {
    #[doc = " @addtogroup lavc_encoding\n @{"]
    pub fn avcodec_encode_subtitle(
        avctx: *mut AVCodecContext,
        buf: *mut u8,
        buf_size: ::std::os::raw::c_int,
        sub: *const AVSubtitle,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Return a value representing the fourCC code associated to the\n pixel format pix_fmt, or 0 if no associated fourCC code can be\n found."]
    pub fn avcodec_pix_fmt_to_codec_tag(pix_fmt: AVPixelFormat) -> ::std::os::raw::c_uint;
}
extern "C" {
    #[doc = " Find the best pixel format to convert to given a certain source pixel\n format.  When converting from one pixel format to another, information loss\n may occur.  For example, when converting from RGB24 to GRAY, the color\n information will be lost. Similarly, other losses occur when converting from\n some formats to other formats. avcodec_find_best_pix_fmt_of_2() searches which of\n the given pixel formats should be used to suffer the least amount of loss.\n The pixel formats from which it chooses one, are determined by the\n pix_fmt_list parameter.\n\n\n @param[in] pix_fmt_list AV_PIX_FMT_NONE terminated array of pixel formats to choose from\n @param[in] src_pix_fmt source pixel format\n @param[in] has_alpha Whether the source pixel format alpha channel is used.\n @param[out] loss_ptr Combination of flags informing you what kind of losses will occur.\n @return The best pixel format to convert to or -1 if none was found."]
    pub fn avcodec_find_best_pix_fmt_of_list(
        pix_fmt_list: *const AVPixelFormat,
        src_pix_fmt: AVPixelFormat,
        has_alpha: ::std::os::raw::c_int,
        loss_ptr: *mut ::std::os::raw::c_int,
    ) -> AVPixelFormat;
}
extern "C" {
    pub fn avcodec_default_get_format(
        s: *mut AVCodecContext,
        fmt: *const AVPixelFormat,
    ) -> AVPixelFormat;
}
extern "C" {
    #[doc = " @}"]
    pub fn avcodec_string(
        buf: *mut ::std::os::raw::c_char,
        buf_size: ::std::os::raw::c_int,
        enc: *mut AVCodecContext,
        encode: ::std::os::raw::c_int,
    );
}
extern "C" {
    pub fn avcodec_default_execute(
        c: *mut AVCodecContext,
        func: ::std::option::Option<
            unsafe extern "C" fn(
                c2: *mut AVCodecContext,
                arg2: *mut ::std::os::raw::c_void,
            ) -> ::std::os::raw::c_int,
        >,
        arg: *mut ::std::os::raw::c_void,
        ret: *mut ::std::os::raw::c_int,
        count: ::std::os::raw::c_int,
        size: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn avcodec_default_execute2(
        c: *mut AVCodecContext,
        func: ::std::option::Option<
            unsafe extern "C" fn(
                c2: *mut AVCodecContext,
                arg2: *mut ::std::os::raw::c_void,
                arg1: ::std::os::raw::c_int,
                arg2: ::std::os::raw::c_int,
            ) -> ::std::os::raw::c_int,
        >,
        arg: *mut ::std::os::raw::c_void,
        ret: *mut ::std::os::raw::c_int,
        count: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Fill AVFrame audio data and linesize pointers.\n\n The buffer buf must be a preallocated buffer with a size big enough\n to contain the specified samples amount. The filled AVFrame data\n pointers will point to this buffer.\n\n AVFrame extended_data channel pointers are allocated if necessary for\n planar audio.\n\n @param frame       the AVFrame\n                    frame->nb_samples must be set prior to calling the\n                    function. This function fills in frame->data,\n                    frame->extended_data, frame->linesize[0].\n @param nb_channels channel count\n @param sample_fmt  sample format\n @param buf         buffer to use for frame data\n @param buf_size    size of buffer\n @param align       plane size sample alignment (0 = default)\n @return            >=0 on success, negative error code on failure\n @todo return the size in bytes required to store the samples in\n case of success, at the next libavutil bump"]
    pub fn avcodec_fill_audio_frame(
        frame: *mut AVFrame,
        nb_channels: ::std::os::raw::c_int,
        sample_fmt: AVSampleFormat,
        buf: *const u8,
        buf_size: ::std::os::raw::c_int,
        align: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Reset the internal codec state / flush internal buffers. Should be called\n e.g. when seeking or when switching to a different stream.\n\n @note for decoders, this function just releases any references the decoder\n might keep internally, but the caller's references remain valid.\n\n @note for encoders, this function will only do something if the encoder\n declares support for AV_CODEC_CAP_ENCODER_FLUSH. When called, the encoder\n will drain any remaining packets, and can then be re-used for a different\n stream (as opposed to sending a null frame which will leave the encoder\n in a permanent EOF state after draining). This can be desirable if the\n cost of tearing down and replacing the encoder instance is high."]
    pub fn avcodec_flush_buffers(avctx: *mut AVCodecContext);
}
extern "C" {
    #[doc = " Return audio frame duration.\n\n @param avctx        codec context\n @param frame_bytes  size of the frame, or 0 if unknown\n @return             frame duration, in samples, if known. 0 if not able to\n                     determine."]
    pub fn av_get_audio_frame_duration(
        avctx: *mut AVCodecContext,
        frame_bytes: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Same behaviour av_fast_malloc but the buffer has additional\n AV_INPUT_BUFFER_PADDING_SIZE at the end which will always be 0.\n\n In addition the whole buffer will initially and after resizes\n be 0-initialized so that no uninitialized data will ever appear."]
    pub fn av_fast_padded_malloc(
        ptr: *mut ::std::os::raw::c_void,
        size: *mut ::std::os::raw::c_uint,
        min_size: usize,
    );
}
extern "C" {
    #[doc = " Same behaviour av_fast_padded_malloc except that buffer will always\n be 0-initialized after call."]
    pub fn av_fast_padded_mallocz(
        ptr: *mut ::std::os::raw::c_void,
        size: *mut ::std::os::raw::c_uint,
        min_size: usize,
    );
}
extern "C" {
    #[doc = " @return a positive value if s is open (i.e. avcodec_open2() was called on it\n with no corresponding avcodec_close()), 0 otherwise."]
    pub fn avcodec_is_open(s: *mut AVCodecContext) -> ::std::os::raw::c_int;
}
pub type __builtin_va_list = *mut ::std::os::raw::c_void;
#[doc = " a pointer to the first option specified in the class if any or NULL\n\n @see av_set_default_options()"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVOption {
    pub _address: u8,
}
#[doc = " Private context used for internal data.\n\n Unlike priv_data, this is not codec-specific. It is used in general\n libavcodec functions."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone, Hash, PartialOrd, Ord, PartialEq, Eq)]
pub struct AVCodecInternal {
    pub _address: u8,
}
